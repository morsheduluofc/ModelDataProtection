{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of this program\n",
    "## Read the oversampled data and then project the data in a new dimension. Used the projected data to train a ML model\n",
    "## Verify security of the trained model by test data (project the test data by using different random matrices)\n",
    "## #Test the model accuracy by attack data (user data whose profile are not used to train ML model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.582305</td>\n",
       "      <td>-0.091624</td>\n",
       "      <td>-0.113317</td>\n",
       "      <td>0.069735</td>\n",
       "      <td>-0.056116</td>\n",
       "      <td>0.071154</td>\n",
       "      <td>-0.146473</td>\n",
       "      <td>0.049818</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137189</td>\n",
       "      <td>-0.202803</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.239653</td>\n",
       "      <td>0.033237</td>\n",
       "      <td>0.097121</td>\n",
       "      <td>0.090061</td>\n",
       "      <td>-0.064359</td>\n",
       "      <td>-0.222110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.403713</td>\n",
       "      <td>-0.178570</td>\n",
       "      <td>0.066751</td>\n",
       "      <td>-0.055265</td>\n",
       "      <td>-0.010389</td>\n",
       "      <td>0.041391</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>0.018638</td>\n",
       "      <td>-0.047548</td>\n",
       "      <td>-0.012591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434401</td>\n",
       "      <td>0.033208</td>\n",
       "      <td>-0.172818</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.126595</td>\n",
       "      <td>-0.084699</td>\n",
       "      <td>-0.008194</td>\n",
       "      <td>-0.019724</td>\n",
       "      <td>-0.256300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.400374</td>\n",
       "      <td>-0.185792</td>\n",
       "      <td>0.012088</td>\n",
       "      <td>-0.067337</td>\n",
       "      <td>0.038272</td>\n",
       "      <td>0.049996</td>\n",
       "      <td>0.012814</td>\n",
       "      <td>-0.025244</td>\n",
       "      <td>-0.030817</td>\n",
       "      <td>-0.068128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156473</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>-0.124143</td>\n",
       "      <td>-0.129319</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>-0.046710</td>\n",
       "      <td>-0.008062</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>-0.075796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.477862</td>\n",
       "      <td>-0.018475</td>\n",
       "      <td>0.071872</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>-0.016150</td>\n",
       "      <td>-0.035783</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>-0.061627</td>\n",
       "      <td>-0.107956</td>\n",
       "      <td>-0.082812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127110</td>\n",
       "      <td>0.179423</td>\n",
       "      <td>-0.115302</td>\n",
       "      <td>0.104676</td>\n",
       "      <td>-0.107193</td>\n",
       "      <td>0.209552</td>\n",
       "      <td>0.027887</td>\n",
       "      <td>0.117224</td>\n",
       "      <td>0.104110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.465657</td>\n",
       "      <td>-0.029432</td>\n",
       "      <td>-0.029614</td>\n",
       "      <td>0.028301</td>\n",
       "      <td>0.067341</td>\n",
       "      <td>-0.131359</td>\n",
       "      <td>0.090756</td>\n",
       "      <td>-0.053325</td>\n",
       "      <td>-0.038439</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122469</td>\n",
       "      <td>-0.361710</td>\n",
       "      <td>-0.096674</td>\n",
       "      <td>0.032555</td>\n",
       "      <td>0.192928</td>\n",
       "      <td>-0.012668</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>-0.094648</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.582305 -0.091624 -0.113317  0.069735 -0.056116  0.071154 -0.146473   \n",
       "1  0.403713 -0.178570  0.066751 -0.055265 -0.010389  0.041391  0.013069   \n",
       "2  0.400374 -0.185792  0.012088 -0.067337  0.038272  0.049996  0.012814   \n",
       "3  0.477862 -0.018475  0.071872 -0.000463 -0.016150 -0.035783  0.070162   \n",
       "4  0.465657 -0.029432 -0.029614  0.028301  0.067341 -0.131359  0.090756   \n",
       "\n",
       "          8         9        10  ...        96        97        98        99  \\\n",
       "0  0.049818  0.002500  0.020655  ...  0.137189 -0.202803 -0.061708 -0.239653   \n",
       "1  0.018638 -0.047548 -0.012591  ...  0.434401  0.033208 -0.172818  0.005580   \n",
       "2 -0.025244 -0.030817 -0.068128  ...  0.156473  0.000591 -0.124143 -0.129319   \n",
       "3 -0.061627 -0.107956 -0.082812  ...  0.127110  0.179423 -0.115302  0.104676   \n",
       "4 -0.053325 -0.038439  0.009342  ...  0.122469 -0.361710 -0.096674  0.032555   \n",
       "\n",
       "        100       101       102       103       104  Label  \n",
       "0  0.033237  0.097121  0.090061 -0.064359 -0.222110      0  \n",
       "1  0.126595 -0.084699 -0.008194 -0.019724 -0.256300      0  \n",
       "2  0.004072 -0.046710 -0.008062  0.001104 -0.075796      0  \n",
       "3 -0.107193  0.209552  0.027887  0.117224  0.104110      0  \n",
       "4  0.192928 -0.012668  0.027907 -0.094648  0.170670      0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read all data\n",
    "import csv\n",
    "import pandas as pd\n",
    "dataset=pd.read_csv('Dataset\\OversampledVoiceData.csv',index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIeZ6YEDfA-n",
    "outputId": "45773dd3-0044-4836-e53c-a3f147051c3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17200, 105)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0E2tEHXVILi",
    "outputId": "6009ba3e-a8de-4f88-8ddb-353e45bad711"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0     200\n",
       "1     200\n",
       "2     200\n",
       "3     200\n",
       "4     200\n",
       "     ... \n",
       "81    200\n",
       "82    200\n",
       "83    200\n",
       "84    200\n",
       "85    200\n",
       "Name: Label, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace the user ID by class name and count the number of sample in each class\n",
    "dataset['Label'] = pd.factorize(dataset['Label'])[0]\n",
    "dataset.groupby(['Label'])['Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1ECjuoeVILj",
    "outputId": "6f90137f-dda1-4e87-e80f-7f1f090aa77f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in training dataset: 68\n",
      "Total user in auxiliary dataset: 18\n"
     ]
    }
   ],
   "source": [
    "#seperate the profile in two groups (80.0%, 20.0%): (i) Training profile (0-155), and (ii) auxiliary profile (156-192)\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData = dataset[dataset['Label'] <68]\n",
    "auxilaryData = dataset[dataset['Label'] >= 68]\n",
    "print(\"Total user in training dataset:\", len(pd.unique(trainingData['Label'])))\n",
    "print(\"Total user in auxiliary dataset:\", len(pd.unique(auxilaryData['Label'])))\n",
    "#assigned 0-154 users' data to dataset\n",
    "dataset=trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjPJhsxJVILj",
    "outputId": "f7a2ca95-5992-4875-f6b3-6197fe61e605"
   },
   "outputs": [],
   "source": [
    "#Prepare the traning data for training and testing the model\n",
    "#import tensorflow\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "#Xtrain, Xtest= train_test_split(trainingData, test_size=0.2, random_state=22)\n",
    "#Xtrain.groupby(['Label'])['Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XnVsHhXjtjWM",
    "outputId": "1edca751-3479-442f-c323-f10519124c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in the training dataset: 68\n"
     ]
    }
   ],
   "source": [
    "#total use in the system\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData=dataset\n",
    "print(\"Total user in the training dataset:\", len(pd.unique(trainingData['Label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdnsfZolVILk",
    "outputId": "23512e15-149c-4cb1-8d49-9def8d346ab8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_26360\\1610803386.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  trainDatasetRP = pd.concat([trainDatasetRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13600, 105)\n",
      "(13600, 95)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30', 'RPF31', 'RPF32', 'RPF33', 'RPF34', 'RPF35',\n",
    "         'RPF36', 'RPF37', 'RPF38', 'RPF39', 'RPF40', 'RPF41', 'RPF42', 'RPF43', 'RPF44', 'RPF45', 'RPF46', 'RPF47', 'RPF48', 'RPF49', 'RPF50', 'RPF51', 'RPF52',\n",
    "         'RPF53', 'RPF54', 'RPF55', 'RPF56', 'RPF57', 'RPF58', 'RPF59', 'RPF60', 'RPF61', 'RPF62', 'RPF63', 'RPF64', 'RPF65', 'RPF66', 'RPF67', 'RPF68', 'RPF69',\n",
    "         'RPF70', 'RPF71', 'RPF72', 'RPF73', 'RPF74', 'RPF75', 'RPF76', 'RPF77', 'RPF78', 'RPF79', 'RPF80', 'RPF81', 'RPF82', 'RPF83', 'RPF84', 'RPF85', 'RPF86',\n",
    "         'RPF87', 'RPF88', 'RPF89', 'RPF90', 'RPF91', 'RPF92', 'RPF93', 'RPF94', 'Label']\n",
    "column2=column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30', 'RPF31', 'RPF32', 'RPF33', 'RPF34', 'RPF35',\n",
    "         'RPF36', 'RPF37', 'RPF38', 'RPF39', 'RPF40', 'RPF41', 'RPF42', 'RPF43', 'RPF44', 'RPF45', 'RPF46', 'RPF47', 'RPF48', 'RPF49', 'RPF50', 'RPF51', 'RPF52',\n",
    "         'RPF53', 'RPF54', 'RPF55', 'RPF56', 'RPF57', 'RPF58', 'RPF59', 'RPF60', 'RPF61', 'RPF62', 'RPF63', 'RPF64', 'RPF65', 'RPF66', 'RPF67', 'RPF68', 'RPF69',\n",
    "         'RPF70', 'RPF71', 'RPF72', 'RPF73', 'RPF74', 'RPF75', 'RPF76', 'RPF77', 'RPF78', 'RPF79', 'RPF80', 'RPF81', 'RPF82', 'RPF83', 'RPF84', 'RPF85', 'RPF86',\n",
    "         'RPF87', 'RPF88', 'RPF89', 'RPF90', 'RPF91', 'RPF92', 'RPF93', 'RPF94']\n",
    "\n",
    "trainDatasetRP = pd.DataFrame(columns=column1)\n",
    "\n",
    "# Assuming Xtrain is defined before this code snippet\n",
    "\n",
    "for seed in range(0,68):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = trainingData[trainingData['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=94, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    trainDatasetRP = pd.concat([trainDatasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(trainingData.shape)\n",
    "print(trainDatasetRP.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare group 1 traning data for training and validate the model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X=trainDatasetRP.drop(columns=['Label'])\n",
    "y=trainDatasetRP['Label']\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "#Xtest=testDatasetRP.drop(columns=['Label'])\n",
    "#ytest=testDatasetRP['Label']\n",
    "\n",
    "ytrain = to_categorical(ytrain)\n",
    "yval = to_categorical(yval)\n",
    "#ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10880, 94)\n",
      "(10880, 68)\n",
      "(2720, 94)\n",
      "(2720, 68)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xval.shape)\n",
    "print(yval.shape)\n",
    "#print(Xtest.shape)\n",
    "#print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nPqBOz3FVILo"
   },
   "outputs": [],
   "source": [
    "# import all necessary package for a neural network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inlineimport keras\n",
    "from keras.layers import Dense, Dropout, Input,Activation,Dropout, Flatten\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "#from tqdm import tqdm\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "#import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SkLyIb0GVILp"
   },
   "outputs": [],
   "source": [
    "#define optimizers for neural network\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "def adam_optimizer():\n",
    "    return Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "def RMSprop_optimizer():\n",
    "    return RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MxWvP-EBVILq",
    "outputId": "be04c0ad-a8a0-4aee-ccf9-33804211007c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,330</span> (95.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,330\u001b[0m (95.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,818</span> (93.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,818\u001b[0m (93.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_classifierRP(release=False, totalClass=10):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(64, input_dim=94))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Activation('relu'))\n",
    "    classifier.add(Dropout(0.5))\n",
    "\n",
    "    classifier.add(Dense(128))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Activation('relu'))\n",
    "    classifier.add(Dropout(0.2))\n",
    "\n",
    "    #classifier.add(Dense(256))\n",
    "    #classifier.add(BatchNormalization())\n",
    "    #classifier.add(Activation('relu'))\n",
    "    #classifier.add(Dropout(0.2))\n",
    "\n",
    "    classifier.add(Dense(64))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Activation('relu'))\n",
    "    classifier.add(Dropout(0.2))\n",
    "\n",
    "    classifier.add(Dense(totalClass, activation='softmax'))\n",
    "\n",
    "\n",
    "    classifier.compile(loss='categorical_crossentropy', optimizer=RMSprop_optimizer(), metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "Clasf=create_classifierRP()\n",
    "Clasf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2k9bvzvVILr",
    "outputId": "c126a7cc-a9ca-4c70-c977-66596ecb0cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1644 - loss: 3.6838 - val_accuracy: 0.9739 - val_loss: 2.3927\n",
      "Epoch 2/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6987 - loss: 1.7750 - val_accuracy: 1.0000 - val_loss: 0.4235\n",
      "Epoch 3/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8218 - loss: 0.9312 - val_accuracy: 1.0000 - val_loss: 0.0521\n",
      "Epoch 4/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.5854 - val_accuracy: 1.0000 - val_loss: 0.0113\n",
      "Epoch 5/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8921 - loss: 0.4453 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 6/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9039 - loss: 0.3613 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 7/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9160 - loss: 0.3127 - val_accuracy: 1.0000 - val_loss: 7.5253e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9204 - loss: 0.2722 - val_accuracy: 1.0000 - val_loss: 5.1875e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9247 - loss: 0.2582 - val_accuracy: 1.0000 - val_loss: 3.2058e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9313 - loss: 0.2397 - val_accuracy: 1.0000 - val_loss: 2.2605e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 0.2326 - val_accuracy: 1.0000 - val_loss: 1.5796e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 0.2038 - val_accuracy: 1.0000 - val_loss: 1.2306e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.2124 - val_accuracy: 1.0000 - val_loss: 9.4809e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9432 - loss: 0.1893 - val_accuracy: 1.0000 - val_loss: 7.2474e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.1902 - val_accuracy: 1.0000 - val_loss: 5.8296e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9503 - loss: 0.1600 - val_accuracy: 1.0000 - val_loss: 4.5944e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.1794 - val_accuracy: 1.0000 - val_loss: 4.9124e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9518 - loss: 0.1670 - val_accuracy: 1.0000 - val_loss: 3.9876e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.1664 - val_accuracy: 1.0000 - val_loss: 3.6680e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9549 - loss: 0.1506 - val_accuracy: 1.0000 - val_loss: 3.5210e-05\n"
     ]
    }
   ],
   "source": [
    "#Train the classifier seperately for black-box attack\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5,min_lr=0.0001)\n",
    "# callbacks_list = [learning_rate_reduction]\n",
    "\n",
    "Classfier2= create_classifierRP(True,68)\n",
    "\n",
    "#------Comment will start from here\n",
    "lossc='categorical_crossentropy'\n",
    "optimizerc=RMSprop(learning_rate=0.001, rho=0.9)\n",
    "Classfier2.compile(loss=lossc, optimizer=optimizerc,metrics=['accuracy'])\n",
    "#------Comments will end from here\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "historyc2 =  Classfier2.fit(Xtrain, ytrain, batch_size=64, epochs=20, validation_data=(Xval, yval),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "0pSKQPWhVILt",
    "outputId": "57b6da97-1b76-4811-94a9-24cc0fade3da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the classifier loss and accuracy curves for training and validation data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(historyc2.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(historyc2.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test by the data set that come from same user but different random matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the test data and seperate test data\n",
    "import csv\n",
    "import pandas as pd\n",
    "testdataset=pd.read_csv('Dataset/VoiceDatatest.csv',index_col=0)\n",
    "testdataset = testdataset[testdataset['Label'] < 68]\n",
    "#testdataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_26360\\637877016.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  testDatasetRP = pd.concat([testDatasetRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1639, 105)\n",
      "(1639, 95)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30', 'RPF31', 'RPF32', 'RPF33', 'RPF34', 'RPF35',\n",
    "         'RPF36', 'RPF37', 'RPF38', 'RPF39', 'RPF40', 'RPF41', 'RPF42', 'RPF43', 'RPF44', 'RPF45', 'RPF46', 'RPF47', 'RPF48', 'RPF49', 'RPF50', 'RPF51', 'RPF52',\n",
    "         'RPF53', 'RPF54', 'RPF55', 'RPF56', 'RPF57', 'RPF58', 'RPF59', 'RPF60', 'RPF61', 'RPF62', 'RPF63', 'RPF64', 'RPF65', 'RPF66', 'RPF67', 'RPF68', 'RPF69',\n",
    "         'RPF70', 'RPF71', 'RPF72', 'RPF73', 'RPF74', 'RPF75', 'RPF76', 'RPF77', 'RPF78', 'RPF79', 'RPF80', 'RPF81', 'RPF82', 'RPF83', 'RPF84', 'RPF85', 'RPF86',\n",
    "         'RPF87', 'RPF88', 'RPF89', 'RPF90', 'RPF91', 'RPF92', 'RPF93', 'RPF94', 'Label']\n",
    "column2=column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30', 'RPF31', 'RPF32', 'RPF33', 'RPF34', 'RPF35',\n",
    "         'RPF36', 'RPF37', 'RPF38', 'RPF39', 'RPF40', 'RPF41', 'RPF42', 'RPF43', 'RPF44', 'RPF45', 'RPF46', 'RPF47', 'RPF48', 'RPF49', 'RPF50', 'RPF51', 'RPF52',\n",
    "         'RPF53', 'RPF54', 'RPF55', 'RPF56', 'RPF57', 'RPF58', 'RPF59', 'RPF60', 'RPF61', 'RPF62', 'RPF63', 'RPF64', 'RPF65', 'RPF66', 'RPF67', 'RPF68', 'RPF69',\n",
    "         'RPF70', 'RPF71', 'RPF72', 'RPF73', 'RPF74', 'RPF75', 'RPF76', 'RPF77', 'RPF78', 'RPF79', 'RPF80', 'RPF81', 'RPF82', 'RPF83', 'RPF84', 'RPF85', 'RPF86',\n",
    "         'RPF87', 'RPF88', 'RPF89', 'RPF90', 'RPF91', 'RPF92', 'RPF93', 'RPF94']\n",
    "\n",
    "testDatasetRP = pd.DataFrame(columns=column1)\n",
    "\n",
    "for seed in range(0,68):\n",
    "    rng = np.random.RandomState(seed+1)\n",
    "    X = testdataset[testdataset['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=94, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    testDatasetRP = pd.concat([testDatasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(testdataset.shape)\n",
    "print(testDatasetRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=testDatasetRP.drop(columns=['Label'])\n",
    "ytest=testDatasetRP['Label']\n",
    "ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4kPqMRQSVILu",
    "outputId": "67b92158-2e2f-40af-a49c-48df5f8a37ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 19.4521  \n",
      "Loss: 19.03345489501953\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test the model accuracy by attack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8796</th>\n",
       "      <td>0.577301</td>\n",
       "      <td>-0.521846</td>\n",
       "      <td>-0.458939</td>\n",
       "      <td>-0.169801</td>\n",
       "      <td>0.492290</td>\n",
       "      <td>-0.608976</td>\n",
       "      <td>-0.075974</td>\n",
       "      <td>-0.057947</td>\n",
       "      <td>0.272287</td>\n",
       "      <td>-0.016334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048005</td>\n",
       "      <td>-0.225233</td>\n",
       "      <td>-0.009301</td>\n",
       "      <td>0.182901</td>\n",
       "      <td>-0.043218</td>\n",
       "      <td>-0.021152</td>\n",
       "      <td>0.009831</td>\n",
       "      <td>0.063303</td>\n",
       "      <td>-0.055561</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8209</th>\n",
       "      <td>0.327843</td>\n",
       "      <td>-0.168374</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.294810</td>\n",
       "      <td>-0.125812</td>\n",
       "      <td>-0.565006</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.336860</td>\n",
       "      <td>-0.243190</td>\n",
       "      <td>-0.249655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.293992</td>\n",
       "      <td>-0.315545</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>0.142055</td>\n",
       "      <td>-0.040365</td>\n",
       "      <td>-0.009444</td>\n",
       "      <td>-0.190533</td>\n",
       "      <td>0.016862</td>\n",
       "      <td>-0.503840</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8721</th>\n",
       "      <td>0.436850</td>\n",
       "      <td>0.242402</td>\n",
       "      <td>-0.545839</td>\n",
       "      <td>0.490844</td>\n",
       "      <td>-0.176363</td>\n",
       "      <td>0.218081</td>\n",
       "      <td>-0.479460</td>\n",
       "      <td>0.485923</td>\n",
       "      <td>-0.089936</td>\n",
       "      <td>0.129415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454873</td>\n",
       "      <td>-0.007616</td>\n",
       "      <td>-0.550065</td>\n",
       "      <td>0.344938</td>\n",
       "      <td>-0.151026</td>\n",
       "      <td>0.131478</td>\n",
       "      <td>0.022711</td>\n",
       "      <td>-0.051380</td>\n",
       "      <td>0.116940</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8875</th>\n",
       "      <td>0.824280</td>\n",
       "      <td>-0.238647</td>\n",
       "      <td>-0.423929</td>\n",
       "      <td>-0.034956</td>\n",
       "      <td>0.228715</td>\n",
       "      <td>-0.374185</td>\n",
       "      <td>-0.142289</td>\n",
       "      <td>0.114626</td>\n",
       "      <td>0.166814</td>\n",
       "      <td>0.080253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069756</td>\n",
       "      <td>-0.344372</td>\n",
       "      <td>-0.107741</td>\n",
       "      <td>0.179268</td>\n",
       "      <td>0.074635</td>\n",
       "      <td>-0.068413</td>\n",
       "      <td>-0.087623</td>\n",
       "      <td>0.231988</td>\n",
       "      <td>-0.060065</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>0.537243</td>\n",
       "      <td>0.459554</td>\n",
       "      <td>0.087789</td>\n",
       "      <td>-0.018138</td>\n",
       "      <td>-0.026348</td>\n",
       "      <td>0.170799</td>\n",
       "      <td>-0.129531</td>\n",
       "      <td>-0.216600</td>\n",
       "      <td>-0.362393</td>\n",
       "      <td>0.169105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104851</td>\n",
       "      <td>-0.217039</td>\n",
       "      <td>0.072538</td>\n",
       "      <td>0.095208</td>\n",
       "      <td>0.076355</td>\n",
       "      <td>0.045516</td>\n",
       "      <td>-0.025971</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>-0.144510</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4         5         6         7  \\\n",
       "8796  0.577301 -0.521846 -0.458939 -0.169801  0.492290 -0.608976 -0.075974   \n",
       "8209  0.327843 -0.168374  0.086000  0.294810 -0.125812 -0.565006  0.021564   \n",
       "8721  0.436850  0.242402 -0.545839  0.490844 -0.176363  0.218081 -0.479460   \n",
       "8875  0.824280 -0.238647 -0.423929 -0.034956  0.228715 -0.374185 -0.142289   \n",
       "9294  0.537243  0.459554  0.087789 -0.018138 -0.026348  0.170799 -0.129531   \n",
       "\n",
       "             8         9        10  ...        96        97        98  \\\n",
       "8796 -0.057947  0.272287 -0.016334  ...  0.048005 -0.225233 -0.009301   \n",
       "8209  0.336860 -0.243190 -0.249655  ... -0.293992 -0.315545  0.182196   \n",
       "8721  0.485923 -0.089936  0.129415  ...  0.454873 -0.007616 -0.550065   \n",
       "8875  0.114626  0.166814  0.080253  ...  0.069756 -0.344372 -0.107741   \n",
       "9294 -0.216600 -0.362393  0.169105  ... -0.104851 -0.217039  0.072538   \n",
       "\n",
       "            99       100       101       102       103       104  Label  \n",
       "8796  0.182901 -0.043218 -0.021152  0.009831  0.063303 -0.055561      4  \n",
       "8209  0.142055 -0.040365 -0.009444 -0.190533  0.016862 -0.503840     17  \n",
       "8721  0.344938 -0.151026  0.131478  0.022711 -0.051380  0.116940     39  \n",
       "8875  0.179268  0.074635 -0.068413 -0.087623  0.231988 -0.060065      7  \n",
       "9294  0.095208  0.076355  0.045516 -0.025971  0.003157 -0.144510     66  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invalid test data\n",
    "import csv\n",
    "import pandas as pd\n",
    "testdataset=pd.read_csv('Dataset/VoiceDatatest.csv',index_col=0)\n",
    "testdataset = testdataset[testdataset['Label'] >= 68]\n",
    "newID = np.random.randint(0, 68, size=testdataset.shape[0])\n",
    "testdataset['Label'] = newID\n",
    "testdataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_26360\\3384775921.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  testDatasetRP = pd.concat([testDatasetRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425, 105)\n",
      "(425, 95)\n"
     ]
    }
   ],
   "source": [
    "#random project the test data\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30', 'RPF31', 'RPF32', 'RPF33', 'RPF34', 'RPF35',\n",
    "         'RPF36', 'RPF37', 'RPF38', 'RPF39', 'RPF40', 'RPF41', 'RPF42', 'RPF43', 'RPF44', 'RPF45', 'RPF46', 'RPF47', 'RPF48', 'RPF49', 'RPF50', 'RPF51', 'RPF52',\n",
    "         'RPF53', 'RPF54', 'RPF55', 'RPF56', 'RPF57', 'RPF58', 'RPF59', 'RPF60', 'RPF61', 'RPF62', 'RPF63', 'RPF64', 'RPF65', 'RPF66', 'RPF67', 'RPF68', 'RPF69',\n",
    "         'RPF70', 'RPF71', 'RPF72', 'RPF73', 'RPF74', 'RPF75', 'RPF76', 'RPF77', 'RPF78', 'RPF79', 'RPF80', 'RPF81', 'RPF82', 'RPF83', 'RPF84', 'RPF85', 'RPF86',\n",
    "         'RPF87', 'RPF88', 'RPF89', 'RPF90', 'RPF91', 'RPF92', 'RPF93', 'RPF94', 'Label']\n",
    "column2=column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30', 'RPF31', 'RPF32', 'RPF33', 'RPF34', 'RPF35',\n",
    "         'RPF36', 'RPF37', 'RPF38', 'RPF39', 'RPF40', 'RPF41', 'RPF42', 'RPF43', 'RPF44', 'RPF45', 'RPF46', 'RPF47', 'RPF48', 'RPF49', 'RPF50', 'RPF51', 'RPF52',\n",
    "         'RPF53', 'RPF54', 'RPF55', 'RPF56', 'RPF57', 'RPF58', 'RPF59', 'RPF60', 'RPF61', 'RPF62', 'RPF63', 'RPF64', 'RPF65', 'RPF66', 'RPF67', 'RPF68', 'RPF69',\n",
    "         'RPF70', 'RPF71', 'RPF72', 'RPF73', 'RPF74', 'RPF75', 'RPF76', 'RPF77', 'RPF78', 'RPF79', 'RPF80', 'RPF81', 'RPF82', 'RPF83', 'RPF84', 'RPF85', 'RPF86',\n",
    "         'RPF87', 'RPF88', 'RPF89', 'RPF90', 'RPF91', 'RPF92', 'RPF93', 'RPF94']\n",
    "\n",
    "testDatasetRP = pd.DataFrame(columns=column1)\n",
    "\n",
    "for seed in range(0,68):\n",
    "    rng = np.random.RandomState(seed+1)\n",
    "    X = testdataset[testdataset['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=94, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    testDatasetRP = pd.concat([testDatasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(testdataset.shape)\n",
    "print(testDatasetRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=testDatasetRP.drop(columns=['Label'])\n",
    "ytest=testDatasetRP['Label']\n",
    "ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 3.1373e-04 - loss: 16.9550  \n",
      "Loss: 17.604259490966797\n",
      "Accuracy: 0.002352941082790494\n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
