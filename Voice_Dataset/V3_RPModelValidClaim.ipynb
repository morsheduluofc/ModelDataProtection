{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of this program\n",
    "## Read the oversampled data and then project the data in a new dimension. Used the projected data to train a ML model\n",
    "## Verify correctness of the trained model by test data (project the test data by using same random matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.582305</td>\n",
       "      <td>-0.091624</td>\n",
       "      <td>-0.113317</td>\n",
       "      <td>0.069735</td>\n",
       "      <td>-0.056116</td>\n",
       "      <td>0.071154</td>\n",
       "      <td>-0.146473</td>\n",
       "      <td>0.049818</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137189</td>\n",
       "      <td>-0.202803</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.239653</td>\n",
       "      <td>0.033237</td>\n",
       "      <td>0.097121</td>\n",
       "      <td>0.090061</td>\n",
       "      <td>-0.064359</td>\n",
       "      <td>-0.222110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.403713</td>\n",
       "      <td>-0.178570</td>\n",
       "      <td>0.066751</td>\n",
       "      <td>-0.055265</td>\n",
       "      <td>-0.010389</td>\n",
       "      <td>0.041391</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>0.018638</td>\n",
       "      <td>-0.047548</td>\n",
       "      <td>-0.012591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434401</td>\n",
       "      <td>0.033208</td>\n",
       "      <td>-0.172818</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.126595</td>\n",
       "      <td>-0.084699</td>\n",
       "      <td>-0.008194</td>\n",
       "      <td>-0.019724</td>\n",
       "      <td>-0.256300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.400374</td>\n",
       "      <td>-0.185792</td>\n",
       "      <td>0.012088</td>\n",
       "      <td>-0.067337</td>\n",
       "      <td>0.038272</td>\n",
       "      <td>0.049996</td>\n",
       "      <td>0.012814</td>\n",
       "      <td>-0.025244</td>\n",
       "      <td>-0.030817</td>\n",
       "      <td>-0.068128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156473</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>-0.124143</td>\n",
       "      <td>-0.129319</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>-0.046710</td>\n",
       "      <td>-0.008062</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>-0.075796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.477862</td>\n",
       "      <td>-0.018475</td>\n",
       "      <td>0.071872</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>-0.016150</td>\n",
       "      <td>-0.035783</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>-0.061627</td>\n",
       "      <td>-0.107956</td>\n",
       "      <td>-0.082812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127110</td>\n",
       "      <td>0.179423</td>\n",
       "      <td>-0.115302</td>\n",
       "      <td>0.104676</td>\n",
       "      <td>-0.107193</td>\n",
       "      <td>0.209552</td>\n",
       "      <td>0.027887</td>\n",
       "      <td>0.117224</td>\n",
       "      <td>0.104110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.465657</td>\n",
       "      <td>-0.029432</td>\n",
       "      <td>-0.029614</td>\n",
       "      <td>0.028301</td>\n",
       "      <td>0.067341</td>\n",
       "      <td>-0.131359</td>\n",
       "      <td>0.090756</td>\n",
       "      <td>-0.053325</td>\n",
       "      <td>-0.038439</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122469</td>\n",
       "      <td>-0.361710</td>\n",
       "      <td>-0.096674</td>\n",
       "      <td>0.032555</td>\n",
       "      <td>0.192928</td>\n",
       "      <td>-0.012668</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>-0.094648</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.582305 -0.091624 -0.113317  0.069735 -0.056116  0.071154 -0.146473   \n",
       "1  0.403713 -0.178570  0.066751 -0.055265 -0.010389  0.041391  0.013069   \n",
       "2  0.400374 -0.185792  0.012088 -0.067337  0.038272  0.049996  0.012814   \n",
       "3  0.477862 -0.018475  0.071872 -0.000463 -0.016150 -0.035783  0.070162   \n",
       "4  0.465657 -0.029432 -0.029614  0.028301  0.067341 -0.131359  0.090756   \n",
       "\n",
       "          8         9        10  ...        96        97        98        99  \\\n",
       "0  0.049818  0.002500  0.020655  ...  0.137189 -0.202803 -0.061708 -0.239653   \n",
       "1  0.018638 -0.047548 -0.012591  ...  0.434401  0.033208 -0.172818  0.005580   \n",
       "2 -0.025244 -0.030817 -0.068128  ...  0.156473  0.000591 -0.124143 -0.129319   \n",
       "3 -0.061627 -0.107956 -0.082812  ...  0.127110  0.179423 -0.115302  0.104676   \n",
       "4 -0.053325 -0.038439  0.009342  ...  0.122469 -0.361710 -0.096674  0.032555   \n",
       "\n",
       "        100       101       102       103       104  Label  \n",
       "0  0.033237  0.097121  0.090061 -0.064359 -0.222110      0  \n",
       "1  0.126595 -0.084699 -0.008194 -0.019724 -0.256300      0  \n",
       "2  0.004072 -0.046710 -0.008062  0.001104 -0.075796      0  \n",
       "3 -0.107193  0.209552  0.027887  0.117224  0.104110      0  \n",
       "4  0.192928 -0.012668  0.027907 -0.094648  0.170670      0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the oversampled data [194 users' oversampled data]\n",
    "import csv\n",
    "import pandas as pd\n",
    "dataset=pd.read_csv('Dataset\\OversampledVoiceData.csv',index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccqmRdmvHjnS",
    "outputId": "d0908640-58d0-446c-adf9-2510c21f85ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0     200\n",
       "1     200\n",
       "2     200\n",
       "3     200\n",
       "4     200\n",
       "     ... \n",
       "81    200\n",
       "82    200\n",
       "83    200\n",
       "84    200\n",
       "85    200\n",
       "Name: Label, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace the user ID by class name and count the number of sample in each class\n",
    "#dataset['Label'] = pd.factorize(dataset['Label'])[0]\n",
    "dataset.groupby(['Label'])['Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in training dataset: 68\n",
      "Total user in auxiliary dataset: 18\n"
     ]
    }
   ],
   "source": [
    "#seperate the profile in two groups: (i) Training profile (0-95), and (ii) auxiliary profile (96-193)\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData = dataset[dataset['Label'] < 68]\n",
    "auxilaryData = dataset[dataset['Label'] >= 68]\n",
    "print(\"Total user in training dataset:\", len(pd.unique(trainingData['Label'])))\n",
    "print(\"Total user in auxiliary dataset:\", len(pd.unique(auxilaryData['Label'])))\n",
    "#assigned 0-154 users' data to dataset\n",
    "dataset=trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in the training dataset: 68\n"
     ]
    }
   ],
   "source": [
    "#total use in the system\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData=dataset\n",
    "print(\"Total user in the training dataset:\", len(pd.unique(trainingData['Label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cJtsn1DHjnT",
    "outputId": "70c0e62b-9866-4ea9-bd5b-3f29bec22fe9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_14576\\1119477967.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  datasetRP = pd.concat([datasetRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13600, 105)\n",
      "(13600, 95)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.random_projection import SparseRandomProjection\n",
    "import numpy as np\n",
    "\n",
    "column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30', 'RPF31', 'RPF32', 'RPF33', 'RPF34', 'RPF35',\n",
    "         'RPF36', 'RPF37', 'RPF38', 'RPF39', 'RPF40', 'RPF41', 'RPF42', 'RPF43', 'RPF44', 'RPF45', 'RPF46', 'RPF47', 'RPF48', 'RPF49', 'RPF50', 'RPF51', 'RPF52',\n",
    "         'RPF53', 'RPF54', 'RPF55', 'RPF56', 'RPF57', 'RPF58', 'RPF59', 'RPF60', 'RPF61', 'RPF62', 'RPF63', 'RPF64', 'RPF65', 'RPF66', 'RPF67', 'RPF68', 'RPF69',\n",
    "         'RPF70', 'RPF71', 'RPF72', 'RPF73', 'RPF74', 'RPF75', 'RPF76', 'RPF77', 'RPF78', 'RPF79', 'RPF80', 'RPF81', 'RPF82', 'RPF83', 'RPF84', 'RPF85', 'RPF86',\n",
    "         'RPF87', 'RPF88', 'RPF89', 'RPF90', 'RPF91', 'RPF92', 'RPF93', 'RPF94','Label']\n",
    "column2=column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30', 'RPF31', 'RPF32', 'RPF33', 'RPF34', 'RPF35',\n",
    "         'RPF36', 'RPF37', 'RPF38', 'RPF39', 'RPF40', 'RPF41', 'RPF42', 'RPF43', 'RPF44', 'RPF45', 'RPF46', 'RPF47', 'RPF48', 'RPF49', 'RPF50', 'RPF51', 'RPF52',\n",
    "         'RPF53', 'RPF54', 'RPF55', 'RPF56', 'RPF57', 'RPF58', 'RPF59', 'RPF60', 'RPF61', 'RPF62', 'RPF63', 'RPF64', 'RPF65', 'RPF66', 'RPF67', 'RPF68', 'RPF69',\n",
    "         'RPF70', 'RPF71', 'RPF72', 'RPF73', 'RPF74', 'RPF75', 'RPF76', 'RPF77', 'RPF78', 'RPF79', 'RPF80', 'RPF81', 'RPF82', 'RPF83', 'RPF84', 'RPF85', 'RPF86',\n",
    "         'RPF87', 'RPF88', 'RPF89', 'RPF90', 'RPF91', 'RPF92', 'RPF93', 'RPF94']\n",
    "datasetRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,68):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = dataset[dataset['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=94, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    datasetRP = pd.concat([datasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(dataset.shape)\n",
    "print(datasetRP.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ECBMYtKIHjnV",
    "outputId": "29a04a95-5425-4d6c-ecf3-344b707d590f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in the training dataset: 68\n"
     ]
    }
   ],
   "source": [
    "#total use in the system\n",
    "totalUser= len(pd.unique(datasetRP['Label']))\n",
    "trainingData=datasetRP\n",
    "print(\"Total user in the training dataset:\", len(pd.unique(trainingData['Label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1J_SeYxDHjnW"
   },
   "outputs": [],
   "source": [
    "#Prepare the traning data for training and testing the model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X=trainingData.drop(columns=['Label'])\n",
    "y=trainingData['Label']\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "ytrain = to_categorical(ytrain)\n",
    "yval = to_categorical(yval)\n",
    "#ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgWD7LFwHjnY",
    "outputId": "18659bff-2f15-45c9-9195-4ae491f165c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10880, 94)\n",
      "(10880, 68)\n",
      "(2720, 94)\n",
      "(2720, 68)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xval.shape)\n",
    "print(yval.shape)\n",
    "#print(Xtest.shape)\n",
    "#print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mLyu5dz1Hjne"
   },
   "outputs": [],
   "source": [
    "# import all necessary package for a neural network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inlineimport keras\n",
    "from keras.layers import Dense, Dropout, Input,Activation,Dropout, Flatten\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "#from tqdm import tqdm\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "#import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bCpCz9-FHjnk"
   },
   "outputs": [],
   "source": [
    "#define optimizers for neural network\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "def adam_optimizer():\n",
    "    return Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "def RMSprop_optimizer():\n",
    "    return RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6S6V0q0gHjnm",
    "outputId": "48eb6e77-ff7c-43b7-e142-62344e6891fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,772</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)             │         \u001b[38;5;34m8,772\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,396</span> (357.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,396\u001b[0m (357.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,244</span> (352.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m90,244\u001b[0m (352.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#neural network architecture for model training\n",
    "\n",
    "def create_classifierRP(release=False,totalClass=68):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(64, input_dim=94))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.5))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(128))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.2))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.2))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(128))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.2))\n",
    "\n",
    "  #if release:\n",
    "  classifier.add(Dense(totalClass, activation='softmax'))\n",
    "  #else:\n",
    "  #   classifier.add(Dense(Tuser))\n",
    "  #np.log_softmax_v2(a, axis=axis)\n",
    "  #classifier.add(F.softmax(a, dim=1))\n",
    "\n",
    "  classifier.compile(loss='categorical_crossentropy', optimizer=RMSprop_optimizer(),metrics=['accuracy'])\n",
    "  return classifier\n",
    "\n",
    "Clasf=create_classifierRP()\n",
    "Clasf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3j2Iq78BHjnn",
    "outputId": "e0ede724-1070-42a0-a698-8c87280f3dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2506 - loss: 3.3473 - val_accuracy: 0.9926 - val_loss: 1.4822\n",
      "Epoch 2/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7660 - loss: 1.1336 - val_accuracy: 1.0000 - val_loss: 0.0363\n",
      "Epoch 3/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.5591 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 4/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8996 - loss: 0.3818 - val_accuracy: 1.0000 - val_loss: 6.7024e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9060 - loss: 0.3230 - val_accuracy: 1.0000 - val_loss: 2.5472e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.2829 - val_accuracy: 1.0000 - val_loss: 1.2293e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.2603 - val_accuracy: 1.0000 - val_loss: 8.1511e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9284 - loss: 0.2459 - val_accuracy: 1.0000 - val_loss: 5.8339e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.2238 - val_accuracy: 1.0000 - val_loss: 3.8980e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9412 - loss: 0.1979 - val_accuracy: 1.0000 - val_loss: 2.9497e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.2093 - val_accuracy: 1.0000 - val_loss: 2.2767e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.1812 - val_accuracy: 1.0000 - val_loss: 1.7171e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9481 - loss: 0.1759 - val_accuracy: 1.0000 - val_loss: 1.1029e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9502 - loss: 0.1639 - val_accuracy: 1.0000 - val_loss: 9.0211e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9471 - loss: 0.1676 - val_accuracy: 1.0000 - val_loss: 1.0094e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9502 - loss: 0.1664 - val_accuracy: 1.0000 - val_loss: 8.4049e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9581 - loss: 0.1479 - val_accuracy: 1.0000 - val_loss: 6.3052e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.1509 - val_accuracy: 1.0000 - val_loss: 6.7266e-06\n",
      "Epoch 19/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9562 - loss: 0.1540 - val_accuracy: 1.0000 - val_loss: 5.2564e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9556 - loss: 0.1524 - val_accuracy: 1.0000 - val_loss: 4.9454e-06\n"
     ]
    }
   ],
   "source": [
    "#Train the classifier seperately for black-box attack\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5,min_lr=0.0001)\n",
    "callbacks_list = [learning_rate_reduction]\n",
    "\n",
    "Classfier2= create_classifierRP(True,68)\n",
    "\n",
    "#------Comment will start from here\n",
    "lossc='categorical_crossentropy'\n",
    "optimizerc=RMSprop(learning_rate=0.001, rho=0.9)\n",
    "Classfier2.compile(loss=lossc, optimizer=optimizerc,metrics=['accuracy'])\n",
    "#------Comments will end from here\n",
    "historyc2 =  Classfier2.fit(Xtrain, ytrain, batch_size=64, epochs=20, validation_data=(Xval, yval),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "Qep4iQmGHjno",
    "outputId": "b71ab71e-f625-4f04-dd68-7f6dac920965"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the classifier loss and accuracy curves for training and validation data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(historyc2.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(historyc2.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the test data and seperate test data\n",
    "import csv\n",
    "import pandas as pd\n",
    "testdataset=pd.read_csv('Dataset/VoiceDatatest.csv',index_col=0)\n",
    "testdataset = testdataset[testdataset['Label'] < 68]\n",
    "#testdataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_14576\\4242769688.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  testdatasetRP = pd.concat([testdatasetRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1639, 105)\n",
      "(1639, 95)\n"
     ]
    }
   ],
   "source": [
    "#random project the test data by using same random matrix\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30', 'RPF31', 'RPF32', 'RPF33', 'RPF34', 'RPF35',\n",
    "         'RPF36', 'RPF37', 'RPF38', 'RPF39', 'RPF40', 'RPF41', 'RPF42', 'RPF43', 'RPF44', 'RPF45', 'RPF46', 'RPF47', 'RPF48', 'RPF49', 'RPF50', 'RPF51', 'RPF52',\n",
    "         'RPF53', 'RPF54', 'RPF55', 'RPF56', 'RPF57', 'RPF58', 'RPF59', 'RPF60', 'RPF61', 'RPF62', 'RPF63', 'RPF64', 'RPF65', 'RPF66', 'RPF67', 'RPF68', 'RPF69',\n",
    "         'RPF70', 'RPF71', 'RPF72', 'RPF73', 'RPF74', 'RPF75', 'RPF76', 'RPF77', 'RPF78', 'RPF79', 'RPF80', 'RPF81', 'RPF82', 'RPF83', 'RPF84', 'RPF85', 'RPF86',\n",
    "         'RPF87', 'RPF88', 'RPF89', 'RPF90', 'RPF91', 'RPF92', 'RPF93', 'RPF94','Label']\n",
    "column2=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30', 'RPF31', 'RPF32', 'RPF33', 'RPF34', 'RPF35',\n",
    "         'RPF36', 'RPF37', 'RPF38', 'RPF39', 'RPF40', 'RPF41', 'RPF42', 'RPF43', 'RPF44', 'RPF45', 'RPF46', 'RPF47', 'RPF48', 'RPF49', 'RPF50', 'RPF51', 'RPF52',\n",
    "         'RPF53', 'RPF54', 'RPF55', 'RPF56', 'RPF57', 'RPF58', 'RPF59', 'RPF60', 'RPF61', 'RPF62', 'RPF63', 'RPF64', 'RPF65', 'RPF66', 'RPF67', 'RPF68', 'RPF69',\n",
    "         'RPF70', 'RPF71', 'RPF72', 'RPF73', 'RPF74', 'RPF75', 'RPF76', 'RPF77', 'RPF78', 'RPF79', 'RPF80', 'RPF81', 'RPF82', 'RPF83', 'RPF84', 'RPF85', 'RPF86',\n",
    "         'RPF87', 'RPF88', 'RPF89', 'RPF90', 'RPF91', 'RPF92', 'RPF93', 'RPF94']\n",
    "testdatasetRP = pd.DataFrame(columns=column1)\n",
    "\n",
    "for seed in range(0,68):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = testdataset[testdataset['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=94, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    testdatasetRP = pd.concat([testdatasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(testdataset.shape)\n",
    "print(testdatasetRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=testdatasetRP.drop(columns=['Label'])\n",
    "ytest=testdatasetRP['Label']\n",
    "ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUEGiCjYHjnp",
    "outputId": "9b78d300-5f85-466b-bb0f-fca7065a247f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6945e-06 \n",
      "Loss: 5.123931259731762e-06\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
