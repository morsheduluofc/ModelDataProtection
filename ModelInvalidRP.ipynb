{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F57</th>\n",
       "      <th>F58</th>\n",
       "      <th>F59</th>\n",
       "      <th>F60</th>\n",
       "      <th>F61</th>\n",
       "      <th>F62</th>\n",
       "      <th>F63</th>\n",
       "      <th>F64</th>\n",
       "      <th>F65</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.043</td>\n",
       "      <td>A3MC5OA9RXOOFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.043</td>\n",
       "      <td>A3MC5OA9RXOOFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.060</td>\n",
       "      <td>A3MC5OA9RXOOFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.060</td>\n",
       "      <td>A3MC5OA9RXOOFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.010</td>\n",
       "      <td>A3MC5OA9RXOOFH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      F1     F2     F3     F4     F5     F6     F7     F8     F9    F10  ...  \\\n",
       "0  0.041  0.026  0.016  0.018  0.060  0.080  0.052  0.049  0.029  0.021  ...   \n",
       "1  0.041  0.026  0.016  0.018  0.060  0.080  0.052  0.049  0.029  0.021  ...   \n",
       "2  0.040  0.027  0.118  0.068  0.052  0.010  0.021  0.013  0.046  0.064  ...   \n",
       "3  0.040  0.027  0.118  0.068  0.052  0.010  0.021  0.013  0.046  0.064  ...   \n",
       "4  0.021  0.011  0.006  0.011  0.044  0.022  0.011  0.048  0.047  0.080  ...   \n",
       "\n",
       "     F57    F58    F59    F60    F61    F62  F63    F64    F65              ID  \n",
       "0  0.697  0.698  0.698  0.694  0.056  0.039  0.0  0.009  0.043  A3MC5OA9RXOOFH  \n",
       "1  0.697  0.698  0.698  0.694  0.056  0.039  0.0  0.009  0.043  A3MC5OA9RXOOFH  \n",
       "2  0.677  0.677  0.684  0.684  0.105  0.031  0.0  0.008  0.060  A3MC5OA9RXOOFH  \n",
       "3  0.677  0.677  0.684  0.684  0.105  0.031  0.0  0.008  0.060  A3MC5OA9RXOOFH  \n",
       "4  0.667  0.667  0.672  0.677  0.067  0.020  1.0  0.014  0.010  A3MC5OA9RXOOFH  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read all data [194 users' oversampled data]\n",
    "import csv\n",
    "import pandas as pd\n",
    "dataset=pd.read_csv('dataset/AllOversampledNData.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "0      1000\n",
       "1      1000\n",
       "2      1000\n",
       "3      1000\n",
       "4      1000\n",
       "       ... \n",
       "188    1000\n",
       "189    1000\n",
       "190    1000\n",
       "191    1000\n",
       "192    1000\n",
       "Name: ID, Length: 193, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace the user ID by class name and count the number of sample in each class\n",
    "dataset['ID'] = pd.factorize(dataset['ID'])[0]\n",
    "dataset.groupby(['ID'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in training dataset: 96\n",
      "Total user in auxiliary dataset: 97\n"
     ]
    }
   ],
   "source": [
    "#seperate the profile in two groups: (i) Training profile (0-95), and (ii) auxiliary profile (96-193)\n",
    "totalUser= len(pd.unique(dataset['ID']))\n",
    "trainingData = dataset[dataset['ID'] < int(totalUser/2)]\n",
    "auxilaryData = dataset[dataset['ID'] >= int(totalUser/2)]\n",
    "print(\"Total user in training dataset:\", len(pd.unique(trainingData['ID'])))\n",
    "print(\"Total user in auxiliary dataset:\", len(pd.unique(auxilaryData['ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "0     827\n",
       "1     792\n",
       "2     775\n",
       "3     793\n",
       "4     811\n",
       "     ... \n",
       "91    812\n",
       "92    801\n",
       "93    813\n",
       "94    798\n",
       "95    783\n",
       "Name: ID, Length: 96, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare the traning data for training and testing the model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Xtrain, Xtest= train_test_split(trainingData, test_size=0.2, random_state=22)\n",
    "Xtrain.groupby(['ID'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78399, 66)\n",
      "(78399, 57)\n"
     ]
    }
   ],
   "source": [
    "#random project the training data\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','ID']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "trainDatasetRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,96):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = Xtrain[Xtrain['ID']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['ID'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['ID']=seed\n",
    "    trainDatasetRP = pd.concat([trainDatasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(Xtrain.shape)\n",
    "print(trainDatasetRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19600, 66)\n",
      "(19600, 57)\n"
     ]
    }
   ],
   "source": [
    "#random project the test data\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','ID']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "testDatasetRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,96):\n",
    "    rng = np.random.RandomState(seed+1)\n",
    "    X = Xtest[Xtest['ID']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['ID'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['ID']=seed\n",
    "    testDatasetRP = pd.concat([testDatasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(Xtest.shape)\n",
    "print(testDatasetRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the traning data for training and testing the model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X=trainDatasetRP.drop(columns=['ID'])\n",
    "y=trainDatasetRP['ID']\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "Xtest=testDatasetRP.drop(columns=['ID'])\n",
    "ytest=testDatasetRP['ID']\n",
    "\n",
    "ytrain = to_categorical(ytrain)\n",
    "yval = to_categorical(yval)\n",
    "ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62719, 56)\n",
      "(62719, 96)\n",
      "(15680, 56)\n",
      "(15680, 96)\n",
      "(19600, 56)\n",
      "(19600, 96)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xval.shape)\n",
    "print(yval.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary package for a neural network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inlineimport keras\n",
    "from keras.layers import Dense, Dropout, Input,Activation,Dropout, Flatten\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "#from tqdm import tqdm\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "#import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizers for neural network\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "def adam_optimizer():\n",
    "    return Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "def RMSprop_optimizer():\n",
    "    return RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               7296      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,370\n",
      "Trainable params: 141,834\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mdmor\\PythonProjects\\ModelInversion\\.venv\\Lib\\site-packages\\keras\\optimizers\\legacy\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#neural network architecture for model training\n",
    "\n",
    "def create_classifierRP(release=False,totalClass=10):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(128, input_dim=56))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(128))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "\n",
    "  #if release:\n",
    "  classifier.add(Dense(totalClass, activation='softmax'))\n",
    "  #else:\n",
    "  #   classifier.add(Dense(Tuser))\n",
    "  #np.log_softmax_v2(a, axis=axis)\n",
    "  #classifier.add(F.softmax(a, dim=1))\n",
    "\n",
    "  classifier.compile(loss='categorical_crossentropy', optimizer=RMSprop_optimizer(),metrics=['accuracy'])\n",
    "  return classifier\n",
    "\n",
    "Clasf=create_classifierRP()\n",
    "Clasf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "967/980 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9945WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 4ms/step - loss: 0.0672 - accuracy: 0.9946 - val_loss: 5.4739e-10 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "969/980 [============================>.] - ETA: 0s - loss: 2.5010e-08 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 4s 4ms/step - loss: 2.4882e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "969/980 [============================>.] - ETA: 0s - loss: 1.0584e-08 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 4s 4ms/step - loss: 1.0640e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 5.8876e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 6s 6ms/step - loss: 5.8921e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 4.2480e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 9s 9ms/step - loss: 4.2480e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 3.1469e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 10s 10ms/step - loss: 3.1475e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 2.8244e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 15s 15ms/step - loss: 2.8244e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 4.2233e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 17s 18ms/step - loss: 4.2233e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 2.5419e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 18s 19ms/step - loss: 2.5545e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 2.3074e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 18s 19ms/step - loss: 2.3074e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 2.4905e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 12s 12ms/step - loss: 2.4899e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 2.1298e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 14s 15ms/step - loss: 2.1307e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 2.3283e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 12s 12ms/step - loss: 2.3245e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 2.4943e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 10s 10ms/step - loss: 2.5336e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 2.6470e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 14ms/step - loss: 2.6401e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 2.6446e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 14ms/step - loss: 2.6458e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 2.5260e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 14s 14ms/step - loss: 2.5260e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 2.4829e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 15s 15ms/step - loss: 2.4804e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 2.5795e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 16s 16ms/step - loss: 2.5830e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 2.3845e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 14s 14ms/step - loss: 2.3835e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 2.8063e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 15s 15ms/step - loss: 2.8035e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 2.4797e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 12s 12ms/step - loss: 2.4747e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 2.4443e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 2.4443e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 2.2812e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 15s 16ms/step - loss: 2.2789e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 2.4008e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 15s 16ms/step - loss: 2.4006e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 2.3973e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 14ms/step - loss: 2.4025e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 2.2656e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 14s 14ms/step - loss: 2.2656e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 2.1369e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 14s 14ms/step - loss: 2.1459e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 2.3069e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 14ms/step - loss: 2.3036e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 2.0813e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 12s 13ms/step - loss: 2.0813e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 1.8057e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 14ms/step - loss: 1.8057e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 1.7142e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 14ms/step - loss: 1.7125e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 1.5993e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 14s 14ms/step - loss: 1.6232e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 2.1423e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 12s 12ms/step - loss: 2.1440e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 2.4772e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 12s 12ms/step - loss: 2.4747e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "975/980 [============================>.] - ETA: 0s - loss: 1.8111e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.8114e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 1.6251e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.6251e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 1.4600e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 12s 12ms/step - loss: 1.4578e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 1.4909e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 11s 12ms/step - loss: 1.4863e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 1.5544e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.5529e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 1.6415e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 18s 18ms/step - loss: 1.6384e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 1.4932e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 15s 16ms/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 1.3684e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 14s 15ms/step - loss: 1.3856e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 1.8265e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 14s 15ms/step - loss: 1.8247e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 1.4882e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 16s 16ms/step - loss: 1.4882e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 1.5293e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 15s 16ms/step - loss: 1.5263e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 1.3269e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.3286e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 1.2043e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 12s 13ms/step - loss: 1.2031e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 1.1756e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 12s 13ms/step - loss: 1.1917e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 1.5458e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 11s 11ms/step - loss: 1.5396e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "#Train the classifier seperately for black-box attack\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5,min_lr=0.0001)\n",
    "callbacks_list = [learning_rate_reduction]\n",
    "\n",
    "Classfier2= create_classifierRP(True,96)\n",
    "\n",
    "#------Comment will start from here\n",
    "lossc='categorical_crossentropy'\n",
    "optimizerc=RMSprop(lr=0.001, rho=0.9)\n",
    "Classfier2.compile(loss=lossc, optimizer=optimizerc,metrics=['accuracy'])\n",
    "#------Comments will end from here\n",
    "historyc2 =  Classfier2.fit(Xtrain, ytrain, batch_size=64, epochs=50, validation_data=(Xval, yval),verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the classifier loss and accuracy curves for training and validation data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(historyc2.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(historyc2.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 1s 1ms/step - loss: 23.9289 - accuracy: 0.0076\n",
      "Loss: 23.92890739440918\n",
      "Accuracy: 0.007602040655910969\n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
