{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Info: Estimate the verification accuracy of DAC for project data\n",
    "- Used DAC(RP projected) data to train an NN model\n",
    "- There are 193 different user's profiles and each profiles has 1000 data samples (normalized data)\n",
    "- Devide all profiles in two groups: training  profile (96) and auxilary profiles (96) \n",
    "- Each auxilary data semple has 65 different features and RP prjection moved them to 56 features\n",
    "- Random matrix of RP follow following distributions: Pr(x=+1)= 1/2s; Pr(x=-1)= 1/2s, Pr(x=0)= 1-1/s where s=3\n",
    "- The value of dimension reduction k is calculated by k= [(4+2\\beta)/(\\epsolon^2/2+\\epsolon^3/2)]log (n) where n is total sample in a profile and \\epsolon,\\beta>0\n",
    "- Construct a NN regressor has 4 dense layers along with 'BatchNormalization' and 'relu' activation funcation\n",
    "- Last layer is sigmoid function. Input dimension of model is 65 and output dimension 56.\n",
    "- Trained regressor to recover the plain data from the projected data for the 96 auxilary data classes\n",
    "- This traind regressor will be used to recove the training data of classifer.\n",
    "- Let say attacker has the access of RP data of original data and their corresponding label. Attacker can find it by model inversion attack\n",
    "\n",
    "- Included a summary of the NN architecture\n",
    "- Need shallow as RP make users profile more distinct\n",
    "- For 10 rounds of training training accurach reached to 100.0% and validation accuracy reached to 100.0%\n",
    "- Included a graph that shows change of training and validation acccruacy in different ephocs\n",
    "- Test accruacy 100.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.251082</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.366255</td>\n",
       "      <td>0.323770</td>\n",
       "      <td>0.065844</td>\n",
       "      <td>0.020243</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>0.060729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732435</td>\n",
       "      <td>0.736285</td>\n",
       "      <td>0.734870</td>\n",
       "      <td>0.707042</td>\n",
       "      <td>0.131098</td>\n",
       "      <td>0.196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.069264</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>0.198381</td>\n",
       "      <td>0.116466</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670837</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>0.670509</td>\n",
       "      <td>0.651643</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.234973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.162602</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.510823</td>\n",
       "      <td>0.280992</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.184739</td>\n",
       "      <td>0.259109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651588</td>\n",
       "      <td>0.651588</td>\n",
       "      <td>0.657061</td>\n",
       "      <td>0.642254</td>\n",
       "      <td>0.320122</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>0.045267</td>\n",
       "      <td>0.194332</td>\n",
       "      <td>0.188755</td>\n",
       "      <td>0.323887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641963</td>\n",
       "      <td>0.641963</td>\n",
       "      <td>0.645533</td>\n",
       "      <td>0.635681</td>\n",
       "      <td>0.204268</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.054645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.378601</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>0.600823</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.465863</td>\n",
       "      <td>0.477733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727623</td>\n",
       "      <td>0.732435</td>\n",
       "      <td>0.731028</td>\n",
       "      <td>0.694836</td>\n",
       "      <td>0.173780</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.178862  0.316667  0.251082  0.144628  0.366255  0.323770  0.065844   \n",
       "1  0.166667  0.108333  0.069264  0.074380  0.246914  0.327869  0.213992   \n",
       "2  0.162602  0.112500  0.510823  0.280992  0.213992  0.040984  0.086420   \n",
       "3  0.085366  0.045833  0.025974  0.045455  0.181070  0.090164  0.045267   \n",
       "4  0.512195  0.295833  0.220779  0.247934  0.378601  0.069672  0.600823   \n",
       "\n",
       "          8         9        10  ...        57        58        59        60  \\\n",
       "0  0.020243  0.032129  0.060729  ...  0.732435  0.736285  0.734870  0.707042   \n",
       "1  0.198381  0.116466  0.085020  ...  0.670837  0.671800  0.670509  0.651643   \n",
       "2  0.052632  0.184739  0.259109  ...  0.651588  0.651588  0.657061  0.642254   \n",
       "3  0.194332  0.188755  0.323887  ...  0.641963  0.641963  0.645533  0.635681   \n",
       "4  0.785425  0.465863  0.477733  ...  0.727623  0.732435  0.731028  0.694836   \n",
       "\n",
       "         61     62   63        64        65  Label  \n",
       "0  0.131098  0.196  1.0  0.279070  0.016393      0  \n",
       "1  0.170732  0.156  0.0  0.209302  0.234973      0  \n",
       "2  0.320122  0.124  0.0  0.186047  0.327869      0  \n",
       "3  0.204268  0.080  1.0  0.325581  0.054645      0  \n",
       "4  0.173780  0.504  0.0  0.255814  0.245902      0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read all data [194 users' oversampled data]\n",
    "import csv\n",
    "import pandas as pd\n",
    "dataset=pd.read_csv('Dataset/OversampledDACData.csv',index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0      300\n",
       "1      300\n",
       "2      300\n",
       "3      300\n",
       "4      300\n",
       "      ... \n",
       "188    300\n",
       "189    300\n",
       "190    300\n",
       "191    300\n",
       "192    300\n",
       "Name: Label, Length: 193, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace the user ID by class name and count the number of sample in each class\n",
    "#dataset['Label'] = pd.factorize(dataset['Label'])[0]\n",
    "dataset.groupby(['Label'])['Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in training dataset: 155\n",
      "Total user in auxiliary dataset: 38\n"
     ]
    }
   ],
   "source": [
    "#seperate the profile in two groups: (i) Training profile (0-95), and (ii) auxiliary profile (96-193)\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData = dataset[dataset['Label'] < 155]\n",
    "attackData = dataset[dataset['Label'] >= 155]\n",
    "print(\"Total user in training dataset:\", len(pd.unique(trainingData['Label'])))\n",
    "print(\"Total user in auxiliary dataset:\", len(pd.unique(attackData['Label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1          1.000000\n",
      "2          1.000000\n",
      "3          0.991342\n",
      "4          1.000000\n",
      "5          0.967078\n",
      "            ...    \n",
      "62         1.000000\n",
      "63         1.000000\n",
      "64         1.000000\n",
      "65         0.874317\n",
      "Label    154.000000\n",
      "Length: 66, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#value range of training data\n",
    "print(trainingData.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When attacker only knows the distribution of R, attacker will train the attack model by the reandom projected attack data that are train by random generated RP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_22432\\4128647647.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  attackDataRP = pd.concat([attackDataRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11400, 66)\n",
      "(11400, 57)\n"
     ]
    }
   ],
   "source": [
    "#Random project the auxiliary dataset\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','Label']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "attackDataRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(155,193):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = attackData[attackData['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    attackDataRP = pd.concat([attackDataRP, XRP], ignore_index=True)\n",
    "    #print(auxilaryDataRP)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(attackData.shape)\n",
    "print(attackDataRP.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        155.0\n",
      "1        155.0\n",
      "2        155.0\n",
      "3        155.0\n",
      "4        155.0\n",
      "         ...  \n",
      "11395    192.0\n",
      "11396    192.0\n",
      "11397    192.0\n",
      "11398    192.0\n",
      "11399    192.0\n",
      "Name: Label, Length: 11400, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#user id in auxilary data\n",
    "print(attackDataRP['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the traning data for training and testing the attacker's model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Xdata=attackData.drop(columns=['Label'])\n",
    "XRPdata=attackDataRP.drop(columns=['Label'])\n",
    "\n",
    "\n",
    "Xtrain, Xval, XRPtrain, XRPval = train_test_split(Xdata, XRPdata, test_size=0.2, random_state=22)\n",
    "#Xtrain, Xval, XRPtrain, XRPval = train_test_split(Xtrain, XRPtrain, test_size=0.3, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9120, 65)\n",
      "(9120, 56)\n",
      "(2280, 65)\n",
      "(2280, 56)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(XRPtrain.shape)\n",
    "#print(Xtest.shape)\n",
    "#print(XRPtest.shape)\n",
    "print(Xval.shape)\n",
    "print(XRPval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary package for a neural network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inlineimport keras\n",
    "from keras.layers import Dense, Dropout, Input,Activation,Dropout, Flatten\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "#from tqdm import tqdm\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "#import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizers for neural network\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "def adam_optimizer():\n",
    "    return Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "def RMSprop_optimizer():\n",
    "    return RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,385</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m7,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)             │         \u001b[38;5;34m8,385\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150,465</span> (587.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m150,465\u001b[0m (587.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,929</span> (581.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m148,929\u001b[0m (581.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#neural network architecture for training a regressor\n",
    "\n",
    "def create_Regressor(release=False,outDim=65):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(128, input_dim=56))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  #classifier.add(Dropout(0.2))\n",
    "   \n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  #classifier.add(Dropout(0.2))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  #classifier.add(Dropout(0.2))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(128))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  #classifier.add(Dropout(0.2))\n",
    "\n",
    "  #if release:\n",
    "  classifier.add(Dense(outDim, activation='sigmoid'))\n",
    "  #else:\n",
    "  #   classifier.add(Dense(Tuser))\n",
    "  #np.log_softmax_v2(a, axis=axis)\n",
    "  #classifier.add(F.softmax(a, dim=1))\n",
    "\n",
    "  classifier.compile(loss='mean_squared_error', optimizer='SGD',metrics=['mean_squared_error'])\n",
    "  return classifier\n",
    "\n",
    "Clasf=create_Regressor()\n",
    "Clasf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0502 - mean_squared_error: 0.0502 - val_loss: 0.0288 - val_mean_squared_error: 0.0288\n",
      "Epoch 2/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 3/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 4/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 5/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 6/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 7/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 8/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 9/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 10/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n"
     ]
    }
   ],
   "source": [
    "#Train the regressor  by auxilary dataset\n",
    "# Input: Projected data\n",
    "# Output: Plain data\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5,min_lr=0.0001)\n",
    "callbacks_list = [learning_rate_reduction]\n",
    "\n",
    "Regressor= create_Regressor(True,65)\n",
    "\n",
    "#------Comment will start from here\n",
    "lossc='mean_squared_error'\n",
    "optimizerc=RMSprop(learning_rate=0.001, rho=0.9)\n",
    "Regressor.compile(loss=lossc, optimizer=optimizerc,metrics=['mean_squared_error'])\n",
    "#------Comments will end from here\n",
    "Rhistoryc2 =  Regressor.fit(XRPtrain, Xtrain, batch_size=64, epochs=10, validation_data=(XRPval, Xval),verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model by pre-seperated data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the test data and seperate test data\n",
    "import csv\n",
    "import pandas as pd\n",
    "testattackdata=pd.read_csv('Dataset/DACDatatest.csv',index_col=0)\n",
    "testattackdata = testattackdata[testattackdata['Label'] >= 155]\n",
    "#testdataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_22432\\233514233.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  testattackDataRP = pd.concat([testattackDataRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1003, 66)\n",
      "(1003, 57)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','Label']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "\n",
    "\n",
    "testattackDataRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(155,193):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = testattackdata[testattackdata['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    testattackDataRP = pd.concat([testattackDataRP, XRP], ignore_index=True)\n",
    "    #print(auxilaryDataRP)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(testattackdata.shape)\n",
    "print(testattackDataRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testattackdata=testattackdata.drop(columns=['Label'])\n",
    "testattackDataRP=testattackDataRP.drop(columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0752 - mean_squared_error: 0.0752\n",
      "Loss: 0.07463707774877548\n",
      "Accuracy: 0.07463707774877548\n"
     ]
    }
   ],
   "source": [
    "#Performance of the trained attacker regressor\n",
    "loss, accuracy = Regressor.evaluate(testattackDataRP, testattackdata)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let say attacker has the access of Random projected data of the original data profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_22432\\470342661.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  trainingDataRP = pd.concat([trainingDataRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46540, 66)\n",
      "(46540, 57)\n"
     ]
    }
   ],
   "source": [
    "#RP of original trained data. Let say attacker has the access of RP data of original data\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','ID']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "trainingDataRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,155):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = trainingData[trainingData['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    trainingDataRP = pd.concat([trainingDataRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(trainingData.shape)\n",
    "print(trainingDataRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0.0\n",
      "1          0.0\n",
      "2          0.0\n",
      "3          0.0\n",
      "4          0.0\n",
      "         ...  \n",
      "46535    154.0\n",
      "46536    154.0\n",
      "46537    154.0\n",
      "46538    154.0\n",
      "46539    154.0\n",
      "Name: Label, Length: 46540, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#user id in original projected data\n",
    "print(trainingDataRP['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1455/1455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "(46540, 65)\n"
     ]
    }
   ],
   "source": [
    "#Prediction of plain data by the attacker mdoel assuming that attacker has access of projected data\n",
    "tDataRP=trainingDataRP.drop(columns=['Label'])\n",
    "tDataReg= Regressor.predict(tDataRP)\n",
    "print(tDataReg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#assume that along with project data attacker know the label of the data.\n",
    "# Add id with recovered data\n",
    "print(type(tDataReg))\n",
    "print(type(trainingDataRP['Label'].to_numpy()))\n",
    "traningdataReg = pd.concat([pd.DataFrame(tDataReg), trainingDataRP['Label'].to_frame()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46540, 66)\n"
     ]
    }
   ],
   "source": [
    "# recovered data by the attacker model from projected data\n",
    "print(traningdataReg.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To test the qulity of recover data we did this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1         2         3         4         5         6         7  \\\n",
      "0      0.507760  0.448571  0.312789  0.394282  0.349583  0.281651  0.440891   \n",
      "1      0.327379  0.314067  0.207835  0.294800  0.225650  0.225861  0.465205   \n",
      "2      0.321946  0.277095  0.312769  0.305615  0.200325  0.204391  0.420286   \n",
      "3      0.259044  0.289822  0.181204  0.262085  0.149847  0.172233  0.238121   \n",
      "4      0.338742  0.328639  0.273115  0.266288  0.194453  0.256723  0.401408   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "46535  0.318575  0.278306  0.223269  0.224521  0.090585  0.382490  0.144079   \n",
      "46536  0.242274  0.275417  0.235705  0.242678  0.121126  0.378494  0.152654   \n",
      "46537  0.242439  0.296302  0.284998  0.229829  0.108278  0.336655  0.186163   \n",
      "46538  0.294658  0.232413  0.177092  0.184336  0.093163  0.313628  0.128370   \n",
      "46539  0.243811  0.191714  0.156988  0.176426  0.061750  0.261868  0.105030   \n",
      "\n",
      "              8         9        10  ...        57        58        59  \\\n",
      "0      0.369247  0.286726  0.288550  ...  0.534283  0.394722  0.302753   \n",
      "1      0.298853  0.347921  0.234328  ...  0.473224  0.268100  0.380233   \n",
      "2      0.294057  0.247381  0.289238  ...  0.418154  0.233945  0.250144   \n",
      "3      0.164054  0.173331  0.148690  ...  0.436697  0.249558  0.217300   \n",
      "4      0.371302  0.283493  0.226620  ...  0.428542  0.310359  0.266820   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "46535  0.124762  0.089708  0.134397  ...  0.167232  0.330399  0.345797   \n",
      "46536  0.105985  0.134385  0.193674  ...  0.220923  0.270406  0.364597   \n",
      "46537  0.101302  0.131422  0.190217  ...  0.258141  0.344004  0.387426   \n",
      "46538  0.105756  0.076375  0.104779  ...  0.199422  0.310804  0.337762   \n",
      "46539  0.071307  0.058237  0.078150  ...  0.167726  0.255358  0.282018   \n",
      "\n",
      "             60        61        62        63        64        65  Label  \n",
      "0      0.191890  0.290741  0.521875  0.830031  0.208198  0.266522    0.0  \n",
      "1      0.262022  0.307076  0.520319  0.375394  0.345129  0.295851    0.0  \n",
      "2      0.199138  0.236403  0.484716  0.491540  0.334920  0.231748    0.0  \n",
      "3      0.170826  0.236643  0.350205  0.814344  0.225464  0.201817    0.0  \n",
      "4      0.233735  0.407736  0.455038  0.677521  0.471063  0.270247    0.0  \n",
      "...         ...       ...       ...       ...       ...       ...    ...  \n",
      "46535  0.141590  0.349005  0.437481  0.358746  0.395353  0.144524  154.0  \n",
      "46536  0.191340  0.260997  0.211221  0.867002  0.383374  0.128198  154.0  \n",
      "46537  0.201382  0.316026  0.163797  0.916663  0.381089  0.133104  154.0  \n",
      "46538  0.146825  0.252306  0.443794  0.329341  0.351800  0.105129  154.0  \n",
      "46539  0.128465  0.242874  0.406988  0.409731  0.308449  0.079261  154.0  \n",
      "\n",
      "[46540 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "traningdataReg.columns=list(trainingData.columns)\n",
    "print(traningdataReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "allPvalue=np.zeros((155,193))\n",
    "for id in range(0,155):\n",
    "    dataset1=traningdataReg[traningdataReg['Label']==id]\n",
    "    dataset2=trainingData[trainingData['Label']==id]\n",
    "    for col in range (0,65):\n",
    "        sample1=dataset1.iloc[:,col]\n",
    "        sample2=dataset2.iloc[:,col]\n",
    "        statistics, allPvalue[id,col]=stats.kstest(sample1, sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.28239769e-079 7.29126583e-088 6.81359615e-039 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [2.20242298e-038 1.74556464e-024 1.16263721e-018 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [2.51496787e-018 1.40833051e-074 2.87676532e-010 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " ...\n",
      " [9.20636237e-061 1.67098241e-071 1.48641150e-078 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [8.66702156e-068 3.16051840e-094 4.46166537e-150 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [1.86743629e-091 6.47616112e-065 1.66202465e-055 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "print(allPvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "allPvalue = np.where(allPvalue < 0.05, 0, 1)\n",
    "#allPvalue[allPvalue < 0.05] = 0\n",
    "print(allPvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(allPvalue, axis=1))\n",
    "print(len(allPvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data=np.sum(allPvalue, axis=1)\n",
    "data=data[0:100]\n",
    "index=[i for i in range (1,len(data)+1)]\n",
    "plt.bar(index, data)\n",
    "plt.xlabel('user id')\n",
    "plt.ylabel('percentage')\n",
    "#plt.title('Total features in a profile (out of 65 features) that passed the similarity test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97999, 66)\n",
      "(97999, 57)\n"
     ]
    }
   ],
   "source": [
    "#Random project the recover data to impersonate the user. Used different seed\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "#traningdataReg = pd.concat([tDataReg, trainingDataRP['ID']], axis=1)\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','ID']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "traningdataReg.columns=dataset.columns\n",
    "trainingDataRPReg = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,96):\n",
    "    rng = np.random.RandomState(seed+10)\n",
    "    X = traningdataReg[traningdataReg['ID']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['ID'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['ID']=seed\n",
    "    trainingDataRPReg = pd.concat([trainingDataRPReg, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(traningdataReg.shape)\n",
    "print(trainingDataRPReg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in test dataset: 96\n"
     ]
    }
   ],
   "source": [
    "print(\"Total user in test dataset:\", len(pd.unique(trainingDataRPReg['ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3063/3063 [==============================] - 4s 1ms/step - loss: 19.9066 - accuracy: 0.0000e+00\n",
      "Loss: 19.906648635864258\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Performance of the attacker by using the random projected recover data\n",
    "#UserModel.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "Xtest=trainingDataRPReg.drop(columns=['ID'])\n",
    "ytest=trainingDataRPReg['ID']\n",
    "ytest=to_categorical(ytest)\n",
    "loss, accuracy = TrainedClassifier.evaluate(Xtest,ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97999, 66)\n",
      "(97999, 57)\n"
     ]
    }
   ],
   "source": [
    "#Random project the recover data to impersonate the user. If the attacker know the key\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "#traningdataReg = pd.concat([tDataReg, trainingDataRP['ID']], axis=1)\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','ID']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "traningdataReg.columns=dataset.columns\n",
    "trainingDataRPReg = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,96):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = traningdataReg[traningdataReg['ID']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['ID'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['ID']=seed\n",
    "    trainingDataRPReg = pd.concat([trainingDataRPReg, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(traningdataReg.shape)\n",
    "print(trainingDataRPReg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3063/3063 [==============================] - 4s 1ms/step - loss: 0.1201 - accuracy: 0.9698\n",
      "Loss: 0.12010253220796585\n",
      "Accuracy: 0.969836413860321\n"
     ]
    }
   ],
   "source": [
    "#Performance of the attacker by using the random projected recover data when key is known\n",
    "#UserModel.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "Xtest=trainingDataRPReg.drop(columns=['ID'])\n",
    "ytest=trainingDataRPReg['ID']\n",
    "ytest=to_categorical(ytest)\n",
    "loss, accuracy = TrainedClassifier.evaluate(Xtest,ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
