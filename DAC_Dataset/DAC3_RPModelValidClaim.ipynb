{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Info: Estimate the verification accuracy of DAC for project data\n",
    "- Used DAC (RP projected) data to train an NN model\n",
    "- There are 193 different user's profiles and each profiles has 1000 data samples (normalized data)\n",
    "- Each data semple has 65 different features and RP prjection moved them to 56 features\n",
    "- Random matrix of RP follow following distributions: Pr(x=+1)= 1/2s; Pr(x=-1)= 1/2s, Pr(x=0)= 1-1/s where s=3\n",
    "- The value of dimension reduction k is calculated by k= [(4+2\\beta)/(\\epsolon^2/2+\\epsolon^3/2)]log (n) where n is total sample in a profile and \\epsolon,\\beta>0\n",
    "- NN has 2 dense layers along with 'BatchNormalization' and 'relu' activation funcation\n",
    "- Last layer is softmax function (193 classes)\n",
    "- Included a summary of the NN architecture\n",
    "- Need shallow as RP make users profile more distinct\n",
    "- For 10 rounds of training training accurach reached to 100.0% and validation accuracy reached to 100.0%\n",
    "- Included a graph that shows change of training and validation acccruacy in different ephocs\n",
    "- Test accruacy 100.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.251082</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.366255</td>\n",
       "      <td>0.323770</td>\n",
       "      <td>0.065844</td>\n",
       "      <td>0.020243</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>0.060729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732435</td>\n",
       "      <td>0.736285</td>\n",
       "      <td>0.734870</td>\n",
       "      <td>0.707042</td>\n",
       "      <td>0.131098</td>\n",
       "      <td>0.196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.069264</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>0.198381</td>\n",
       "      <td>0.116466</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670837</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>0.670509</td>\n",
       "      <td>0.651643</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.234973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.162602</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.510823</td>\n",
       "      <td>0.280992</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.184739</td>\n",
       "      <td>0.259109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651588</td>\n",
       "      <td>0.651588</td>\n",
       "      <td>0.657061</td>\n",
       "      <td>0.642254</td>\n",
       "      <td>0.320122</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>0.045267</td>\n",
       "      <td>0.194332</td>\n",
       "      <td>0.188755</td>\n",
       "      <td>0.323887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641963</td>\n",
       "      <td>0.641963</td>\n",
       "      <td>0.645533</td>\n",
       "      <td>0.635681</td>\n",
       "      <td>0.204268</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.054645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.378601</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>0.600823</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.465863</td>\n",
       "      <td>0.477733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727623</td>\n",
       "      <td>0.732435</td>\n",
       "      <td>0.731028</td>\n",
       "      <td>0.694836</td>\n",
       "      <td>0.173780</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.178862  0.316667  0.251082  0.144628  0.366255  0.323770  0.065844   \n",
       "1  0.166667  0.108333  0.069264  0.074380  0.246914  0.327869  0.213992   \n",
       "2  0.162602  0.112500  0.510823  0.280992  0.213992  0.040984  0.086420   \n",
       "3  0.085366  0.045833  0.025974  0.045455  0.181070  0.090164  0.045267   \n",
       "4  0.512195  0.295833  0.220779  0.247934  0.378601  0.069672  0.600823   \n",
       "\n",
       "          8         9        10  ...        57        58        59        60  \\\n",
       "0  0.020243  0.032129  0.060729  ...  0.732435  0.736285  0.734870  0.707042   \n",
       "1  0.198381  0.116466  0.085020  ...  0.670837  0.671800  0.670509  0.651643   \n",
       "2  0.052632  0.184739  0.259109  ...  0.651588  0.651588  0.657061  0.642254   \n",
       "3  0.194332  0.188755  0.323887  ...  0.641963  0.641963  0.645533  0.635681   \n",
       "4  0.785425  0.465863  0.477733  ...  0.727623  0.732435  0.731028  0.694836   \n",
       "\n",
       "         61     62   63        64        65  Label  \n",
       "0  0.131098  0.196  1.0  0.279070  0.016393      0  \n",
       "1  0.170732  0.156  0.0  0.209302  0.234973      0  \n",
       "2  0.320122  0.124  0.0  0.186047  0.327869      0  \n",
       "3  0.204268  0.080  1.0  0.325581  0.054645      0  \n",
       "4  0.173780  0.504  0.0  0.255814  0.245902      0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read all data [0-192: 193 users' oversampled data]\n",
    "import csv\n",
    "import pandas as pd\n",
    "dataset=pd.read_csv('Dataset/OversampledDACData.csv',index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0      300\n",
       "1      300\n",
       "2      300\n",
       "3      300\n",
       "4      300\n",
       "      ... \n",
       "188    300\n",
       "189    300\n",
       "190    300\n",
       "191    300\n",
       "192    300\n",
       "Name: Label, Length: 193, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace the user ID by class name and count the number of sample in each class\n",
    "#dataset['Label'] = pd.factorize(dataset['Label'])[0]\n",
    "dataset.groupby(['Label'])['Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in training dataset: 155\n",
      "Total user in auxiliary dataset: 38\n"
     ]
    }
   ],
   "source": [
    "#seperate the profile in two groups (80.0%, 20.0%): (i) Training profile (0-155), and (ii) auxiliary profile (156-192)\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData = dataset[dataset['Label'] <155]\n",
    "auxilaryData = dataset[dataset['Label'] >= 155]\n",
    "print(\"Total user in training dataset:\", len(pd.unique(trainingData['Label'])))\n",
    "print(\"Total user in auxiliary dataset:\", len(pd.unique(auxilaryData['Label'])))\n",
    "#assigned 0-154 users' data to dataset\n",
    "dataset=trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in the training dataset: 155\n"
     ]
    }
   ],
   "source": [
    "#total use in the system\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData=dataset\n",
    "print(\"Total user in the training dataset:\", len(pd.unique(trainingData['Label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_24416\\2206063142.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  datasetRP = pd.concat([datasetRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46540, 66)\n",
      "(46540, 57)\n"
     ]
    }
   ],
   "source": [
    "#Project the data with different seed\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','Label']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "datasetRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,155):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = dataset[dataset['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['ID']=seed\n",
    "    datasetRP = pd.concat([datasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(dataset.shape)\n",
    "print(datasetRP.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in the training dataset: 155\n"
     ]
    }
   ],
   "source": [
    "#total use in the system\n",
    "totalUser= len(pd.unique(datasetRP['ID']))\n",
    "trainingData=datasetRP\n",
    "print(\"Total user in the training dataset:\", len(pd.unique(trainingData['ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the group 1 data for training and testing the model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X=trainingData.drop(columns=['ID'])\n",
    "y=trainingData['ID']\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "#Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2, random_state=22)\n",
    "\n",
    "ytrain = to_categorical(ytrain)\n",
    "yval = to_categorical(yval)\n",
    "#ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37232, 56)\n",
      "(37232, 155)\n",
      "(9308, 56)\n",
      "(9308, 155)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xval.shape)\n",
    "print(yval.shape)\n",
    "#print(Xtest.shape)\n",
    "#print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary package for a neural network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inlineimport keras\n",
    "from keras.layers import Dense, Dropout, Input,Activation,Dropout, Flatten\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "#from tqdm import tqdm\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "#import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizers for neural network\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "def adam_optimizer():\n",
    "    return Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "def RMSprop_optimizer():\n",
    "    return RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,898</span> (85.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,898\u001b[0m (85.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,386</span> (83.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,386\u001b[0m (83.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#neural network architecture for model training\n",
    "\n",
    "def create_classifierRP(release=False,totalClass=10):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(64, input_dim=56))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.3))\n",
    "  \n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(128))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.2))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(64))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.3))\n",
    "\n",
    "  #if release:\n",
    "  classifier.add(Dense(totalClass, activation='softmax'))\n",
    "  #else:\n",
    "  #   classifier.add(Dense(Tuser))\n",
    "  #np.log_softmax_v2(a, axis=axis)\n",
    "  #classifier.add(F.softmax(a, dim=1))\n",
    "\n",
    "  classifier.compile(loss='categorical_crossentropy', optimizer=RMSprop_optimizer(),metrics=['accuracy'])\n",
    "  return classifier\n",
    "\n",
    "Clasf=create_classifierRP()\n",
    "Clasf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3555 - loss: 3.5152 - val_accuracy: 0.9996 - val_loss: 0.1517\n",
      "Epoch 2/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8850 - loss: 0.5884 - val_accuracy: 0.9999 - val_loss: 0.0056\n",
      "Epoch 3/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.2934 - val_accuracy: 0.9999 - val_loss: 0.0014\n",
      "Epoch 4/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.2220 - val_accuracy: 1.0000 - val_loss: 4.6359e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9487 - loss: 0.1800 - val_accuracy: 1.0000 - val_loss: 2.4212e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9540 - loss: 0.1585 - val_accuracy: 1.0000 - val_loss: 1.2640e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9574 - loss: 0.1491 - val_accuracy: 1.0000 - val_loss: 1.0451e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.1332 - val_accuracy: 1.0000 - val_loss: 1.2359e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9607 - loss: 0.1328 - val_accuracy: 1.0000 - val_loss: 8.5896e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.1191 - val_accuracy: 1.0000 - val_loss: 7.0234e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.1151 - val_accuracy: 1.0000 - val_loss: 6.0401e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.1088 - val_accuracy: 1.0000 - val_loss: 5.1785e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9671 - loss: 0.1082 - val_accuracy: 1.0000 - val_loss: 4.8111e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9700 - loss: 0.1047 - val_accuracy: 1.0000 - val_loss: 5.1956e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9703 - loss: 0.0987 - val_accuracy: 1.0000 - val_loss: 5.5011e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9730 - loss: 0.0909 - val_accuracy: 1.0000 - val_loss: 3.4528e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9707 - loss: 0.0937 - val_accuracy: 1.0000 - val_loss: 2.4663e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9711 - loss: 0.0952 - val_accuracy: 1.0000 - val_loss: 4.7676e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9745 - loss: 0.0893 - val_accuracy: 1.0000 - val_loss: 1.6088e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9721 - loss: 0.0952 - val_accuracy: 1.0000 - val_loss: 2.2319e-05\n"
     ]
    }
   ],
   "source": [
    "#Train the classifier seperately for black-box attack\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5,min_lr=0.0001)\n",
    "callbacks_list = [learning_rate_reduction]\n",
    "\n",
    "Classfier2= create_classifierRP(True,155)\n",
    "\n",
    "#------Comment will start from here\n",
    "lossc='categorical_crossentropy'\n",
    "optimizerc=RMSprop(learning_rate=0.001, rho=0.9)\n",
    "Classfier2.compile(loss=lossc, optimizer=optimizerc,metrics=['accuracy'])\n",
    "#------Comments will end from here\n",
    "historyc2 =  Classfier2.fit(Xtrain, ytrain, batch_size=64, epochs=20, validation_data=(Xval, yval),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWu0lEQVR4nO3deVxUVeMG8GfYhh0XcBBCcN8CNBTCJc0oXCK1UjQTXHszNZVM5XVvkcoyMi2rn0rWW7mktlAYolYiLqmYGpJboii4wggqy8z5/TExOrIPM3Nn4Pl+PvfDzJ1zz5w7F5zHe865VyaEECAiIiJqQKykbgARERGRqTEAERERUYPDAEREREQNDgMQERERNTgMQERERNTgMAARERFRg8MARERERA2OjdQNMEdqtRoXL16Ei4sLZDKZ1M0hIiKiGhBC4ObNm/Dy8oKVVdXneBiAKnDx4kX4+PhI3QwiIiLSw/nz5/HAAw9UWYYBqAIuLi4ANB+gq6urxK0hIiKimlAqlfDx8dF+j1eFAagCZd1erq6uDEBEREQWpibDVzgImoiIiBocBiAiIiJqcBiAiIiIqMFhACIiIqIGhwGIiIiIGhwGICIiImpwGICIiIiowWEAIiIiogaHAYiIiIgaHAYgIiIianAkDUC//fYbIiIi4OXlBZlMhq1bt1a7za5du/DQQw9BLpejTZs2SEhIKFdm5cqV8PPzg729PUJCQrB//37DN56IiIgslqQBqLCwEIGBgVi5cmWNyp89exaDBg3Co48+ivT0dEyfPh0TJkzAtm3btGXWr1+PmJgYLFy4EIcOHUJgYCDCw8Nx+fJlY+0GERERWRiZEEJI3QhAc+OyLVu2YMiQIZWWmT17NhITE3Hs2DHtuhEjRiAvLw9JSUkAgJCQEHTv3h0rVqwAAKjVavj4+GDq1KmYM2dOjdqiVCrh5uaG/Px8y7gZqhCASqVZjH04hTDeQkREDYerK9C4sUGrrM33t0XdDT4tLQ1hYWE668LDwzF9+nQAQHFxMQ4ePIjY2Fjt61ZWVggLC0NaWlql9RYVFaGoqEj7XKlUGrbhZb78Evjkk7th5f5Fra78taoWhgciIrI0sbHAkiWSvb1FBaCcnBwoFAqddQqFAkqlErdv38aNGzegUqkqLHPixIlK642Li8PixYuN0mYdFy4Au3cb/33MmUxW9UJERA2DjbQRxKICkLHExsYiJiZG+1ypVMLHx8fwbzRkCNC2LWBtfXexstJ9XtVSk7JWJhjWVV2IYbghIiIzZ1EByNPTE7m5uTrrcnNz4erqCgcHB1hbW8Pa2rrCMp6enpXWK5fLIZfLjdJmHR06aBYiIiKSlEVdByg0NBQpKSk665KTkxEaGgoAsLOzQ1BQkE4ZtVqNlJQUbRkiIiIiSQNQQUEB0tPTkZ6eDkAzzT09PR1ZWVkANF1TUVFR2vIvvvgizpw5g1mzZuHEiRP46KOPsGHDBsyYMUNbJiYmBp999hk+//xzZGRkYNKkSSgsLMTYsWNNum9ERERkviTtAvvjjz/w6KOPap+XjcOJjo5GQkICLl26pA1DANCyZUskJiZixowZ+OCDD/DAAw/g//7v/xAeHq4tExkZiStXrmDBggXIyclBly5dkJSUVG5gNBERETVcZnMdIHNicdcBIiIiolp9f1vUGCAiIiIiQ2AAIiIiogaHAYiIiIgaHAYgIiIianAYgIiIiKjBYQAiIiKiBocBiIiIiBocBiAiIiJqcBiAiIiIqMFhACIiIqIGhwGIiIiIGhwGICIiImpwGICIiIiowbGRugFERERkPoQAbt/WPLaxAWxtAZlM2jYZAwMQERFRPSAEUFQE5OcDSqVm0fexSqVbt7X13TBka3v3cUXrKnt8/7onnwSefVaazwpgACIiIjI7t24BV65olqtXK35840b54FJSYpz2qFSapajIcHV6eTEAERGRhRMCuHMHKCjQXQoLy6+raKms3P1nIgxJJgMcHQFnZ8DFRbNU9Limrzs5VdxVpFZrwkplQabs8b3ryrqg9OXiAri5Aa6umqW2j11cACsrTaAqLdX8vPdxTddV9frDD9dtH+uKAYiIiABoQszNm8D163eXa9d0n9+/Lj//blhRq6Xeg9orLgby8gxTl0ymCUFlocjGRvNZXbumX5CzswM8PDSLu3v5x02a6IaWshDj7KwJL1Q1BiAionqi7CzMrVt3l5s3NWcfqgsyZUtpad3bUXZWpaLFyany1+4v5+SkGS9iLGr13c+ooEDz897HtVmnVms+/7IwWBE3t7vhpaJAc/9jZ+f6OfjYXDAAERFB8wV2+TKQlXV3OX9e87Oo6O7gzbLFzq78On3K2NqWDy2FhbrPa7NOiLp/Fg4OmrML9y5Nm1a8ruyMQ9ni6KgZMNuQlM2auj8glZRoPqOyYGNnJ3VL6V4MQETUIBQWlg8294ed4mKpW2k4crkmjDg5VR9i7l/n4CB16y1L2VgiR0dAoZC6NVRTDEBEZPFUKiAnp3youXe5fr36eqysNDNTWrQAfHzu/nRyujt48/6luLjy12pSrrRUN6yUfZFW9LymZRriWRii2mIAIiLJqdWaLoP8fM2A1Nr+vHatZmNX3Nw0oebegHPv4uVl3DEnRGQ+GICIyCCKizWDbe8fVHvvbKF7Q8u9j5XKuo9dsbEBHnig8nDj46MJQEREAAMQEd3n9u3KQ0xVS2UzX2rDzg5o1EizuLnV7GejRppxLJ6e7PYhoppjACKyALdva7p57twxznL7tuZMzPXrmuf6ksmAxo3LD6pt3Ljy8HLvOnt7Q3xaRETVYwAiMiOlpcCpU8DRo8CxY3d/njplmOnNNWVjUz7E1GRxc+MF2IjIMjAAEUlACCA7WzfoHD0KZGRUfq8dW1vN9GR7e+MsjRrdDTK8ABsR1XcMQERGlpdXPugcO1b55fcdHYEHHwT8/e/+9PcHmjUzZauJiOo3BiAiA7lzBzhxQjfkHD0KXLhQcXlra6Bdu7sBpyzwtGzJbiQiImNjACLSgxDA338DaWnA3r2an8ePV37DQx8f3ZDj7w906KC5AB4REZme5P/PXLlyJfz8/GBvb4+QkBDs37+/0rIlJSV47bXX0Lp1a9jb2yMwMBBJSUk6ZRYtWgSZTKazdOjQwdi7QfWcUgkkJwOvvw4MHKiZdt2hAzB2LPDJJ8Cff2rCT+PGwCOPAC+9BHz8MbB7t+baOFlZQGIi8NZbwPPPA4GBDD9ERFKS9AzQ+vXrERMTg1WrViEkJATx8fEIDw9HZmYmmlUw4GHevHn48ssv8dlnn6FDhw7Ytm0bhg4dij179qBr167acp07d8b27du1z21seKKLak6t1nRllZ3Z2btXc3bn/llYcjnQrRsQGgo8/DAQEgJ4e3PwMBGRJZAJYcrJtbpCQkLQvXt3rFixAgCgVqvh4+ODqVOnYs6cOeXKe3l5Ye7cuZg8ebJ23TPPPAMHBwd8+eWXADRngLZu3Yr09HS926VUKuHm5ob8/Hy4urrqXQ9Zhhs3gP37NWEnLQ3Yt09zheL7+fndDTuhoZqzOLy7MxGR+ajN97dkp0aKi4tx8OBBxMbGatdZWVkhLCwMaWlpFW5TVFQE+/uulObg4IDdu3frrDt58iS8vLxgb2+P0NBQxMXFoUWLFpW2paioCEX3zD1WKpX67BJZAJVKM9W8LOzs3at5fj8HB6B797th5+GHNVcaJiKi+kGyAHT16lWoVCooFAqd9QqFAidOnKhwm/DwcCxbtgyPPPIIWrdujZSUFGzevBmqe0aehoSEICEhAe3bt8elS5ewePFi9O7dG8eOHYOLi0uF9cbFxWHx4sWG2zkyG7dva87o/PYb8Pvvmsc3b5Yv17q17tkdf3/eFJOIqD6zqMExH3zwASZOnIgOHTpAJpOhdevWGDt2LNasWaMtM2DAAO3jgIAAhISEwNfXFxs2bMD48eMrrDc2NhYxMTHa50qlEj4+PsbbETIapRLYs0cTeH77TdO1VVKiW8bJCQgOvht2QkJ4jR0iooZGsgDk7u4Oa2tr5Obm6qzPzc2FZyV9DR4eHti6dSvu3LmDa9euwcvLC3PmzEGrVq0qfZ9GjRqhXbt2OHXqVKVl5HI55JySY5GuXtWc2SkLPOnpmkHM92reHOjTB+jdG+jRQzMNnePiiYgaNsm+Buzs7BAUFISUlBQMGTIEgGYQdEpKCqZMmVLltvb29vD29kZJSQm+/fZbDB8+vNKyBQUFOH36NEaPHm3I5pNEsrPvhp3ffgP++qt8mVatNFPRy5ZWrTgzi4iIdEn6/+CYmBhER0ejW7duCA4ORnx8PAoLCzF27FgAQFRUFLy9vREXFwcA2LdvH7Kzs9GlSxdkZ2dj0aJFUKvVmDVrlrbOmTNnIiIiAr6+vrh48SIWLlwIa2trjBw5UpJ9JP0JAZw5oxt4zpwpX65Tp7thp3dv4IEHTN9WIiKyLJIGoMjISFy5cgULFixATk4OunTpgqSkJO3A6KysLFjdc0+AO3fuYN68eThz5gycnZ0xcOBAfPHFF2jUqJG2zIULFzBy5Ehcu3YNHh4e6NWrF/bu3QsPDw9T7x7VklqtmZF1b+C5eFG3jJUV0KXL3cDTqxfAQ0tERLUl6XWAzBWvA2Ra168DH30ErFwJ5OTovmZrq5mOXhZ4evQA3NykaScREZk3i7gOENE//wDvvw/83/8Bt25p1jk4aGZmlQWekBDN3dGJiIgMiQGITO7QIWDpUmDjxrs3Dw0MBF59FRg2jFdXJiIi42MAIpMQAvjlF03wSUm5uz4sDJg1S/OTM7WIiMhUGIDIqEpKgPXrgXffBY4c0ayztgYiI4GZM4F77mFLRERkMgxAZBQ3b2rG9rz/PnD+vGadkxMwYQIwYwbg6ytt+4iIqGFjACKDunQJWL4cWLUKyMvTrGvWDHj5ZWDSJKBJE0mbR0REBIABiAzkxAlNN9cXXwDFxZp17dppurlGjwbs7aVtHxER0b0YgEhvQgCpqZqBzd9/f3d9jx6aGV1PPaW5cCEREZG5YQCiWlOpNIHnnXeAvXvvrh88WBN8evaUrm1EREQ1wQBENXb7NrBuHfDee8DJk5p1dnZAVBTwyitAhw7Sto+IiKimGICoRnJzNVdm/vtvzfNGjYCXXgKmTgU8PSVtGhERUa0xAFG1lEpgwABN+PH0BGbPBsaPB1xcpG4ZERGRfhiAqEpFRcDQocDhw5q7rv/+O9CmjdStIiIiqhvO0aFKqdWa8T07dgDOzsDPPzP8EBFR/cAARBUSApg2DdiwAbC1BTZvBoKCpG4VERGRYTAAUYXi4oAVKzSP160DHn9c2vYQEREZEgMQlbN6NTB3ruZxfDwwYoSkzSEiIjI4BiDS8f33wAsvaB7PmaPpBiMiIqpvGIBIKzUViIzUDH4eMwZYskTqFhERERkHAxABAI4fByIigDt3gEGDgE8/BWQyqVtFRERkHAxAhPPngf79gRs3gIcfvjvzi4iIqL5iAGrgrl8HwsOBCxeAjh2BH38EHB2lbhUREZFxMQA1YLduAU8+CWRkAN7eQFIS0LSp1K0iIiIyPgagBqq0VDPgOS1Nc2PTbduAFi2kbhUREZFpMAA1QEJoprr/+CNgbw/88APQubPUrSIiIjIdBqAGaO5cYO1awMoKWL8e6NVL6hYRERGZFgNQA7N8ueY2FwDwySfAU09J2x4iIiIpMAA1IN98A0yfrnn8xhvAhAmSNoeIiEgyDEANxPbtQFSUZvzP5MnAf/8rdYuIiIikwwDUABw6BAwdCpSUAMOGAR98wKs8ExFRw8YAVM+dOgUMGAAUFAD9+gFffAFYW0vdKiIiImlJHoBWrlwJPz8/2NvbIyQkBPv376+0bElJCV577TW0bt0a9vb2CAwMRFJSUp3qrM9ycjRXeb58GejSBdiyBZDLpW4VERGR9CQNQOvXr0dMTAwWLlyIQ4cOITAwEOHh4bh8+XKF5efNm4dPPvkEH374If766y+8+OKLGDp0KA4fPqx3nfWVUgkMHAicOQO0bAn8/DPg6ip1q4iIiMyDTAghpHrzkJAQdO/eHStWrAAAqNVq+Pj4YOrUqZgzZ0658l5eXpg7dy4mT56sXffMM8/AwcEBX375pV51VkSpVMLNzQ35+flwtcDUUFSkCT87dgAeHsCePUCbNlK3ioiIyLhq8/0t2Rmg4uJiHDx4EGFhYXcbY2WFsLAwpKWlVbhNUVER7O3tddY5ODhg9+7detdZVq9SqdRZLJVarZnttWMH4OysOfPD8ENERKRLsgB09epVqFQqKBQKnfUKhQI5OTkVbhMeHo5ly5bh5MmTUKvVSE5OxubNm3Hp0iW96wSAuLg4uLm5aRcfH5867p00hACmTQM2bABsbYHNm4GgIKlbRUREZH4kHwRdGx988AHatm2LDh06wM7ODlOmTMHYsWNhZVW33YiNjUV+fr52OX/+vIFabFoffQT82/OHdeuAxx+Xtj1ERETmSrIA5O7uDmtra+Tm5uqsz83NhaenZ4XbeHh4YOvWrSgsLMS5c+dw4sQJODs7o1WrVnrXCQByuRyurq46iyX66ivNz9deA0aMkLYtRERE5kyyAGRnZ4egoCCkpKRo16nVaqSkpCA0NLTKbe3t7eHt7Y3S0lJ8++23GDx4cJ3rrA/+7QnEY49J2w4iIiJzZyPlm8fExCA6OhrdunVDcHAw4uPjUVhYiLFjxwIAoqKi4O3tjbh/7965b98+ZGdno0uXLsjOzsaiRYugVqsxa9asGtdZXwmhue4PADRvLm1biIiIzJ2kASgyMhJXrlzBggULkJOTgy5duiApKUk7iDkrK0tnfM+dO3cwb948nDlzBs7Ozhg4cCC++OILNGrUqMZ11lc3bwK3b2se1/NdJSIiqjNJrwNkrizxOkCZmUCHDpqLHebnS90aIiIi07OI6wCRYbH7i4iIqOYYgOqJsgBUxWQ3IiIi+hcDUD1RNgOMAYiIiKh6DED1BLvAiIiIao4BqJ5gFxgREVHNMQDVE+wCIyIiqjkGoHqCXWBEREQ1xwBUT7ALjIiIqOYYgOqB0lLgyhXNYwYgIiKi6jEA1QOXL2vuBWZtDbi7S90aIiIi88cAVA+UdX8pFIAVjygREVG1+HVZD3AGGBERUe0wANUDHABNRERUOwxA9QCnwBMREdUOA1A9wC4wIiKi2mEAqgfYBUZERFQ7DED1ALvAiIiIaocBqB5gFxgREVHtMABZOCHYBUZERFRbDEAWrqAAuHVL85gBiIiIqGYYgCxcWfeXiwvg5CRtW4iIiCwFA5CFY/cXERFR7TEAWTjOACMiIqo9BiALxxlgREREtccAZOHYBUZERFR7DEAWjl1gREREtccAZOHYBUZERFR7DEAWjl1gREREtccAZOHYBUZERFR7DEAWrLQUuHxZ85hngIiIiGqOAciCXbmiuReYlRXg7i51a4iIiCyH5AFo5cqV8PPzg729PUJCQrB///4qy8fHx6N9+/ZwcHCAj48PZsyYgTt37mhfX7RoEWQymc7SoUMHY++GJMq6vxQKwNpa2rYQERFZEhsp33z9+vWIiYnBqlWrEBISgvj4eISHhyMzMxPNmjUrV/6rr77CnDlzsGbNGvTo0QN///03xowZA5lMhmXLlmnLde7cGdu3b9c+t7GRdDeNhjPAiIiI9CPpGaBly5Zh4sSJGDt2LDp16oRVq1bB0dERa9asqbD8nj170LNnTzz33HPw8/PDE088gZEjR5Y7a2RjYwNPT0/t4l5P+4c4A4yIiEg/kgWg4uJiHDx4EGFhYXcbY2WFsLAwpKWlVbhNjx49cPDgQW3gOXPmDH766ScMHDhQp9zJkyfh5eWFVq1aYdSoUcjKyqqyLUVFRVAqlTqLJeAMMCIiIv1I1jd09epVqFQqKBQKnfUKhQInTpyocJvnnnsOV69eRa9evSCEQGlpKV588UX897//1ZYJCQlBQkIC2rdvj0uXLmHx4sXo3bs3jh07BhcXlwrrjYuLw+LFiw23cybCLjAiIiL9SD4IujZ27dqFJUuW4KOPPsKhQ4ewefNmJCYm4vXXX9eWGTBgAIYNG4aAgACEh4fjp59+Ql5eHjZs2FBpvbGxscjPz9cu58+fN8Xu1Bm7wIiIiPQj2Rkgd3d3WFtbIzc3V2d9bm4uPCv5Rp8/fz5Gjx6NCRMmAAD8/f1RWFiIF154AXPnzoWVVfk816hRI7Rr1w6nTp2qtC1yuRxyubwOeyMNdoERERHpR7IzQHZ2dggKCkJKSop2nVqtRkpKCkJDQyvc5tatW+VCjvW/87+FEBVuU1BQgNOnT6N5PUwJ7AIjIiLSj6Tzw2NiYhAdHY1u3bohODgY8fHxKCwsxNixYwEAUVFR8Pb2RlxcHAAgIiICy5YtQ9euXRESEoJTp05h/vz5iIiI0AahmTNnIiIiAr6+vrh48SIWLlwIa2trjBw5UrL9NBZ2gREREelH0gAUGRmJK1euYMGCBcjJyUGXLl2QlJSkHRidlZWlc8Zn3rx5kMlkmDdvHrKzs+Hh4YGIiAi8+eab2jIXLlzAyJEjce3aNXh4eKBXr17Yu3cvPDw8TL5/xlRQABQWah4zABEREdWOTFTWd9SAKZVKuLm5IT8/H66urlI3p0InTwLt2gHOzsDNm1K3hoiISHq1+f62qFlgdBe7v4iIiPTHAGShOAOMiIhIfwxAFoozwIiIiPTHAGSh2AVGRESkPwYgC8UuMCIiIv0xAFkodoERERHpT68AtHPnTkO3g2qJXWBERET60ysA9e/fH61bt8Ybb7xhMTcOrW/YBUZERKQ/vQJQdnY2pkyZgk2bNqFVq1YIDw/Hhg0bUFxcbOj2UQVUKuDyZc1jngEiIiKqPb0CkLu7O2bMmIH09HTs27cP7dq1w0svvQQvLy+8/PLLOHLkiKHbSfe4cgVQqwErK6Ce3eGDiIjIJOo8CPqhhx5CbGwspkyZgoKCAqxZswZBQUHo3bs3jh8/bog20n3Kur+aNQP+vQcsERER1YLeAaikpASbNm3CwIED4evri23btmHFihXIzc3FqVOn4Ovri2HDhhmyrfQvzgAjIiKqG73uBj916lR8/fXXEEJg9OjReOedd/Dggw9qX3dycsK7774LLy8vgzWU7uIMMCIiorrRKwD99ddf+PDDD/H0009DLpdXWMbd3Z3T5Y2EM8CIiIjqRq8AlJKSUn3FNjbo06ePPtVTNdgFRkREVDd6jQGKi4vDmjVryq1fs2YN3n777To3iqrGLjAiIqK60SsAffLJJ+jQoUO59Z07d8aqVavq3CiqGrvAiIiI6kavAJSTk4PmFXz7enh44FJZ/wwZDbvAiIiI6kavAOTj44PU1NRy61NTUznzywTYBUZERFQ3eg2CnjhxIqZPn46SkhL069cPgGZg9KxZs/DKK68YtIGkq6BAswDsAiMiItKXXgHo1VdfxbVr1/DSSy9p7/9lb2+P2bNnIzY21qANJF1lZ3+cnABnZ2nbQkREZKlkQgih78YFBQXIyMiAg4MD2rZtW+k1gSyNUqmEm5sb8vPz4erqKnVzdOzeDfTuDbRuDZw6JXVriIiIzEdtvr/1OgNUxtnZGd27d69LFVRLnAFGRERUd3oHoD/++AMbNmxAVlaWthuszObNm+vcMKoYZ4ARERHVnV6zwL755hv06NEDGRkZ2LJlC0pKSnD8+HHs2LEDbm5uhm4j3YMzwIiIiOpOrwC0ZMkSvP/++/jhhx9gZ2eHDz74ACdOnMDw4cPRokULQ7eR7sEAREREVHd6BaDTp09j0KBBAAA7OzsUFhZCJpNhxowZ+PTTTw3aQNJV1gXGMUBERET60ysANW7cGDdv3gQAeHt749ixYwCAvLw83Lp1y3Cto3J4BoiIiKju9BoE/cgjjyA5ORn+/v4YNmwYpk2bhh07diA5ORmPPfaYodtI92AAIiIiqju9AtCKFStw584dAMDcuXNha2uLPXv24JlnnsG8efMM2kC6S6UCcnM1j9kFRkREpL9aB6DS0lL8+OOPCA8PBwBYWVlhzpw5Bm8YlXf1KqBWAzIZ4OEhdWuIiIgsV63HANnY2ODFF1/UngGqq5UrV8LPzw/29vYICQnB/v37qywfHx+P9u3bw8HBAT4+PpgxY0a5ttS2TktR1v3l4QHY1OkSlkRERA2bXoOgg4ODkZ6eXuc3X79+PWJiYrBw4UIcOnQIgYGBCA8Px+XLlyss/9VXX2HOnDlYuHAhMjIysHr1aqxfvx7//e9/9a7TknAGGBERkWHodS+wDRs2IDY2FjNmzEBQUBCcnJx0Xg8ICKhRPSEhIejevTtWrFgBAFCr1fDx8cHUqVMr7FabMmUKMjIykJKSol33yiuvYN++fdi9e7dedVbEXO8FlpAAjB0LhIcDSUlSt4aIiMi8GP1eYCNGjAAAvPzyy9p1MpkMQgjIZDKoVKpq6yguLsbBgwd17h5vZWWFsLAwpKWlVbhNjx498OWXX2L//v0IDg7GmTNn8NNPP2H06NF61wkARUVFKCoq0j5XKpXVtl8KnAFGRERkGHoFoLNnz9b5ja9evQqVSgWFQqGzXqFQ4MSJExVu89xzz+Hq1avo1asXhBAoLS3Fiy++qO0C06dOAIiLi8PixYvruEfGxy4wIiIiw9ArAPn6+hq6HTWya9cuLFmyBB999BFCQkJw6tQpTJs2Da+//jrmz5+vd72xsbGIiYnRPlcqlfDx8TFEkw2KZ4CIiIgMQ68AtG7duipfj4qKqrYOd3d3WFtbI7fswjb/ys3NhWcl3/Dz58/H6NGjMWHCBACAv78/CgsL8cILL2Du3Ll61QkAcrkccrm82jZLjQGIiIjIMPQKQNOmTdN5XlJSglu3bsHOzg6Ojo41CkB2dnYICgpCSkoKhgwZAkAzYDklJQVTpkypcJtbt27Bykp34pq1tTUAQAihV52WpCwAsQuMiIiobvQKQDdu3Ci37uTJk5g0aRJeffXVGtcTExOD6OhodOvWDcHBwYiPj0dhYSHGjh0LQHMmydvbG3FxcQCAiIgILFu2DF27dtV2gc2fPx8RERHaIFRdnZasbAwQzwARERHVjcEup9e2bVu89dZbeP7556sccHyvyMhIXLlyBQsWLEBOTg66dOmCpKQk7SDmrKwsnTM+8+bNg0wmw7x585CdnQ0PDw9ERETgzTffrHGdlqqwEPj3/rMMQERERHWk13WAKpOeno5HHnnEbKeR15Q5XgfozBmgdWvA0REoKNDcDoOIiIjuMvp1gL7//nud50IIXLp0CStWrEDPnj31qZKqcW/3F8MPERFR3egVgMoGGJeRyWTw8PBAv3798N577xmiXXQfzgAjIiIyHL0CkFqtNnQ7qBqcAUZERGQ4et0MlUyPM8CIiIgMR68A9Mwzz+Dtt98ut/6dd97BsGHD6twoKo9dYERERIajVwD67bffMHDgwHLrBwwYgN9++63OjaLy2AVGRERkOHoFoIKCAtjZ2ZVbb2tra/FT4M0Vu8CIiIgMR68A5O/vj/Xr15db/80336BTp051bhSVxy4wIiIiw9FrFtj8+fPx9NNP4/Tp0+jXrx8AICUlBV9//TU2btxo0AYSoFYDZfd3ZRcYERFR3ekVgCIiIrB161YsWbIEmzZtgoODAwICArB9+3b06dPH0G1s8K5eBVQqzQUQPTykbg0REZHl0/teYIMGDcKgQYMM2RaqRFn3l7s7YGsrbVuIiIjqA73GAB04cAD79u0rt37fvn34448/6two0sUZYERERIalVwCaPHkyzp8/X259dnY2Jk+eXOdGkS7OACMiIjIsvQLQX3/9hYceeqjc+q5du+Kvv/6qc6NIF2eAERERGZZeAUgulyO3bFrSPS5dugQbG72HFVEl2AVGRERkWHoFoCeeeAKxsbHIz8/XrsvLy8N///tfPP744wZrHGmwC4yIiMiw9Dpd8+677+KRRx6Br68vunbtCgBIT0+HQqHAF198YdAGErvAiIiIDE2vAOTt7Y0///wT//vf/3DkyBE4ODhg7NixGDlyJGw5T9vg2AVGRERkWHoP2HFyckKvXr3QokULFBcXAwB+/vlnAMBTTz1lmNYRAHaBERERGZpeAejMmTMYOnQojh49CplMBiEEZDKZ9nWVSmWwBjZ0t24BZfeXZQAiIiIyDL0GQU+bNg0tW7bE5cuX4ejoiGPHjuHXX39Ft27dsGvXLgM3sWErm2zn4AC4ukrbFiIiovpCrzNAaWlp2LFjB9zd3WFlZQVra2v06tULcXFxePnll3H48GFDt7PBurf7656TbERERFQHep0BUqlUcHFxAQC4u7vj4sWLAABfX19kZmYarnXEGWBERERGoNcZoAcffBBHjhxBy5YtERISgnfeeQd2dnb49NNP0apVK0O3sUHjDDAiIiLD0ysAzZs3D4WFhQCA1157DU8++SR69+6Npk2bYv369QZtYEPHGWBERESGp1cACg8P1z5u06YNTpw4gevXr6Nx48Y6s8Go7tgFRkREZHgGu3FXkyZNDFUV3YNdYERERIan1yBoMh12gRERERkeA5CZYxcYERGR4TEAmTG1+u6FENkFRkREZDgMQGbs2jWgtFTzuFkzadtCRERUn5hFAFq5ciX8/Pxgb2+PkJAQ7N+/v9Kyffv2hUwmK7cMGjRIW2bMmDHlXu/fv78pdsWgyrq/3N0BW1tp20JERFSfGGwWmL7Wr1+PmJgYrFq1CiEhIYiPj0d4eDgyMzPRrILTHps3b9befR4Arl27hsDAQAwbNkynXP/+/bF27Vrtc7lcbrydMBLOACMiIjIOyc8ALVu2DBMnTsTYsWPRqVMnrFq1Co6OjlizZk2F5Zs0aQJPT0/tkpycDEdHx3IBSC6X65Rr3LixKXbHoDgDjIiIyDgkDUDFxcU4ePAgwsLCtOusrKwQFhaGtLS0GtWxevVqjBgxAk5OTjrrd+3ahWbNmqF9+/aYNGkSrl27VmkdRUVFUCqVOos54AwwIiIi45A0AF29ehUqlQoKhUJnvUKhQE7Zt38V9u/fj2PHjmHChAk66/v3749169YhJSUFb7/9Nn799VcMGDAAKpWqwnri4uLg5uamXXx8fPTfKQNiFxgREZFxSD4GqC5Wr14Nf39/BAcH66wfMWKE9rG/vz8CAgLQunVr7Nq1C4899li5emJjYxETE6N9rlQqzSIEsQuMiIjIOCQ9A+Tu7g5ra2vkll3s5l+5ubnwrOZbv7CwEN988w3Gjx9f7fu0atUK7u7uOHXqVIWvy+VyuLq66izmgF1gRERExiFpALKzs0NQUBBSUlK069RqNVJSUhAaGlrlths3bkRRURGef/75at/nwoULuHbtGppbWF8SAxAREZFxSD4LLCYmBp999hk+//xzZGRkYNKkSSgsLMTYsWMBAFFRUYiNjS233erVqzFkyBA0bdpUZ31BQQFeffVV7N27F//88w9SUlIwePBgtGnTRucu9pagrAvMwnIbERGR2ZN8DFBkZCSuXLmCBQsWICcnB126dEFSUpJ2YHRWVhasrHRzWmZmJnbv3o1ffvmlXH3W1tb4888/8fnnnyMvLw9eXl544okn8Prrr1vUtYBu3wby8zWPeQaIiIjIsGRCCCF1I8yNUqmEm5sb8vPzJRsP9M8/QMuWgFyuCUMymSTNICIishi1+f6WvAuMKnZv9xfDDxERkWExAJkpDoAmIiIyHgYgM8UAREREZDwMQGaKM8CIiIiMhwHITPEMEBERkfEwAJkpBiAiIiLjYQAyU+wCIyIiMh4GIDPFM0BERETGwwBkhtRqoOz+sAxAREREhscAZIauXwdKSjSP/70jCBERERkQA5AZKuv+atoUsLOTti1ERET1EQOQGeL4HyIiIuNiADJDnAFGRERkXAxAZohngIiIiIyLAcgMMQAREREZFwOQGWIXGBERkXExAJkhngEiIiIyLgYgM8QAREREZFwMQGaIXWBERETGxQBkZu7cAfLyNI95BoiIiMg4GIDMTNk9wORyoFEjSZtCRERUbzEAmZmy7i9PT0Amk7YtRERE9RUDkJnhAGgiIiLjYwAyMwxARERExscAZGY4A4yIiMj4GIDMDM8AERERGR8DkJlhACIiIjI+BiAzwy4wIiIi42MAMjM8A0RERGR8DEBmRAgGICIiIlNgADIj168DJSWaxwqFtG0hIiKqz8wiAK1cuRJ+fn6wt7dHSEgI9u/fX2nZvn37QiaTlVsGDRqkLSOEwIIFC9C8eXM4ODggLCwMJ0+eNMWu1EnZ2Z8mTTS3wiAiIiLjkDwArV+/HjExMVi4cCEOHTqEwMBAhIeH4/LlyxWW37x5My5duqRdjh07BmtrawwbNkxb5p133sHy5cuxatUq7Nu3D05OTggPD8edO3dMtVt6YfcXERGRaUgegJYtW4aJEydi7Nix6NSpE1atWgVHR0esWbOmwvJNmjSBp6endklOToajo6M2AAkhEB8fj3nz5mHw4MEICAjAunXrcPHiRWzdurXCOouKiqBUKnUWKXAGGBERkWlIGoCKi4tx8OBBhIWFaddZWVkhLCwMaWlpNapj9erVGDFiBJycnAAAZ8+eRU5Ojk6dbm5uCAkJqbTOuLg4uLm5aRcfH5867JX+eAaIiIjINCQNQFevXoVKpYLivhG/CoUCOWVpoAr79+/HsWPHMGHCBO26su1qU2dsbCzy8/O1y/nz52u7KwbBAERERGQaNlI3oC5Wr14Nf39/BAcH16keuVwOuRmMOmYXGBERkWlIegbI3d0d1tbWyM3N1Vmfm5sLz2pOgxQWFuKbb77B+PHjddaXbadPnVLjGSAiIiLTkDQA2dnZISgoCCkpKdp1arUaKSkpCA0NrXLbjRs3oqioCM8//7zO+pYtW8LT01OnTqVSiX379lVbp9QYgIiIiExD8i6wmJgYREdHo1u3bggODkZ8fDwKCwsxduxYAEBUVBS8vb0RFxens93q1asxZMgQNG3aVGe9TCbD9OnT8cYbb6Bt27Zo2bIl5s+fDy8vLwwZMsRUu6UXdoERERGZhuQBKDIyEleuXMGCBQuQk5ODLl26ICkpSTuIOSsrC1ZWuieqMjMzsXv3bvzyyy8V1jlr1iwUFhbihRdeQF5eHnr16oWkpCTY29sbfX/0VVQE3LihecwzQERERMYlE0IIqRthbpRKJdzc3JCfnw9XV1eTvGdWFuDrC9jZAXfuADKZSd6WiIio3qjN97fkF0IkjbLuL09Phh8iIiJjYwAyExwATUREZDoMQGaCAYiIiMh0GIDMBGeAERERmQ4DkJngGSAiIiLTYQAyEwxAREREpsMAZCbYBUZERGQ6DEBmgmeAiIiITIcByAwIwQBERERkSgxAZiAvDygu1jz+9w4gREREZEQMQGagbPxP48aAGd+ujIiIqN5gADID7P4iIiIyLQYgM8AAREREZFoMQGaAU+CJiIhMiwHIDPAMEBERkWkxAJkBBiAiIiLTYgAyA+wCIyIiMi0GIDPAM0BERESmxQBkBhiAiIiITIsBSGLFxcC1a5rH7AIjIiIyDQYgieXman7a2mquBE1ERETGxwAksbLuL4UCsOLRICIiMgl+5UqMM8CIiIhMjwFIYhwATUREZHoMQBJjACIiIjI9BiCJsQuMiIjI9BiAJMYzQERERKbHACQxBiAiIiLTYwCSGLvAiIiITI8BSEJC8AwQERGRFBiAJJSfDxQVaR4zABEREZmO5AFo5cqV8PPzg729PUJCQrB///4qy+fl5WHy5Mlo3rw55HI52rVrh59++kn7+qJFiyCTyXSWDh06GHs39FLW/dWoEWBvL2lTiIiIGhQbKd98/fr1iImJwapVqxASEoL4+HiEh4cjMzMTzZo1K1e+uLgYjz/+OJo1a4ZNmzbB29sb586dQ6NGjXTKde7cGdu3b9c+t7GRdDcrxe4vIiIiaUiaDJYtW4aJEydi7NixAIBVq1YhMTERa9aswZw5c8qVX7NmDa5fv449e/bA1tYWAODn51eunI2NDTxrkSqKiopQVNYXBUCpVNZyT/TDAERERCQNybrAiouLcfDgQYSFhd1tjJUVwsLCkJaWVuE233//PUJDQzF58mQoFAo8+OCDWLJkCVQqlU65kydPwsvLC61atcKoUaOQlZVVZVvi4uLg5uamXXx8fOq+gzXAGWBERETSkCwAXb16FSqVCgqFQme9QqFATtmpkfucOXMGmzZtgkqlwk8//YT58+fjvffewxtvvKEtExISgoSEBCQlJeHjjz/G2bNn0bt3b9y8ebPStsTGxiI/P1+7nD9/3jA7WQ2eASIiIpKGeQ6OqYRarUazZs3w6aefwtraGkFBQcjOzsbSpUuxcOFCAMCAAQO05QMCAhASEgJfX19s2LAB48ePr7BeuVwOuVxukn24FwMQERGRNCQLQO7u7rC2tkZubq7O+tzc3ErH7zRv3hy2trawtrbWruvYsSNycnJQXFwMOzu7cts0atQI7dq1w6lTpwy7AwbALjAiIiJpSNYFZmdnh6CgIKSkpGjXqdVqpKSkIDQ0tMJtevbsiVOnTkGtVmvX/f3332jevHmF4QcACgoKcPr0aTQ3w5TBM0BERETSkPQ6QDExMfjss8/w+eefIyMjA5MmTUJhYaF2VlhUVBRiY2O15SdNmoTr169j2rRp+Pvvv5GYmIglS5Zg8uTJ2jIzZ87Er7/+in/++Qd79uzB0KFDYW1tjZEjR5p8/6rDAERERCQNSccARUZG4sqVK1iwYAFycnLQpUsXJCUlaQdGZ2Vlwcrqbkbz8fHBtm3bMGPGDAQEBMDb2xvTpk3D7NmztWUuXLiAkSNH4tq1a/Dw8ECvXr2wd+9eeHh4mHz/qlJcDFy9qnlshieniMjClZaWori4WOpmEBmUnZ2dwa7tJxNCCIPUVI8olUq4ubkhPz8frq6uRnmPCxcAHx/AxkZzOwwrya/JTUT1gRACWVlZuFr2Pyyiesbd3R0tWrSATCYr91ptvr8tahZYfVLW/aVQMPwQkeGUhR9vb284OzvrnEUnsmRqtRoFBQXIzs5GcXExWrVqpTMpqrYYgCTCGWBEZGilpaXa8FObq+ETWQpnZ2cAQHZ2NjZu3Ijw8HA0btxYr7r4XwOJcAA0ERla2Zifsi8Jovqo7Pf7ypUr+PHHH/W+fRUDkEQYgIjIWNjtRfVZ2e+3QqHAhQsXkJ2drV89hmwU1Ry7wIiIiPRnbW0NmUyG27dv67U9A5BEeAaIiMh4/Pz8EB8fX+Pyu3btgkwmQ15entHaROaFAUgiDEBERIBMJqtyWbRokV71HjhwAC+88EKNy/fo0QOXLl2Cm5ubXu9HloezwCTCLjAiIuBS2T+GANavX48FCxYgMzNTu+7eAd1CCKhUqhpdCK+2F7+1s7NrsDPnKruXZn3HM0ASEIJngIjINIQACgtNv9T0Eruenp7axc3NDTKZTPv8xIkTcHFxwc8//4ygoCDI5XLs3r0bp0+fxuDBg6FQKODs7Izu3btj+/btOvXe3wUmk8nwf//3fxg6dCgcHR3Rtm1bfP/999rX7+8CS0hIQKNGjbBt2zZ07NgRzs7O6N+/v05gKy0txcsvv4xGjRqhadOmmD17NqKjozFkyJBK9/fatWsYOXIkvL294ejoCH9/f3z99dc6ZdRqNd555x20adMGcrkcLVq0wJtvvql9veyOB02aNIGTkxO6deuGffv2AQDGjBlT7v2nT5+Ovn37ap/37dsXU6ZMwfTp0+Hu7o7w8HAAwLJly+Dv7w8nJyf4+PjgpZdeQkFBgU5dqamp6Nu3LxwdHdG4cWOEh4fjxo0bWLduHZo2bYqioiKd8kOGDMHo0aMr/TykxAAkAaUSuHNH85gBiIiM6dYtwNnZ9MutW4bbhzlz5uCtt95CRkYGAgICUFBQgIEDByIlJQWHDx9G//79ERERgaysrCrrWbx4MYYPH44///wTAwcOxKhRo3D9+vUqPrtbePfdd/HFF1/gt99+Q1ZWFmbOnKl9/e2338b//vc/rF27FqmpqVAqldi6dWuVbbhz5w6CgoKQmJiIY8eO4YUXXsDo0aOxf/9+bZnY2Fi89dZbmD9/Pv766y989dVX2ltEFRQUoE+fPsjOzsb333+PI0eOYNasWTo3Ca+Jzz//HHZ2dkhNTcWqVasAaGZXLV++HMePH8fnn3+OHTt2YNasWdpt0tPT8dhjj6FTp05IS0vD7t27ERERAZVKhWHDhkGlUumEysuXLyMxMRHjxo2rVdtMRlA5+fn5AoDIz883Sv0ZGUIAQri5GaV6ImqgCgsLxR9//CEKCwu16woKNP/emHopKKh9+9euXSvc7vmHcefOnQKA2Lp1a7Xbdu7cWXz44Yfa576+vuL999/XPgcg5s2bd8/nUiAAiJ9//lnnvW7cuKFtCwBx6tQp7TYrV64UCoVC+1yhUIilS5dqn5eWlooWLVqIwYMH13SXhRBCDBo0SLzyyitCCCGUSqWQy+Xis88+q7DsJ598IlxcXMS1a9cqfD06Orrc+0+bNk306dNH+7xPnz6ia9eu1bZr48aNomnTptrnI0eOFD179qy0/KRJk8SAAQO0z9977z3RqlUroVarq32v2ij7Pd+0aZOIi4sTBw8e1L5Wm+9vjgGSALu/iMhUHB2B+3oxTPa+htKtWzed5wUFBVi0aBESExNx6dIllJaW4vbt29WeAQoICNA+dnJygqurKy5fvlxpeUdHR7Ru3Vr7vHnz5try+fn5yM3NRXBwsPZ1a2trBAUFVXk2RqVSYcmSJdiwYYP2lg5FRUVw/PcDy8jIQFFRER577LEKt09PT0fXrl3RpEmTKve1OkFBQeXWbd++HXFxcThx4gSUSiVKS0tx584d3Lp1C46OjkhPT8ewYcMqrXPixIno3r07srOz4e3tjYSEBIwZM6bCe3aZAwYgCTAAEZGpyGSAk5PUragbp/t2YObMmUhOTsa7776LNm3awMHBAc8++6z2StiVsbW11Xkuk8mqDCsVlRd1vH/40qVL8cEHHyA+Pl473mb69Onatjs4OFS5fXWvW1lZlWtjSUlJuXL3f6b//PMPnnzySUyaNAlvvvkmmjRpgt27d2P8+PEoLi6Go6Njte/dtWtXBAYGYt26dXjiiSdw/PhxJCYmVrmNlDgGSAKcAUZEpL/U1FSMGTMGQ4cOhb+/Pzw9PfHPP/+YtA1ubm5QKBQ4cOCAdp1KpcKhQ4eq3C41NRWDBw/G888/j8DAQLRq1Qp///239vW2bdvCwcEBKSkpFW4fEBCA9PT0SscueXh46AzUBjRnjapz8OBBqNVqvPfee3j44YfRrl07XLx4sdx7V9auMhMmTEBCQgLWrl2LsLAw+Pj4VPveUmEAkgDPABER6a9t27bYvHkz0tPTceTIETz33HO1HgRsCFOnTkVcXBy+++47ZGZmYtq0abhx40aVXT5t27ZFcnIy9uzZg4yMDPznP/9Bbm6u9nV7e3vMnj0bs2bNwrp163D69Gns3bsXq1evBgCMHDkSnp6eGDJkCFJTU3HmzBl8++23SEtLAwD069cPf/zxB9atW4eTJ09i4cKFOHbsWLX70qZNG5SUlODDDz/EmTNn8MUXX2gHR5eJjY3FgQMH8NJLL+HPP//EiRMn8PHHH+Pq1avaMs899xwuXLiAzz77zHwHP/+LAUgCDEBERPpbtmwZGjdujB49eiAiIgLh4eF46KGHTN6O2bNnY+TIkYiKikJoaCicnZ0RHh4Oe3v7SreZN28eHnroIYSHh6Nv377aMHOv+fPn45VXXsGCBQvQsWNHREZGasce2dnZ4ZdffkGzZs0wcOBA+Pv746233oK1tTUAIDw8HPPnz8esWbPQvXt33Lx5E1FRUdXuS2BgIJYtW4a3334bDz74IP73v/8hLi5Op0y7du3wyy+/4MiRIwgODkZoaCi+++47nesyubm54ZlnnoGzs3OVlwMwBzJR1w7NekipVMLNzQ35+flwdXU1eP1PPAEkJwOffw7U4PeSiKhGbt26hYyMDHTs2FE7qJZMR61Wo2PHjhg+fDhef/11qZsjmcceewydO3fG8uXLjVJ/2e/5P//8g5MnT+KJJ57QBuDafH9zELQEeAaIiMjynTt3Dr/88gv69OmDoqIirFixAmfPnsVzzz0nddMkcePGDezatQu7du3CRx99JHVzqsUAJAEGICIiy2dlZYWEhATMnDkTQgg8+OCD2L59Ozp27Ch10yTRtWtX3LhxA2+//Tbat28vdXOqxQBkYiUlwJUrmsecBUZEZLl8fHyQmpoqdTPMhqln4tUVB0GbWNk1t6ytgaZNpW0LERFRQ8UAZGJl3V8KBWDFT5+IiEgS/Ao2sbLrU3H8DxERkXQYgEys7AwQx/8QERFJhwHIxDgDjIiISHoMQCbGLjAiIiLpMQCZGLvAiIgMr2/fvpg+fbr2uZ+fH+Lj46vcRiaTYevWrXV+b0PVQ6bFAGRi7AIjIrorIiIC/fv3r/C133//HTKZDH/++Wet6z1w4ABeeOGFujZPx6JFi9ClS5dy6y9duoQBAwYY9L3I+BiATIxdYEREd40fPx7Jycm4cOFCudfWrl2Lbt26ISAgoNb1enh4mOx+aJ6enpDL5SZ5L3NSXFwsdRPqhAHIhIRgFxgRmZgQQGGh6Zca3mf7ySefhIeHBxISEnTWFxQUYOPGjRg/fjyuXbuGkSNHwtvbG46OjvD398fXX39dZb33d4GdPHkSjzzyCOzt7dGpUyckJyeX22b27Nlo164dHB0d0apVK8yfPx8lJSUAgISEBCxevBhHjhyBTCaDTCbTtvn+LrCjR4+iX79+cHBwQNOmTfHCCy+goKBA+/qYMWMwZMgQvPvuu2jevDmaNm2KyZMna9+rIqdPn8bgwYOhUCjg7OyM7t27Y/v27TplioqKMHv2bPj4+EAul6NNmzZYvXq19vXjx4/jySefhKurK1xcXNC7d2+cPn0aQPkuRAAYMmQIxowZo/OZvv7664iKioKrq6v2DFtVn1uZH374Ad27d4e9vT3c3d0xdOhQAMBrr72GBx98sNz+dunSBfPnz6/08zAE3grDhG7eBG7f1jxWKKRtCxE1ELduAc7Opn/fggLAyanaYjY2NoiKikJCQgLmzp0LmUwGANi4cSNUKhVGjhyJgoICBAUFYfbs2XB1dUViYiJGjx6N1q1bIzg4uNr3UKvVePrpp6FQKLBv3z7k5+eX+7IHABcXFyQkJMDLywtHjx7FxIkT4eLiglmzZiEyMhLHjh1DUlKSNni4ubmVq6OwsBDh4eEIDQ3FgQMHcPnyZUyYMAFTpkzRCXk7d+5E8+bNsXPnTpw6dQqRkZHo0qULJk6cWMnHWYCBAwfizTffhFwux7p16xAREYHMzEy0aNECABAVFYW0tDQsX74cgYGBOHv2LK5evQoAyM7OxiOPPIK+fftix44dcHV1RWpqKkpLS6v9/O717rvvYsGCBVi4cGGNPjcASExMxNChQzF37lysW7cOxcXF+OmnnwAA48aNw+LFi3HgwAF0794dAHD48GH8+eef2Lx5c63aVmtCYitWrBC+vr5CLpeL4OBgsW/fvirL37hxQ7z00kvC09NT2NnZibZt24rExMQ61Xm//Px8AUDk5+fXen+qcuKEEIAQLi4GrZaISAghRGFhofjjjz9EYWHh3ZUFBZp/eEy9FBTUuN0ZGRkCgNi5c6d2Xe/evcXzzz9f6TaDBg0Sr7zyivZ5nz59xLRp07TPfX19xfvvvy+EEGLbtm3CxsZGZGdna1//+eefBQCxZcuWSt9j6dKlIigoSPt84cKFIjAwsFy5e+v59NNPRePGjUXBPfufmJgorKysRE5OjhBCiOjoaOHr6ytKS0u1ZYYNGyYiIyMrbUtFOnfuLD788EMhhBCZmZkCgEhOTq6wbGxsrGjZsqUoLi6u8PX7Pz8hhBg8eLCIjo7WPvf19RVDhgyptl33f26hoaFi1KhRlZYfMGCAmDRpkvb51KlTRd++fSstX/Z7vmnTJhEXFycOHjyofa0239+SngFav349YmJisGrVKoSEhCA+Ph7h4eHIzMxEs2bNypUvLi7G448/jmbNmmHTpk3w9vbGuXPn0KhRI73rNCV2fxGRyTk6as7GSPG+NdShQwf06NEDa9asQd++fXHq1Cn8/vvveO211wAAKpUKS5YswYYNG5CdnY3i4mIUFRXVeIxPRkYGfHx84OXlpV0XGhpartz69euxfPlynD59GgUFBSgtLYWrq2uN96PsvQIDA+F0z9mvnj17Qq1WIzMzE4p/T/937twZ1tbW2jLNmzfH0aNHK623oKAAixYtQmJiIi5duoTS0lLcvn0bWVlZAID09HRYW1ujT58+FW6fnp6O3r17w9bWtlb7c79u3bqVW1fd55aenl7pmS0AmDhxIsaNG4dly5bBysoKX331Fd5///06tbMmJB0DtGzZMkycOBFjx45Fp06dsGrVKjg6OmLNmjUVll+zZg2uX7+OrVu3omfPnvDz80OfPn0QGBiod52Apt9UqVTqLMbAGWBEZHIymaYrytTLv11ZNTV+/Hh8++23uHnzJtauXYvWrVtrv8yXLl2KDz74ALNnz8bOnTuRnp6O8PBwgw7CTUtLw6hRozBw4ED8+OOPOHz4MObOnWu0gb73BxGZTAa1Wl1p+ZkzZ2LLli1YsmQJfv/9d6Snp8Pf31/bPgcHhyrfr7rXraysIO4bt1XRmCSn+7o1a/K5VffeERERkMvl2LJlC3744QeUlJTg2WefrXIbQ5AsABUXF+PgwYMICwu72xgrK4SFhSEtLa3Cbb7//nuEhoZi8uTJUCgUePDBB7FkyRKoVCq96wSAuLg4uLm5aRcfHx8D7aUuzgAjIqrY8OHDtf/7X7duHcaNG6cdD5SamorBgwfj+eefR2BgIFq1aoW///67xnV37NgR58+fx6Wyf4QB7N27V6fMnj174Ovri7lz56Jbt25o27Ytzp07p1PGzs5O+31T1XsdOXIEhYWF2nWpqamwsrJC+/bta9zm+6WmpmLMmDEYOnQo/P394enpiX/++Uf7ur+/P9RqNX799dcKtw8ICMDvv/9e6UBrDw8Pnc9HpVLh2LFj1barJp9bQEAAUlJSKq3DxsYG0dHRWLt2LdauXYsRI0ZUG5oMQbIAdPXqVahUKu3pwDIKhQI5ZadK7nPmzBls2rQJKpUKP/30E+bPn4/33nsPb7zxht51AkBsbCzy8/O1y/nz5+u4dxUrKgIcHNgFRkR0P2dnZ0RGRiI2NhaXLl3SmX3Utm1bJCcnY8+ePcjIyMB//vMf5Obm1rjusLAwtGvXDtHR0Thy5Ah+//13zJ07V6dM27ZtkZWVhW+++QanT5/G8uXLsWXLFp0yfn5+OHv2LNLT03H16lUUFRWVe69Ro0bB3t4e0dHROHbsGHbu3ImpU6di9OjR5b6baqNt27bYvHkz0tPTceTIETz33HM6Z4z8/PwQHR2NcePGYevWrTh79ix27dqFDRs2AACmTJkCpVKJESNG4I8//sDJkyfxxRdfIDMzEwDQr18/JCYmIjExESdOnMCkSZOQl5dXo3ZV97ktXLgQX3/9NRYuXIiMjAwcPXoUb7/9tk6ZCRMmYMeOHUhKSsK4ceP0/pxqw6KmwavVajRr1gyffvopgoKCEBkZiblz52LVqlV1qlcul8PV1VVnMYbZszWzQ5cuNUr1REQWbfz48bhx4wbCw8N1xuvMmzcPDz30EMLDw9G3b194enpiyJAhNa7XysoKW7Zswe3btxEcHIwJEybgzTff1Cnz1FNPYcaMGZgyZQq6dOmCPXv2lJuG/cwzz6B///549NFH4eHhUeFUfEdHR2zbtg3Xr19H9+7d8eyzz+Kxxx7DihUravdh3GfZsmVo3LgxevTogYiICISHh+Ohhx7SKfPxxx/j2WefxUsvvYQOHTpg4sSJ2jNRTZs2xY4dO1BQUIA+ffogKCgIn332mbYrbty4cYiOjkZUVBT69OmDVq1a4dFHH622XTX53Pr27YuNGzfi+++/R5cuXdCvXz/s379fp0zbtm3Ro0cPdOjQASEhIXX5qGpMJu7v9DOR4uJiODo6YtOmTTq/yNHR0cjLy8N3331Xbps+ffrA1tZW59oHP//8MwYOHKhN4rWtsyJKpRJubm7Iz883WhgiIjK0W7duISMjAx07djTZRQCJDEEIgbZt2+Kll15CTExMlWXLfs//+ecfnDx5Ek888YQ2DNbm+1uyM0B2dnYICgrS6RdUq9VISUmpcHQ+oBlJf+rUKZ3Tfn///TeaN28OOzs7veokIiIi6Vy5cgUrVqxATk4Oxo4da7L3lXQafExMDKKjo9GtWzcEBwcjPj4ehYWF2g8gKioK3t7eiIuLAwBMmjQJK1aswLRp0zB16lScPHkSS5Yswcsvv1zjOomIiMh8NGvWDO7u7vj000/RuHFjk72vpAEoMjISV65cwYIFC5CTk4MuXbogKSlJO1AsKysLVlZ3T1L5+Phg27ZtmDFjBgICAuDt7Y1p06Zh9uzZNa6TiIiIzIdEI3GkGwNkzjgGiIgsEccAUUNg8WOAiIjIOKq6oB6RpTPU7zcDEBFRPWFnZwcAOnceJ6pvyn6/K7uoY03xbvBERPWEjY0N3N3dkZ2dDUBzccF7x1ESWTK1Wo2CggJkZ2cjLy+vzmeCGICIiOqRFi1aAIA2BBHVN3l5ecjNzYVKpYIQAvb29nrVwwBERFSPyGQy+Pr64saNG0hLS4OtrS2cnJy099UislRCCBQXF0OtVkOlUuHKlSto3rw5mut5fykGICKieigwMBAqlQp79+6FUqmUbKoxkTFYW1vD29sbAwcO1PvaQQxARET1kEwmw0MPPYSOHTuisLCQM8OoXrGxsYGrq6v2XmZ61WHA9hARkRmRyWRwdHTkNYGIKsDpAURERNTg8AxQBcr6ypVKpcQtISIiopoq+96uyZg3BqAK3Lx5E4Dm3mNERERkWW7evAk3N7cqy/BeYBVQq9W4ePEiXFxcDD51VKlUwsfHB+fPn6/39xnjvtZfDWl/ua/1V0Pa34ayr0II3Lx5E15eXtVeBJRngCpgZWWFBx54wKjv4erqWq9/Ce/Ffa2/GtL+cl/rr4a0vw1hX6s781OGg6CJiIiowWEAIiIiogaHAcjE5HI5Fi5cCLlcLnVTjI77Wn81pP3lvtZfDWl/G9K+1hQHQRMREVGDwzNARERE1OAwABEREVGDwwBEREREDQ4DEBERETU4DEBGsHLlSvj5+cHe3h4hISHYv39/leU3btyIDh06wN7eHv7+/vjpp59M1FL9xcXFoXv37nBxcUGzZs0wZMgQZGZmVrlNQkICZDKZzmJvb2+iFutv0aJF5drdoUOHKrexxGNaxs/Pr9z+ymQyTJ48ucLylnRcf/vtN0RERMDLywsymQxbt27VeV0IgQULFqB58+ZwcHBAWFgYTp48WW29tf2bN4Wq9rWkpASzZ8+Gv78/nJyc4OXlhaioKFy8eLHKOvX5WzCV6o7tmDFjyrW9f//+1dZraccWQIV/vzKZDEuXLq20TnM+tsbCAGRg69evR0xMDBYuXIhDhw4hMDAQ4eHhuHz5coXl9+zZg5EjR2L8+PE4fPgwhgwZgiFDhuDYsWMmbnnt/Prrr5g8eTL27t2L5ORklJSU4IknnkBhYWGV27m6uuLSpUva5dy5cyZqcd107txZp927d++utKylHtMyBw4c0NnX5ORkAMCwYcMq3cZSjmthYSECAwOxcuXKCl9/5513sHz5cqxatQr79u2Dk5MTwsPDcefOnUrrrO3fvKlUta+3bt3CoUOHMH/+fBw6dAibN29GZmYmnnrqqWrrrc3fgilVd2wBoH///jpt//rrr6us0xKPLQCdfbx06RLWrFkDmUyGZ555psp6zfXYGo0ggwoODhaTJ0/WPlepVMLLy0vExcVVWH748OFi0KBBOutCQkLEf/7zH6O209AuX74sAIhff/210jJr164Vbm5upmuUgSxcuFAEBgbWuHx9OaZlpk2bJlq3bi3UanWFr1vqcQUgtmzZon2uVquFp6enWLp0qXZdXl6ekMvl4uuvv660ntr+zUvh/n2tyP79+wUAce7cuUrL1PZvQSoV7W90dLQYPHhwreqpL8d28ODBol+/flWWsZRja0g8A2RAxcXFOHjwIMLCwrTrrKysEBYWhrS0tAq3SUtL0ykPAOHh4ZWWN1f5+fkAgCZNmlRZrqCgAL6+vvDx8cHgwYNx/PhxUzSvzk6ePAkvLy+0atUKo0aNQlZWVqVl68sxBTS/019++SXGjRtX5Y2BLfW43uvs2bPIycnROXZubm4ICQmp9Njp8zdvrvLz8yGTydCoUaMqy9Xmb8Hc7Nq1C82aNUP79u0xadIkXLt2rdKy9eXY5ubmIjExEePHj6+2rCUfW30wABnQ1atXoVKpoFAodNYrFArk5ORUuE1OTk6typsjtVqN6dOno2fPnnjwwQcrLde+fXusWbMG3333Hb788kuo1Wr06NEDFy5cMGFray8kJAQJCQlISkrCxx9/jLNnz6J37964efNmheXrwzEts3XrVuTl5WHMmDGVlrHU43q/suNTm2Onz9+8Obpz5w5mz56NkSNHVnmjzNr+LZiT/v37Y926dUhJScHbb7+NX3/9FQMGDIBKpaqwfH05tp9//jlcXFzw9NNPV1nOko+tvng3eKqzyZMn49ixY9X2F4eGhiI0NFT7vEePHujYsSM++eQTvP7668Zupt4GDBigfRwQEICQkBD4+vpiw4YNNfpflSVbvXo1BgwYAC8vr0rLWOpxJY2SkhIMHz4cQgh8/PHHVZa15L+FESNGaB/7+/sjICAArVu3xq5du/DYY49J2DLjWrNmDUaNGlXtxARLPrb64hkgA3J3d4e1tTVyc3N11ufm5sLT07PCbTw9PWtV3txMmTIFP/74I3bu3IkHHnigVtva2tqia9euOHXqlJFaZxyNGjVCu3btKm23pR/TMufOncP27dsxYcKEWm1nqce17PjU5tjp8zdvTsrCz7lz55CcnFzl2Z+KVPe3YM5atWoFd3f3Sttu6ccWAH7//XdkZmbW+m8YsOxjW1MMQAZkZ2eHoKAgpKSkaNep1WqkpKTo/A/5XqGhoTrlASA5ObnS8uZCCIEpU6Zgy5Yt2LFjB1q2bFnrOlQqFY4ePYrmzZsboYXGU1BQgNOnT1fabks9pvdbu3YtmjVrhkGDBtVqO0s9ri1btoSnp6fOsVMqldi3b1+lx06fv3lzURZ+Tp48ie3bt6Np06a1rqO6vwVzduHCBVy7dq3StlvysS2zevVqBAUFITAwsNbbWvKxrTGpR2HXN998842Qy+UiISFB/PXXX+KFF14QjRo1Ejk5OUIIIUaPHi3mzJmjLZ+amipsbGzEu+++KzIyMsTChQuFra2tOHr0qFS7UCOTJk0Sbm5uYteuXeLSpUva5datW9oy9+/r4sWLxbZt28Tp06fFwYMHxYgRI4S9vb04fvy4FLtQY6+88orYtWuXOHv2rEhNTRVhYWHC3d1dXL58WQhRf47pvVQqlWjRooWYPXt2udcs+bjevHlTHD58WBw+fFgAEMuWLROHDx/Wznx66623RKNGjcR3330n/vzzTzF48GDRsmVLcfv2bW0d/fr1Ex9++KH2eXV/81Kpal+Li4vFU089JR544AGRnp6u8zdcVFSkreP+fa3ub0FKVe3vzZs3xcyZM0VaWpo4e/as2L59u3jooYdE27ZtxZ07d7R11IdjWyY/P184OjqKjz/+uMI6LOnYGgsDkBF8+OGHokWLFsLOzk4EBweLvXv3al/r06ePiI6O1im/YcMG0a5dO2FnZyc6d+4sEhMTTdzi2gNQ4bJ27Vptmfv3dfr06drPRaFQiIEDB4pDhw6ZvvG1FBkZKZo3by7s7OyEt7e3iIyMFKdOndK+Xl+O6b22bdsmAIjMzMxyr1nycd25c2eFv7dl+6NWq8X8+fOFQqEQcrlcPPbYY+U+A19fX7Fw4UKddVX9zUulqn09e/ZspX/DO3fu1NZx/75W97cgpar299atW+KJJ54QHh4ewtbWVvj6+oqJEyeWCzL14diW+eSTT4SDg4PIy8ursA5LOrbGIhNCCKOeYiIiIiIyMxwDRERERA0OAxARERE1OAxARERE1OAwABEREVGDwwBEREREDQ4DEBERETU4DEBERETU4DAAERERUYPDAEREVIFdu3ZBJpMhLy9P6qYQkREwABEREVGDwwBEREREDQ4DEBGZJbVajbi4OLRs2RIODg4IDAzEpk2bANztnkpMTERAQADs7e3x8MMP49ixYzp1fPvtt+jcuTPkcjn8/Pzw3nvv6bxeVFSE2bNnw8fHB3K5HG3atMHq1at1yhw8eBDdunWDo6MjevTogczMTO1rR44cwaOPPgoXFxe4uroiKCgIf/zxh5E+ESIyJAYgIjJLcXFxWLduHVatWoXjx49jxowZeP755/Hrr79qy7z66qt47733cODAAXh4eCAiIgIlJSUANMFl+PDhGDFiBI4ePYpFixZh/vz5SEhI0G4fFRWFr7/+GsuXL0dGRgY++eQTODs767Rj7ty5eO+99/DHH3/AxsYG48aN0742atQoPPDAAzhw4AAOHjyIOXPmwNbW1rgfDBEZhtS3oyciut+dO3eEo6Oj2LNnj8768ePHi5EjR4qdO3cKAOKbb77Rvnbt2jXh4OAg1q9fL4QQ4rnnnhOPP/64zvavvvqq6NSpkxBCiMzMTAFAJCcnV9iGsvfYvn27dl1iYqIAIG7fvi2EEMLFxUUkJCTUfYeJyOR4BoiIzM6pU6dw69YtPP7443B2dtYu69atw+nTp7XlQkNDtY+bNGmC9u3bIyMjAwCQkZGBnj176tTbs2dPnDx5EiqVCunp6bC2tkafPn2qbEtAQID2cfPmzQEAly9fBgDExMRgwoQJCAsLw1tvvaXTNiIybwxARGR2CgoKAACJiYlIT0/XLn/99Zd2HFBdOTg41KjcvV1aMpkMgGZ8EgAsWrQIx48fx6BBg7Bjxw506tQJW7ZsMUj7iMi4GICIyOx06tQJcrkcWVlZaNOmjc7i4+OjLbd3717t4xs3buDvv/9Gx44dAQAdO3ZEamqqTr2pqalo164drK2t4e/vD7VarTOmSB/t2rXDjBkz8Msvv+Dpp5/G2rVr61QfEZmGjdQNICK6n4uLC2bOnIkZM2ZArVajV69eyM/PR2pqKlxdXeHr6wsAeO2119C0aVMoFArMnTsX7u7uGDJkCADglVdeQffu3fH6668jMjISaWlpWLFiBT766CMAgJ+fH6KjozFu3DgsX74cgYGBOHfuHC5fvozhw4dX28bbt2/j1VdfxbPPPouWLVviwoULOHDgAJ555hmjfS5EZEBSD0IiIqqIWq0W8fHxon379sLW1lZ4eHiI8PBw8euvv2oHKP/www+ic+fOws7OTgQHB4sjR47o1LFp0ybRqVMnYWtrK1q0aCGWLl2q8/rt27fFjBkzRPPmzYWdnZ1o06aNWLNmjRDi7iDoGzduaMsfPnxYABBnz54VRUVFYsSIEcLHx0fY2dkJLy8vMWXKFO0AaSIybzIhhJA4gxER1cquXbvw6KOP4saNG2jUqJHUzSEiC8QxQERERNTgMAARERFRg8MuMCIiImpweAaIiIiIGhwGICIiImpwGICIiIiowWEAIiIiogaHAYiIiIgaHAYgIiIianAYgIiIiKjBYQAiIiKiBuf/ASzMUq9EegAyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the classifier loss and accuracy curves for training and validation data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(historyc2.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(historyc2.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the test data and seperate test data\n",
    "import csv\n",
    "import pandas as pd\n",
    "testdataset=pd.read_csv('Dataset/DACDatatest.csv',index_col=0)\n",
    "testdataset = testdataset[testdataset['Label'] < 155]\n",
    "#testdataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_24416\\2241069678.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  testdatasetRP = pd.concat([testdatasetRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4121, 66)\n",
      "(4121, 57)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','Label']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "\n",
    "testdatasetRP = pd.DataFrame(columns=column1)\n",
    "\n",
    "for seed in range(0,155):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = testdataset[testdataset['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    testdatasetRP = pd.concat([testdatasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(testdataset.shape)\n",
    "print(testdatasetRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=testdatasetRP.drop(columns=['Label'])\n",
    "ytest=testdatasetRP['Label']\n",
    "ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1370e-05\n",
      "Loss: 1.639494439586997e-05\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
