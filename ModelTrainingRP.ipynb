{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Actual data: (25, 3000)\n",
      "Shape of Randome Matrix: 3000 2000\n",
      "Shape of Projected data: (25, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Sparse randome projection example\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "seed=42\n",
    "rng = np.random.RandomState(seed)\n",
    "X = rng.rand(25, 3000)\n",
    "\n",
    "transformer = SparseRandomProjection(n_components=2000, random_state=rng)\n",
    "X_new = transformer.fit_transform(X)\n",
    "print(\"Shape of Actual data:\",X.shape)\n",
    "print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "print(\"Shape of Projected data:\", X_new.shape)\n",
    "#(25, 2759)\n",
    "# very few components are non-zero\n",
    "#np.mean(transformer.components_ != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F57</th>\n",
       "      <th>F58</th>\n",
       "      <th>F59</th>\n",
       "      <th>F60</th>\n",
       "      <th>F61</th>\n",
       "      <th>F62</th>\n",
       "      <th>F63</th>\n",
       "      <th>F64</th>\n",
       "      <th>F65</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.043</td>\n",
       "      <td>A3MC5OA9RXOOFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.043</td>\n",
       "      <td>A3MC5OA9RXOOFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.060</td>\n",
       "      <td>A3MC5OA9RXOOFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.060</td>\n",
       "      <td>A3MC5OA9RXOOFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.010</td>\n",
       "      <td>A3MC5OA9RXOOFH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      F1     F2     F3     F4     F5     F6     F7     F8     F9    F10  ...  \\\n",
       "0  0.041  0.026  0.016  0.018  0.060  0.080  0.052  0.049  0.029  0.021  ...   \n",
       "1  0.041  0.026  0.016  0.018  0.060  0.080  0.052  0.049  0.029  0.021  ...   \n",
       "2  0.040  0.027  0.118  0.068  0.052  0.010  0.021  0.013  0.046  0.064  ...   \n",
       "3  0.040  0.027  0.118  0.068  0.052  0.010  0.021  0.013  0.046  0.064  ...   \n",
       "4  0.021  0.011  0.006  0.011  0.044  0.022  0.011  0.048  0.047  0.080  ...   \n",
       "\n",
       "     F57    F58    F59    F60    F61    F62  F63    F64    F65              ID  \n",
       "0  0.697  0.698  0.698  0.694  0.056  0.039  0.0  0.009  0.043  A3MC5OA9RXOOFH  \n",
       "1  0.697  0.698  0.698  0.694  0.056  0.039  0.0  0.009  0.043  A3MC5OA9RXOOFH  \n",
       "2  0.677  0.677  0.684  0.684  0.105  0.031  0.0  0.008  0.060  A3MC5OA9RXOOFH  \n",
       "3  0.677  0.677  0.684  0.684  0.105  0.031  0.0  0.008  0.060  A3MC5OA9RXOOFH  \n",
       "4  0.667  0.667  0.672  0.677  0.067  0.020  1.0  0.014  0.010  A3MC5OA9RXOOFH  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read all data [194 users' oversampled data]\n",
    "import csv\n",
    "import pandas as pd\n",
    "dataset=pd.read_csv('dataset/AllOversampledNData.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "0      1000\n",
       "1      1000\n",
       "2      1000\n",
       "3      1000\n",
       "4      1000\n",
       "       ... \n",
       "188    1000\n",
       "189    1000\n",
       "190    1000\n",
       "191    1000\n",
       "192    1000\n",
       "Name: ID, Length: 193, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace the user ID by class name and count the number of sample in each class\n",
    "dataset['ID'] = pd.factorize(dataset['ID'])[0]\n",
    "dataset.groupby(['ID'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194999, 66)\n",
      "(194999, 57)\n"
     ]
    }
   ],
   "source": [
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','ID']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "datasetRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,193):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = dataset[dataset['ID']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['ID'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['ID']=seed\n",
    "    datasetRP = pd.concat([datasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(dataset.shape)\n",
    "print(datasetRP.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in training dataset: 96\n",
      "Total user in auxiliary dataset: 97\n"
     ]
    }
   ],
   "source": [
    "#seperate the profile in two groups: (i) Training profile (0-95), and (ii) auxiliary profile (96-193)\n",
    "totalUser= len(pd.unique(datasetRP['ID']))\n",
    "trainingData = datasetRP[datasetRP['ID'] < int(totalUser/2)]\n",
    "auxilaryData = datasetRP[datasetRP['ID'] >= int(totalUser/2)]\n",
    "print(\"Total user in training dataset:\", len(pd.unique(trainingData['ID'])))\n",
    "print(\"Total user in auxiliary dataset:\", len(pd.unique(auxilaryData['ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the traning data for training and testing the model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X=trainingData.drop(columns=['ID'])\n",
    "y=trainingData['ID']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2, random_state=22)\n",
    "\n",
    "ytrain = to_categorical(ytrain)\n",
    "yval = to_categorical(yval)\n",
    "ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62719, 56)\n",
      "(62719, 96)\n",
      "(15680, 56)\n",
      "(15680, 96)\n",
      "(19600, 56)\n",
      "(19600, 96)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xval.shape)\n",
    "print(yval.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary package for a neural network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inlineimport keras\n",
    "from keras.layers import Dense, Dropout, Input,Activation,Dropout, Flatten\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "#from tqdm import tqdm\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "#import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizers for neural network\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "def adam_optimizer():\n",
    "    return Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "def RMSprop_optimizer():\n",
    "    return RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 128)               7296      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,370\n",
      "Trainable params: 141,834\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mdmor\\PythonProjects\\ModelInversion\\.venv\\Lib\\site-packages\\keras\\optimizers\\legacy\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#neural network architecture for model training\n",
    "\n",
    "def create_classifierRP(release=False,totalClass=10):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(128, input_dim=56))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(128))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "\n",
    "  #if release:\n",
    "  classifier.add(Dense(totalClass, activation='softmax'))\n",
    "  #else:\n",
    "  #   classifier.add(Dense(Tuser))\n",
    "  #np.log_softmax_v2(a, axis=axis)\n",
    "  #classifier.add(F.softmax(a, dim=1))\n",
    "\n",
    "  classifier.compile(loss='categorical_crossentropy', optimizer=RMSprop_optimizer(),metrics=['accuracy'])\n",
    "  return classifier\n",
    "\n",
    "Clasf=create_classifierRP()\n",
    "Clasf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mdmor\\PythonProjects\\ModelInversion\\.venv\\Lib\\site-packages\\keras\\optimizers\\legacy\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973/980 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9893WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 4ms/step - loss: 0.0599 - accuracy: 0.9894 - val_loss: 2.8147e-04 - val_accuracy: 0.9998 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "972/980 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9985WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 1.8101e-04 - val_accuracy: 0.9999 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "967/980 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9992WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 4s 4ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 5.8026e-04 - val_accuracy: 0.9997 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "969/980 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9994WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 3.2387e-09 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9996WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 6s 6ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 3.2554e-06 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 1.7773e-05 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "975/980 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9996WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 2.9294e-07 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.1176e-09 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "970/980 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998    WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 1.7562e-09 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 1.5205e-11 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "970/980 [============================>.] - ETA: 0s - loss: 6.4751e-04 - accuracy: 0.9999WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 6.4095e-04 - accuracy: 0.9999 - val_loss: 1.5138e-07 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "975/980 [============================>.] - ETA: 0s - loss: 3.8165e-04 - accuracy: 0.9999WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 3.7971e-04 - accuracy: 0.9999 - val_loss: 2.5168e-08 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 13/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 2.1738e-04 - accuracy: 0.9999WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 2.1738e-04 - accuracy: 0.9999 - val_loss: 3.0411e-11 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 14/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 8.5460e-04 - accuracy: 0.9999WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 7s 7ms/step - loss: 8.5460e-04 - accuracy: 0.9999 - val_loss: 1.1328e-09 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 15/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 4.1739e-04 - accuracy: 0.9999WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 4.1739e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 16/50\n",
      "973/980 [============================>.] - ETA: 0s - loss: 5.3475e-06 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 5.3094e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 17/50\n",
      "971/980 [============================>.] - ETA: 0s - loss: 2.6721e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 6ms/step - loss: 2.6476e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 18/50\n",
      "969/980 [============================>.] - ETA: 0s - loss: 4.8954e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 5.5970e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 19/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 3.0629e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 3.0505e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 20/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 1.4334e-08 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 1.4290e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 21/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 1.8817e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 5s 5ms/step - loss: 1.8740e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 22/50\n",
      "975/980 [============================>.] - ETA: 0s - loss: 1.7728e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 6s 6ms/step - loss: 1.7638e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 23/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 3.8091e-11 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 8s 8ms/step - loss: 3.8014e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 24/50\n",
      "971/980 [============================>.] - ETA: 0s - loss: 2.5513e-10 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 10s 10ms/step - loss: 2.5279e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 25/50\n",
      "971/980 [============================>.] - ETA: 0s - loss: 4.0284e-11 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 10s 10ms/step - loss: 3.9914e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 26/50\n",
      "973/980 [============================>.] - ETA: 0s - loss: 1.5315e-10 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 9s 9ms/step - loss: 1.5205e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 27/50\n",
      "975/980 [============================>.] - ETA: 0s - loss: 2.1014e-11 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 9s 9ms/step - loss: 2.0908e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 28/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 2.6927e-08 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 10s 10ms/step - loss: 2.6845e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 29/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 1.8956e-04 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 9s 10ms/step - loss: 1.8898e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 30/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 6.6272e-07 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 10s 11ms/step - loss: 6.6206e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 31/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 1.5061e-10 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 10s 10ms/step - loss: 1.5015e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 32/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 2.6119e-10 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 15s 15ms/step - loss: 2.6039e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 33/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 2.0929e-11 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 16s 17ms/step - loss: 2.0908e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 34/50\n",
      "975/980 [============================>.] - ETA: 0s - loss: 1.8587e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.8493e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 35/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 2.2869e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 15s 15ms/step - loss: 2.2846e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 36/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 5.1816e-08 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 17s 18ms/step - loss: 5.1816e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 37/50\n",
      "975/980 [============================>.] - ETA: 0s - loss: 9.6092e-10 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 15s 15ms/step - loss: 9.5603e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 38/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 4.1900e-11 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 14s 14ms/step - loss: 4.1815e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 39/50\n",
      "977/980 [============================>.] - ETA: 0s - loss: 1.9065e-11 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 10s 11ms/step - loss: 1.9007e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 40/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 7.9739e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 6s 6ms/step - loss: 7.9659e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 41/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 4.6092e-05 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 10s 10ms/step - loss: 4.5905e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 42/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 1.8828e-05 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 11s 11ms/step - loss: 1.8751e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 43/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 6.1073e-10 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 11s 11ms/step - loss: 6.1012e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 44/50\n",
      "976/980 [============================>.] - ETA: 0s - loss: 1.5458e-10 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 11s 11ms/step - loss: 1.5586e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 45/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 5.1423e-11 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 11s 11ms/step - loss: 5.1319e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 46/50\n",
      "978/980 [============================>.] - ETA: 0s - loss: 7.2562e-10 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 11s 11ms/step - loss: 7.2415e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 47/50\n",
      "979/980 [============================>.] - ETA: 0s - loss: 3.9843e-08 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 10s 10ms/step - loss: 3.9803e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 48/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 2.3395e-04 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 12s 12ms/step - loss: 2.3395e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 49/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 7.9192e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 11s 11ms/step - loss: 7.9192e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 50/50\n",
      "980/980 [==============================] - ETA: 0s - loss: 1.3780e-09 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "980/980 [==============================] - 11s 11ms/step - loss: 1.3780e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "#Train the classifier seperately for black-box attack\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5,min_lr=0.0001)\n",
    "callbacks_list = [learning_rate_reduction]\n",
    "\n",
    "Classfier2= create_classifierRP(True,96)\n",
    "\n",
    "#------Comment will start from here\n",
    "lossc='categorical_crossentropy'\n",
    "optimizerc=RMSprop(lr=0.001, rho=0.9)\n",
    "Classfier2.compile(loss=lossc, optimizer=optimizerc,metrics=['accuracy'])\n",
    "#------Comments will end from here\n",
    "historyc2 =  Classfier2.fit(Xtrain, ytrain, batch_size=64, epochs=50, validation_data=(Xval, yval),verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the classifier loss and accuracy curves for training and validation data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(historyc2.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(historyc2.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Loss: 0.0\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
