{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Info: Estimate the verification accuracy of DAC for project data\n",
    "- Used DAC(RP projected) data to train an NN model\n",
    "- There are 193 different user's profiles and each profiles has 1000 data samples (normalized data)\n",
    "- Devide all profiles in two groups: training  profile (96) and auxilary profiles (96) \n",
    "- Each auxilary data semple has 65 different features and RP prjection moved them to 56 features\n",
    "- Random matrix of RP follow following distributions: Pr(x=+1)= 1/2s; Pr(x=-1)= 1/2s, Pr(x=0)= 1-1/s where s=3\n",
    "- The value of dimension reduction k is calculated by k= [(4+2\\beta)/(\\epsolon^2/2+\\epsolon^3/2)]log (n) where n is total sample in a profile and \\epsolon,\\beta>0\n",
    "- Construct a NN regressor has 4 dense layers along with 'BatchNormalization' and 'relu' activation funcation\n",
    "- Last layer is sigmoid function. Input dimension of model is 65 and output dimension 56.\n",
    "- Trained regressor to recover the plain data from the projected data for the 96 auxilary data classes\n",
    "- This traind regressor will be used to recove the training data of classifer.\n",
    "- Let say attacker has the access of RP data of original data and their corresponding label. Attacker can find it by model inversion attack\n",
    "\n",
    "- Included a summary of the NN architecture\n",
    "- Need shallow as RP make users profile more distinct\n",
    "- For 10 rounds of training training accurach reached to 100.0% and validation accuracy reached to 100.0%\n",
    "- Included a graph that shows change of training and validation acccruacy in different ephocs\n",
    "- Test accruacy 100.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052478</td>\n",
       "      <td>0.277631</td>\n",
       "      <td>0.451259</td>\n",
       "      <td>0.718039</td>\n",
       "      <td>0.462785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>0.167556</td>\n",
       "      <td>-0.021220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.175416</td>\n",
       "      <td>0.183196</td>\n",
       "      <td>0.083857</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>0.183644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052112</td>\n",
       "      <td>0.329417</td>\n",
       "      <td>0.456423</td>\n",
       "      <td>0.707689</td>\n",
       "      <td>0.431129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.188321</td>\n",
       "      <td>-0.046427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001681</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.161923</td>\n",
       "      <td>0.174437</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.172166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044798</td>\n",
       "      <td>0.246703</td>\n",
       "      <td>0.482247</td>\n",
       "      <td>0.682013</td>\n",
       "      <td>0.413386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.219466</td>\n",
       "      <td>-0.084152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.165296</td>\n",
       "      <td>0.176905</td>\n",
       "      <td>0.015824</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.179818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.292016</td>\n",
       "      <td>0.470626</td>\n",
       "      <td>0.711022</td>\n",
       "      <td>0.418269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019350</td>\n",
       "      <td>0.182533</td>\n",
       "      <td>-0.089321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.009006</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.165296</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.183644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048638</td>\n",
       "      <td>0.282665</td>\n",
       "      <td>0.438347</td>\n",
       "      <td>0.712347</td>\n",
       "      <td>0.447676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023968</td>\n",
       "      <td>0.151995</td>\n",
       "      <td>-0.024688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001410</td>\n",
       "      <td>0.007316</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.175416</td>\n",
       "      <td>0.184353</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.183644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5    6    7         8  \\\n",
       "0  0.052478  0.277631  0.451259  0.718039  0.462785  0.0  0.0  0.018702   \n",
       "1  0.052112  0.329417  0.456423  0.707689  0.431129  0.0  0.0  0.018824   \n",
       "2  0.044798  0.246703  0.482247  0.682013  0.413386  0.0  0.0  0.023549   \n",
       "3  0.050101  0.292016  0.470626  0.711022  0.418269  0.0  0.0  0.019350   \n",
       "4  0.048638  0.282665  0.438347  0.712347  0.447676  0.0  0.0  0.023968   \n",
       "\n",
       "          9        10  ...        25        26        27        28        29  \\\n",
       "0  0.167556 -0.021220  ... -0.000286  0.006156  0.000038  0.098039  0.175416   \n",
       "1  0.188321 -0.046427  ... -0.001681  0.006563  0.000043  0.172549  0.161923   \n",
       "2  0.219466 -0.084152  ... -0.003980  0.007612  0.000058  0.172549  0.165296   \n",
       "3  0.182533 -0.089321  ...  0.000438  0.009006  0.000081  0.149020  0.165296   \n",
       "4  0.151995 -0.024688  ... -0.001410  0.007316  0.000054  0.125490  0.175416   \n",
       "\n",
       "         30        31        32        33  Label  \n",
       "0  0.183196  0.083857  0.007032  0.183644      0  \n",
       "1  0.174437  0.012390  0.000154  0.172166      0  \n",
       "2  0.176905  0.015824  0.000250  0.179818      0  \n",
       "3  0.178174  0.036672  0.001343  0.183644      0  \n",
       "4  0.184353  0.061493  0.003786  0.183644      0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read all data [194 users' oversampled data]\n",
    "import csv\n",
    "import pandas as pd\n",
    "dataset=pd.read_csv('Dataset/OversampledSwipeData.csv',index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0     300\n",
       "1     300\n",
       "2     300\n",
       "3     300\n",
       "4     300\n",
       "     ... \n",
       "81    300\n",
       "82    300\n",
       "83    300\n",
       "84    300\n",
       "85    300\n",
       "Name: Label, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace the user ID by class name and count the number of sample in each class\n",
    "#dataset['Label'] = pd.factorize(dataset['Label'])[0]\n",
    "dataset.groupby(['Label'])['Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in training dataset: 68\n",
      "Total user in auxiliary dataset: 18\n"
     ]
    }
   ],
   "source": [
    "#seperate the profile in two groups: (i) Training profile (0-95), and (ii) auxiliary profile (96-193)\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData = dataset[dataset['Label'] < 68]\n",
    "attackData = dataset[dataset['Label'] >= 68]\n",
    "print(\"Total user in training dataset:\", len(pd.unique(trainingData['Label'])))\n",
    "print(\"Total user in auxiliary dataset:\", len(pd.unique(attackData['Label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1         1.000000\n",
      "2         1.000000\n",
      "3         0.881859\n",
      "4         1.000000\n",
      "5         1.000000\n",
      "6         0.978824\n",
      "7         0.916667\n",
      "8         0.558563\n",
      "9         0.970466\n",
      "10        0.228430\n",
      "11        1.000000\n",
      "12        1.000000\n",
      "13        0.698851\n",
      "14        1.000000\n",
      "15        0.970992\n",
      "16        1.000000\n",
      "17        0.937500\n",
      "18        0.970820\n",
      "19        1.000000\n",
      "20        1.000000\n",
      "21        1.000000\n",
      "22        1.000000\n",
      "23        0.071859\n",
      "24        1.000000\n",
      "25        0.691649\n",
      "26        1.000000\n",
      "27        1.000000\n",
      "28        1.000000\n",
      "29        1.000000\n",
      "30        1.000000\n",
      "31        1.000000\n",
      "32        1.000000\n",
      "33        1.000000\n",
      "Label    67.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#value range of training data\n",
    "print(trainingData.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When attacker only knows the distribution of R, attacker will train the attack model by the reandom projected attack data that are train by random generated RP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 34)\n",
      "(5400, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_27732\\3965929912.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  attackDataRP = pd.concat([attackDataRP, XRP], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#Random project the attack dataset\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30','Label']\n",
    "column2=column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30']\n",
    "attackDataRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(68,86):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = attackData[attackData['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=30, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    attackDataRP = pd.concat([attackDataRP, XRP], ignore_index=True)\n",
    "    #print(auxilaryDataRP)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(attackData.shape)\n",
    "print(attackDataRP.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       68.0\n",
      "1       68.0\n",
      "2       68.0\n",
      "3       68.0\n",
      "4       68.0\n",
      "        ... \n",
      "5395    85.0\n",
      "5396    85.0\n",
      "5397    85.0\n",
      "5398    85.0\n",
      "5399    85.0\n",
      "Name: Label, Length: 5400, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#user id in auxilary data\n",
    "print(attackDataRP['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the traning data for training and testing the attacker's model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Xdata=attackData.drop(columns=['Label'])\n",
    "XRPdata=attackDataRP.drop(columns=['Label'])\n",
    "\n",
    "\n",
    "Xtrain, Xval, XRPtrain, XRPval = train_test_split(Xdata, XRPdata, test_size=0.2, random_state=22)\n",
    "#Xtrain, Xval, XRPtrain, XRPval = train_test_split(Xtrain, XRPtrain, test_size=0.3, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 33)\n",
      "(4320, 30)\n",
      "(1080, 33)\n",
      "(1080, 30)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(XRPtrain.shape)\n",
    "#print(Xtest.shape)\n",
    "#print(XRPtest.shape)\n",
    "print(Xval.shape)\n",
    "print(XRPval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary package for a neural network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inlineimport keras\n",
    "from keras.layers import Dense, Dropout, Input,Activation,Dropout, Flatten\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "#from tqdm import tqdm\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "#import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizers for neural network\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "def adam_optimizer():\n",
    "    return Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "def RMSprop_optimizer():\n",
    "    return RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m3,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)             │         \u001b[38;5;34m4,257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,009</span> (558.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m143,009\u001b[0m (558.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141,473</span> (552.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m141,473\u001b[0m (552.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#neural network architecture for training a regressor\n",
    "\n",
    "def create_Regressor(release=False,outDim=33):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(128, input_dim=30))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  #classifier.add(Dropout(0.2))\n",
    "   \n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  #classifier.add(Dropout(0.2))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  #classifier.add(Dropout(0.2))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(128))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  #classifier.add(Dropout(0.2))\n",
    "\n",
    "  #if release:\n",
    "  classifier.add(Dense(outDim, activation='sigmoid'))\n",
    "  #else:\n",
    "  #   classifier.add(Dense(Tuser))\n",
    "  #np.log_softmax_v2(a, axis=axis)\n",
    "  #classifier.add(F.softmax(a, dim=1))\n",
    "\n",
    "  classifier.compile(loss='mean_squared_error', optimizer='SGD',metrics=['mean_squared_error'])\n",
    "  return classifier\n",
    "\n",
    "Clasf=create_Regressor()\n",
    "Clasf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0966 - mean_squared_error: 0.0966 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 2/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0305 - val_mean_squared_error: 0.0305\n",
      "Epoch 3/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
      "Epoch 4/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 5/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 6/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 7/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 8/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 9/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 10/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 11/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 12/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 13/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 14/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 15/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 16/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 17/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 18/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 19/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 20/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 21/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 22/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 23/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 24/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 25/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 26/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 27/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 28/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 29/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 30/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 32/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 33/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 35/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 36/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 37/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 38/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 39/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 40/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 41/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 42/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 43/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 44/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 45/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 46/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 47/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 48/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 49/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 50/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n"
     ]
    }
   ],
   "source": [
    "#Train the regressor  by auxilary dataset\n",
    "# Input: Projected data\n",
    "# Output: Plain data\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5,min_lr=0.0001)\n",
    "callbacks_list = [learning_rate_reduction]\n",
    "\n",
    "Regressor= create_Regressor(True,33)\n",
    "\n",
    "#------Comment will start from here\n",
    "lossc='mean_squared_error'\n",
    "optimizerc=RMSprop(learning_rate=0.001, rho=0.9)\n",
    "Regressor.compile(loss=lossc, optimizer=optimizerc,metrics=['mean_squared_error'])\n",
    "#------Comments will end from here\n",
    "Rhistoryc2 =  Regressor.fit(XRPtrain, Xtrain, batch_size=64, epochs=50, validation_data=(XRPval, Xval),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the classifier loss and accuracy curves for training and validation data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Rhistoryc2.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(Rhistoryc2.history['val_loss'], color='r',label=\"Validation loss\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test the model by pre-seperated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the test data and seperate test data\n",
    "import csv\n",
    "import pandas as pd\n",
    "testattackdata=pd.read_csv('Dataset/SwipeDatatest.csv',index_col=0)\n",
    "testattackdata = testattackdata[testattackdata['Label'] >= 68]\n",
    "#testdataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425, 34)\n",
      "(425, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_27732\\378522388.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  testattackDataRP = pd.concat([testattackDataRP, XRP], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#Random project the auxiliary dataset\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30','Label']\n",
    "column2=column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30']\n",
    "testattackDataRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(68,86):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = testattackdata[testattackdata['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=30, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    testattackDataRP = pd.concat([testattackDataRP, XRP], ignore_index=True)\n",
    "    #print(auxilaryDataRP)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(testattackdata.shape)\n",
    "print(testattackDataRP.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testattackdata=testattackdata.drop(columns=['Label'])\n",
    "testattackDataRP=testattackDataRP.drop(columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0437 - mean_squared_error: 0.0437 \n",
      "Loss: 0.04291098192334175\n",
      "Accuracy: 0.04291098192334175\n"
     ]
    }
   ],
   "source": [
    "#Performance of the trained attacker regressor\n",
    "loss, accuracy = Regressor.evaluate(testattackDataRP, testattackdata)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let say attacker has the access of Random projected data of the original data profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_27732\\2605144147.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  trainingDataRP = pd.concat([trainingDataRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20400, 34)\n",
      "(20400, 31)\n"
     ]
    }
   ],
   "source": [
    "#Let say attacker has the access of RP data of original data\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30','Label']\n",
    "column2=column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30']\n",
    "trainingDataRP = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,68):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = trainingData[trainingData['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=30, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    trainingDataRP = pd.concat([trainingDataRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(trainingData.shape)\n",
    "print(trainingDataRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "20395    67.0\n",
      "20396    67.0\n",
      "20397    67.0\n",
      "20398    67.0\n",
      "20399    67.0\n",
      "Name: Label, Length: 20400, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#user id in original projected data\n",
    "print(trainingDataRP['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "(20400, 33)\n"
     ]
    }
   ],
   "source": [
    "#Prediction of plain data by the attacker mdoel assuming that attacker has access of projected data\n",
    "tDataRP=trainingDataRP.drop(columns=['Label'])\n",
    "tDataReg= Regressor.predict(tDataRP)\n",
    "print(tDataReg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#assume that along with project data attacker know the label of the data.\n",
    "# Add id with recovered data\n",
    "print(type(tDataReg))\n",
    "print(type(trainingDataRP['Label'].to_numpy()))\n",
    "traningdataReg = pd.concat([pd.DataFrame(tDataReg), trainingDataRP['Label'].to_frame()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20400, 34)\n"
     ]
    }
   ],
   "source": [
    "# recovered data by the attacker model from projected data\n",
    "print(traningdataReg.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To test the qulity of recover data we did this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1         2         3         4         5         6         7  \\\n",
      "0      0.032680  0.370753  0.476616  0.570317  0.566552  0.274710  0.076256   \n",
      "1      0.029372  0.344024  0.457228  0.544581  0.550227  0.286820  0.092882   \n",
      "2      0.035404  0.345655  0.415918  0.511967  0.533250  0.286831  0.094000   \n",
      "3      0.035516  0.352978  0.437762  0.524220  0.558556  0.284170  0.082641   \n",
      "4      0.030678  0.362171  0.456348  0.561425  0.559586  0.272875  0.077437   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "20395  0.020455  0.485648  0.620453  0.654131  0.464135  0.097189  0.240331   \n",
      "20396  0.019439  0.481310  0.632519  0.681990  0.476812  0.083126  0.249748   \n",
      "20397  0.026972  0.517533  0.622974  0.678244  0.463813  0.102897  0.293118   \n",
      "20398  0.029807  0.514943  0.622744  0.613524  0.459855  0.140712  0.276386   \n",
      "20399  0.042534  0.540828  0.554335  0.497912  0.457573  0.164414  0.294056   \n",
      "\n",
      "              8         9        10  ...        25        26        27  \\\n",
      "0      0.047228  0.338977  0.003157  ...  0.009369  0.018156  0.010173   \n",
      "1      0.052592  0.309760  0.003186  ...  0.009392  0.015771  0.008707   \n",
      "2      0.057211  0.288084  0.003959  ...  0.009635  0.015708  0.009427   \n",
      "3      0.057749  0.328954  0.003945  ...  0.010143  0.017206  0.009818   \n",
      "4      0.049105  0.321136  0.003141  ...  0.008741  0.016797  0.009313   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "20395  0.099859  0.552508  0.005340  ...  0.012308  0.023312  0.009763   \n",
      "20396  0.093211  0.523862  0.004927  ...  0.011832  0.023765  0.009639   \n",
      "20397  0.088893  0.492691  0.007372  ...  0.019250  0.032037  0.011255   \n",
      "20398  0.149944  0.583731  0.010868  ...  0.017143  0.021922  0.010179   \n",
      "20399  0.097394  0.585197  0.005915  ...  0.018076  0.015586  0.004474   \n",
      "\n",
      "             28        29        30        31        32        33  Label  \n",
      "0      0.740294  0.633950  0.547275  0.050078  0.009054  0.588988    0.0  \n",
      "1      0.726421  0.619307  0.516250  0.049346  0.008238  0.579021    0.0  \n",
      "2      0.735141  0.620582  0.560139  0.047784  0.010446  0.555019    0.0  \n",
      "3      0.750245  0.621482  0.546003  0.047721  0.010679  0.568124    0.0  \n",
      "4      0.726043  0.627213  0.530291  0.048130  0.009061  0.576090    0.0  \n",
      "...         ...       ...       ...       ...       ...       ...    ...  \n",
      "20395  0.645645  0.640191  0.743847  0.024403  0.012905  0.920745   67.0  \n",
      "20396  0.718774  0.659325  0.784859  0.023258  0.010790  0.938333   67.0  \n",
      "20397  0.594230  0.600757  0.718773  0.036536  0.016176  0.910589   67.0  \n",
      "20398  0.471904  0.613810  0.707813  0.042116  0.023198  0.876611   67.0  \n",
      "20399  0.333931  0.546411  0.731971  0.066802  0.050664  0.814996   67.0  \n",
      "\n",
      "[20400 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "traningdataReg.columns=list(trainingData.columns)\n",
    "print(traningdataReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "allPvalue=np.zeros((86,33))\n",
    "for id in range(0,68):\n",
    "    dataset1=traningdataReg[traningdataReg['Label']==id]\n",
    "    dataset2=trainingData[trainingData['Label']==id]\n",
    "    for col in range (0,33):\n",
    "        sample1=dataset1.iloc[:,col]\n",
    "        sample2=dataset2.iloc[:,col]\n",
    "        statistics, allPvalue[id,col]=stats.kstest(sample1, sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.51803856e-023 1.14206452e-151 3.74262317e-028 ... 4.22238366e-021\n",
      "  1.86743629e-091 1.48029788e-179]\n",
      " [7.09312363e-137 2.36785122e-111 5.55983928e-144 ... 8.66702156e-068\n",
      "  1.48029788e-179 1.48029788e-179]\n",
      " [1.63129640e-148 1.48029788e-179 5.90299077e-129 ... 5.30245661e-172\n",
      "  3.46788500e-048 1.48029788e-179]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "print(allPvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "allPvalue = np.where(allPvalue < 0.05, 0, 1)\n",
    "#allPvalue[allPvalue < 0.05] = 0\n",
    "print(allPvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(allPvalue, axis=1))\n",
    "print(len(allPvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGyCAYAAAAYveVYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAw9ElEQVR4nO3dfVRU9aL/8c8AMsAxIUVACERNU1OR5Er4cMqkY2aUeW6ZecWj5r2mpklPUuZDncRjadrJcmkqudI0K83SixqK3oo0TcyH1FQKrgE+HUTRQJn9+6Ofcw8HLDYODGzfr7X2Ws53f/fsz6zNqs/aDzM2wzAMAQAAWISHuwMAAAC4EuUGAABYCuUGAABYCuUGAABYCuUGAABYCuUGAABYCuUGAABYCuUGAABYCuUGAABYipe7A9Q2h8Ohn3/+WTfccINsNpu74wAAgCowDEPnzp1TaGioPDx+59yM4UZbt2417rvvPqNZs2aGJGP16tW/u80vv/xiPP/880ZERITh7e1tNG/e3Fi0aFGV95mbm2tIYmFhYWFhYamHS25u7u/+v96tZ26Ki4sVFRWl4cOHa8CAAVXa5uGHH1ZBQYEWLVqkm2++WXl5eXI4HFXe5w033CBJys3NVaNGjaqVGwAA1K6ioiKFh4c7/z/+W9xabvr27au+fftWeX5aWpq2bt2qY8eOqXHjxpKkyMhIU/u8cimqUaNGlBsAAOqZqtxSUq9uKF67dq1iYmI0c+ZMhYWFqU2bNnr66ad18eLFq25TUlKioqKicgsAALCuenVD8bFjx/TFF1/Ix8dHq1ev1qlTpzR69GidPn1aS5YsqXSblJQUTZs2rZaTAgAAd6lXZ24cDodsNpuWLVumrl276t5779Xs2bP17rvvXvXsTXJyss6ePetccnNzazk1AACoTfXqzE2zZs0UFhYmf39/51i7du1kGIb+93//V61bt66wjd1ul91ur82YAADAjerVmZvu3bvr559/1vnz551jhw8floeHh2666SY3JgMAAHWFW8vN+fPnlZWVpaysLElSdna2srKylJOTI+nXS0qJiYnO+Y8++qiaNGmiYcOG6cCBA9q2bZueeeYZDR8+XL6+vu74CAAAoI5xa7nZuXOnoqOjFR0dLUlKSkpSdHS0Jk+eLEnKy8tzFh1JatiwoTZt2qTCwkLFxMRo8ODBSkhI0BtvvOGW/AAAoO6xGYZhuDtEbSoqKpK/v7/Onj3L99wAAFBPmPn/d7265wYAAOD3UG4AAIClUG4AAIClUG4AAIClUG4AAIClUG4AAIClUG4AAICl1KvflgJqSuTEdRXGfpzRzw1JgKr717/b+v43a7XPA/fhzA0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUyg0AALAUt5abbdu2KSEhQaGhobLZbFqzZk2Vt/3yyy/l5eWlzp0711g+AABQ/7i13BQXFysqKkrz5s0ztV1hYaESExPVu3fvGkoGAADqKy937rxv377q27ev6e1GjRqlRx99VJ6enr97tqekpEQlJSXO10VFRab3BwAA6o96d8/NkiVLdOzYMU2ZMqVK81NSUuTv7+9cwsPDazghAABwp3pVbn744QdNnDhR7733nry8qnbSKTk5WWfPnnUuubm5NZwSAAC4k1svS5lRVlamRx99VNOmTVObNm2qvJ3dbpfdbq/BZAAAoC6pN+Xm3Llz2rlzp3bv3q2xY8dKkhwOhwzDkJeXlzZu3Ki77rrLzSkBAIC71Zty06hRI+3du7fc2FtvvaXNmzfrww8/VIsWLdyUDAAA1CVuLTfnz5/XkSNHnK+zs7OVlZWlxo0bKyIiQsnJyTp+/LiWLl0qDw8PdejQodz2QUFB8vHxqTAOAACuX24tNzt37lSvXr2cr5OSkiRJQ4cOVWpqqvLy8pSTk+OueAAAoB5ya7m58847ZRjGVdenpqb+5vZTp07V1KlTXRsKAADUa/XqUXAAAIDfQ7kBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACWQrkBAACW4tZys23bNiUkJCg0NFQ2m01r1qz5zfkff/yx7r77bjVt2lSNGjVSXFycNmzYUDthAQBAveDWclNcXKyoqCjNmzevSvO3bdumu+++W+vXr9euXbvUq1cvJSQkaPfu3TWcFAAA1Bde7tx537591bdv3yrPnzNnTrnX06dP1yeffKJPP/1U0dHRlW5TUlKikpIS5+uioqJqZQUAAPVDvb7nxuFw6Ny5c2rcuPFV56SkpMjf39+5hIeH12JCAABQ2+p1uXnttdd0/vx5Pfzww1edk5ycrLNnzzqX3NzcWkwIAABqm1svS12L5cuXa9q0afrkk08UFBR01Xl2u112u70WkwEAAHeql+VmxYoVeuyxx7Rq1SrFx8e7Ow4AAKhD6t1lqffff1/Dhg3T+++/r379+rk7DgAAqGPceubm/PnzOnLkiPN1dna2srKy1LhxY0VERCg5OVnHjx/X0qVLJf16KWro0KGaO3euYmNjlZ+fL0ny9fWVv7+/Wz4DAACoW9x65mbnzp2Kjo52PsadlJSk6OhoTZ48WZKUl5ennJwc5/wFCxbo8uXLGjNmjJo1a+Zcxo8f75b8AACg7nHrmZs777xThmFcdX1qamq51xkZGTUbCAAA1Hv17p4bAACA30K5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlkK5AQAAlnLN5aaoqEhr1qzR999/74o8AAAA18R0uXn44Yf15ptvSpIuXryomJgYPfzww+rUqZM++ugjlwcEAAAww3S52bZtm3r27ClJWr16tQzDUGFhod544w399a9/dXlAAAAAM0yXm7Nnz6px48aSpLS0NP35z3+Wn5+f+vXrpx9++MHlAQEAAMwwXW7Cw8OVmZmp4uJipaWl6U9/+pMk6R//+Id8fHxcHhAAAMAML7MbPPnkkxo8eLAaNmyoiIgI3XnnnZJ+vVzVsWNHV+cDAAAwxXS5GT16tLp27arc3Fzdfffd8vD49eRPy5YtuecGAAC4nelyI0kxMTHq1KmTsrOz1apVK3l5ealfv36uzgYAAGCa6XtuLly4oBEjRsjPz0+33nqrcnJyJElPPPGEZsyY4fKAAAAAZpguN8nJydqzZ48yMjLK3UAcHx+vlStXujQcAACAWaYvS61Zs0YrV67U7bffLpvN5hy/9dZbdfToUZeGAwAAMMv0mZuTJ08qKCiownhxcXG5sgMAAOAOpstNTEyM1q1b53x9pdC88847iouLc10yAACAajB9WWr69Onq27evDhw4oMuXL2vu3Lk6cOCAvvrqK23durUmMgIAAFSZ6TM3PXr00J49e3T58mV17NhRGzduVFBQkDIzM9WlS5eayAgAAFBlps7cXLp0Sf/1X/+lF198UQsXLqypTAAAANVm6sxNgwYN9NFHH9VUFgAAgGtm+rJU//79tWbNGpfsfNu2bUpISFBoaKhsNluV3jcjI0O33Xab7Ha7br75ZqWmprokCwAAsAbTNxS3bt1aL730kr788kt16dJFf/jDH8qtHzduXJXfq7i4WFFRURo+fLgGDBjwu/Ozs7PVr18/jRo1SsuWLVN6eroee+wxNWvWTH369DH7UQAAgAWZLjeLFi1SQECAdu3apV27dpVbZ7PZTJWbvn37qm/fvlWeP3/+fLVo0UKzZs2SJLVr105ffPGFXn/9dcoNAACQVI1yk52dXRM5qiQzM1Px8fHlxvr06aMnn3zyqtuUlJSopKTE+bqoqKim4gEAgDrA9D037pSfn6/g4OByY8HBwSoqKtLFixcr3SYlJUX+/v7OJTw8vDaiAgAANzF95mb48OG/uX7x4sXVDlMTkpOTlZSU5HxdVFREwQEAwMJMl5t//OMf5V5funRJ+/btU2Fhoe666y6XBatMSEiICgoKyo0VFBSoUaNG8vX1rXQbu90uu91eo7kAAEDdYbrcrF69usKYw+HQ448/rlatWrkk1NXExcVp/fr15cY2bdrEb1oBAAAnl9xz4+HhoaSkJL3++uumtjt//ryysrKUlZUl6deblbOyspSTkyPp10tKiYmJzvmjRo3SsWPH9Oyzz+rgwYN666239MEHH2jChAmu+BgAAMACXHZD8dGjR3X58mVT2+zcuVPR0dGKjo6WJCUlJSk6OlqTJ0+WJOXl5TmLjiS1aNFC69at06ZNmxQVFaVZs2bpnXfe4TFwAADgZPqy1D/fnCtJhmEoLy9P69at09ChQ02915133inDMK66vrJvH77zzju1e/duU/sBAADXD9Pl5l+LhYeHh5o2bapZs2b97pNUAAAANc10udmyZUtN5AAAAHAJ0/fc3HXXXSosLKwwXlRUVOOPggMAAPwe0+UmIyNDpaWlFcZ/+eUX/c///I9LQgEAAFRXlS9Lfffdd85/HzhwQPn5+c7XZWVlSktLU1hYmGvTAQAAmFTlctO5c2fZbDbZbLZKLz/5+vrq73//u0vDAQAAmFXlcpOdnS3DMNSyZUvt2LFDTZs2da7z9vZWUFCQPD09ayQkAABAVVW53DRv3lzSrz+1AAAAUFeZfhT8igMHDignJ6fCzcX333//NYcCAACoLtPl5tixY3rwwQe1d+9e2Ww25zcM22w2Sb/eXAwAAOAuph8FHz9+vFq0aKETJ07Iz89P+/fv17Zt2xQTE6OMjIwaiAgAAFB1ps/cZGZmavPmzQoMDJSHh4c8PDzUo0cPpaSkaNy4cfzuEwAAcCvTZ27Kysp0ww03SJICAwP1888/S/r1huNDhw65Nh0AAIBJps/cdOjQQXv27FGLFi0UGxurmTNnytvbWwsWLFDLli1rIiMAAECVmS43kyZNUnFxsSTppZde0n333aeePXuqSZMmWrlypcsDAgAAmGG63PTp08f575tvvlkHDx7UmTNndOONNzqfmAIAAHAX0/fcXHHkyBFt2LBBFy9eVOPGjV2ZCQAAoNpMl5vTp0+rd+/eatOmje69917l5eVJkkaMGKGnnnrK5QEBAADMMF1uJkyYoAYNGignJ0d+fn7O8YEDByotLc2l4QAAAMwyfc/Nxo0btWHDBt10003lxlu3bq2ffvrJZcEAAACqw/SZm+Li4nJnbK44c+aM7Ha7S0IBAABUl+ly07NnTy1dutT52mazyeFwaObMmerVq5dLwwEAAJhl+rLUzJkz1bt3b+3cuVOlpaV69tlntX//fp05c0ZffvllTWQEAACoMtNnbjp06KDDhw+rR48eeuCBB1RcXKwBAwZo9+7datWqVU1kBAAAqLIqnbkZMGCAUlNT1ahRIy1dulQDBw7UCy+8UNPZAAAATKvSmZvPPvvM+ZMLw4YN09mzZ2s0FAAAQHVV6cxN27ZtlZycrF69eskwDH3wwQdq1KhRpXMTExNdGhAAAMCMKpWb+fPnKykpSevWrZPNZtOkSZMq/R0pm81GuQEAAG5VpXLTrVs3ff3115IkDw8PHT58WEFBQTUaDAAAoDpMPy2VnZ2tpk2b1kQWAACAa2b6e26aN29eEzkAAABcwvSZGwAAgLqMcgMAACylSuVm7dq1unTpUk1nAQAAuGZVKjcPPvigCgsLJUmenp46ceJETWYCAACotiqVm6ZNmzofBTcMo9LvuLkW8+bNU2RkpHx8fBQbG6sdO3b85vw5c+bolltuka+vr8LDwzVhwgT98ssvLs0EAADqpyo9LTVq1Cg98MADstlsstlsCgkJuercsrIyUwFWrlyppKQkzZ8/X7GxsZozZ4769OmjQ4cOVfpdOsuXL9fEiRO1ePFidevWTYcPH9Zf/vIX2Ww2zZ4929S+AQCA9VSp3EydOlWPPPKIjhw5ovvvv19LlixRQECASwLMnj1bI0eO1LBhwyT9+m3I69at0+LFizVx4sQK87/66it1795djz76qCQpMjJSgwYN0vbt212SBwAA1G9V/p6btm3bqm3btpoyZYoeeugh+fn5XfPOS0tLtWvXLiUnJzvHPDw8FB8fr8zMzEq36datm9577z3t2LFDXbt21bFjx7R+/XoNGTKk0vklJSUqKSlxvi4qKrrm3AAAoO4y/SV+U6ZMkSSdPHlShw4dkiTdcsst1frW4lOnTqmsrEzBwcHlxoODg3Xw4MFKt3n00Ud16tQp9ejRQ4Zh6PLlyxo1apSef/75SuenpKRo2rRpprMBAID6yfT33Fy4cEHDhw9XaGio/vjHP+qPf/yjQkNDNWLECF24cKEmMpaTkZGh6dOn66233tK3336rjz/+WOvWrdPLL79c6fzk5GSdPXvWueTm5tZ4RgAA4D6my82ECRO0detWrV27VoWFhSosLNQnn3yirVu36qmnnjL1XoGBgfL09FRBQUG58YKCgqvetPziiy9qyJAheuyxx9SxY0c9+OCDmj59ulJSUuRwOCrMt9vtatSoUbkFAABYl+ly89FHH2nRokXq27evsyzce++9WrhwoT788ENT7+Xt7a0uXbooPT3dOeZwOJSenq64uLhKt7lw4YI8PMrH9vT0lPTrY+oAAOD6ZvqemwsXLlS4R0aSgoKCqnVZKikpSUOHDlVMTIy6du2qOXPmqLi42Pn0VGJiosLCwpSSkiJJSkhI0OzZsxUdHa3Y2FgdOXJEL774ohISEpwlBwAAXL9Ml5u4uDhNmTJFS5culY+PjyTp4sWLmjZt2lXPtvyWgQMH6uTJk5o8ebLy8/PVuXNnpaWlOQtUTk5OuTM1kyZNks1m06RJk3T8+HE1bdpUCQkJeuWVV0zvGwAAWI/NMHktZ9++ferTp49KSkoUFRUlSdqzZ498fHy0YcMG3XrrrTUS1FWKiork7++vs2fPcv8NnCInrqsw9uOMfm5IAlTdv/7d1ve/Wat9HriWmf9/mz5z06FDB/3www9atmyZ83HtQYMGafDgwfL19a1eYgAAABcxXW4kyc/PTyNHjnR1FgAAgGtm+mkpAACAuoxyAwAALIVyAwAALIVyAwAALMV0uWnZsqVOnz5dYbywsFAtW7Z0SSgAAIDqMl1ufvzxR5WVlVUYLykp0fHjx10SCgAAoLqq/Cj42rVrnf/esGGD/P39na/LysqUnp6uyMhIl4YDAAAwq8rlpn///pIkm82moUOHllvXoEEDRUZGatasWS4NBwAAYFaVy43D4ZAktWjRQt98840CAwNrLBQAAEB1mf6G4uzs7JrIAQAA4BLV+vmF9PR0paen68SJE84zOlcsXrzYJcEAAACqw3S5mTZtml566SXFxMSoWbNmstlsNZELAACgWkyXm/nz5ys1NVVDhgypiTwAAADXxPT33JSWlqpbt241kQUAAOCamS43jz32mJYvX14TWQAAAK6Z6ctSv/zyixYsWKDPP/9cnTp1UoMGDcqtnz17tsvCAQAAmGW63Hz33Xfq3LmzJGnfvn3l1nFzMQAAcDfT5WbLli01kQMAAMAlTN9zc8WRI0e0YcMGXbx4UZJkGIbLQgEAAFSX6XJz+vRp9e7dW23atNG9996rvLw8SdKIESP01FNPuTwgAACAGabLzYQJE9SgQQPl5OTIz8/POT5w4EClpaW5NBwAAIBZpu+52bhxozZs2KCbbrqp3Hjr1q31008/uSwYAABAdZg+c1NcXFzujM0VZ86ckd1ud0koAACA6jJdbnr27KmlS5c6X9tsNjkcDs2cOVO9evVyaTgAAACzTF+Wmjlzpnr37q2dO3eqtLRUzz77rPbv368zZ87oyy+/rImMAAAAVWb6zE2HDh10+PBh9ejRQw888ICKi4s1YMAA7d69W61ataqJjAAAAFVm+syNJPn7++uFF15wdRYAAIBrZvrMzZIlS7Rq1aoK46tWrdK7777rklAAAADVZbrcpKSkKDAwsMJ4UFCQpk+f7pJQAAAA1WW63OTk5KhFixYVxps3b66cnByXhAIAAKgu0+UmKChI3333XYXxPXv2qEmTJi4JBQAAUF2my82gQYM0btw4bdmyRWVlZSorK9PmzZs1fvx4PfLIIzWREQAAoMpMPy318ssv68cff1Tv3r3l5fXr5g6HQ4mJidxzAwAA3M7UmRvDMJSfn6/U1FQdOnRIy5Yt08cff6yjR49q8eLF8vb2rlaIefPmKTIyUj4+PoqNjdWOHTt+c35hYaHGjBmjZs2ayW63q02bNlq/fn219g0AAKzF1JkbwzB08803a//+/WrdurVat259zQFWrlyppKQkzZ8/X7GxsZozZ4769OmjQ4cOKSgoqML80tJS3X333QoKCtKHH36osLAw/fTTTwoICLjmLAAAoP4zVW48PDzUunVrnT592iXFRpJmz56tkSNHatiwYZKk+fPna926dVq8eLEmTpxYYf7ixYt15swZffXVV2rQoIEkKTIy8qrvX1JSopKSEufroqIil+QGAAB1k+kbimfMmKFnnnlG+/btu+adl5aWateuXYqPj/+/QB4eio+PV2ZmZqXbrF27VnFxcRozZoyCg4PVoUMHTZ8+XWVlZZXOT0lJkb+/v3MJDw+/5twAAKDuMn1DcWJioi5cuKCoqCh5e3vL19e33PozZ85U+b1OnTqlsrIyBQcHlxsPDg7WwYMHK93m2LFj2rx5swYPHqz169fryJEjGj16tC5duqQpU6ZUmJ+cnKykpCTn66KiIgoOAAAWZrrczJkzpwZiVJ3D4VBQUJAWLFggT09PdenSRcePH9err75aabmx2+2y2+1uSAoAANzBdLkZOnSoy3YeGBgoT09PFRQUlBsvKChQSEhIpds0a9ZMDRo0kKenp3OsXbt2ys/PV2lpabWf2AIAANZg+p4bSTp69KgmTZqkQYMG6cSJE5Kk//7v/9b+/ftNvY+3t7e6dOmi9PR055jD4VB6erri4uIq3aZ79+46cuSIHA6Hc+zw4cNq1qwZxQYAAJgvN1u3blXHjh21fft2ffzxxzp//rykX39+obLLQr8nKSlJCxcu1Lvvvqvvv/9ejz/+uIqLi51PTyUmJio5Odk5//HHH9eZM2c0fvx4HT58WOvWrdP06dM1ZswY0/sGAADWY/qy1MSJE/XXv/5VSUlJuuGGG5zjd911l958803TAQYOHKiTJ09q8uTJys/PV+fOnZWWlua8yTgnJ0ceHv/XwcLDw7VhwwZNmDBBnTp1UlhYmMaPH6/nnnvO9L4BAID1mC43e/fu1fLlyyuMBwUF6dSpU9UKMXbsWI0dO7bSdRkZGRXG4uLi9PXXX1drXwAAwNpMX5YKCAhQXl5ehfHdu3crLCzMJaEAAACqy3S5eeSRR/Tcc88pPz9fNptNDodDX375pZ5++mklJibWREYAAIAqM11upk+frrZt2yo8PFznz59X+/bt9cc//lHdunXTpEmTaiIjAABAlZm+58bb21sLFy7Uiy++qH379un8+fOKjo522W9NAQAAXAvT5eaKiIgI588Y2Gw2lwUCAAC4FtX6Er9FixapQ4cO8vHxkY+Pjzp06KB33nnH1dkAAABMM33mZvLkyZo9e7aeeOIJ57cIZ2ZmasKECcrJydFLL73k8pAAAABVZbrcvP3221q4cKEGDRrkHLv//vvVqVMnPfHEE5QbAADgVqYvS126dEkxMTEVxrt06aLLly+7JBQAAEB1mS43Q4YM0dtvv11hfMGCBRo8eLBLQgEAAFRXtZ6WWrRokTZu3Kjbb79dkrR9+3bl5OQoMTFRSUlJznmzZ892TUoAAIAqMl1u9u3bp9tuu02SdPToUUlSYGCgAgMDtW/fPuc8Hg8HAADuYLrcbNmypSZyAAAAuES1vucGAACgrqLcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6HcAAAAS6kT5WbevHmKjIyUj4+PYmNjtWPHjiptt2LFCtlsNvXv379mAwIAgHrD7eVm5cqVSkpK0pQpU/Ttt98qKipKffr00YkTJ35zux9//FFPP/20evbsWUtJAQBAfeD2cjN79myNHDlSw4YNU/v27TV//nz5+flp8eLFV92mrKxMgwcP1rRp09SyZcvffP+SkhIVFRWVWwAAgHW5tdyUlpZq165dio+Pd455eHgoPj5emZmZV93upZdeUlBQkEaMGPG7+0hJSZG/v79zCQ8Pd0l2AABQN7m13Jw6dUplZWUKDg4uNx4cHKz8/PxKt/niiy+0aNEiLVy4sEr7SE5O1tmzZ51Lbm7uNecGAAB1l5e7A5hx7tw5DRkyRAsXLlRgYGCVtrHb7bLb7TWcDAAA1BVuLTeBgYHy9PRUQUFBufGCggKFhIRUmH/06FH9+OOPSkhIcI45HA5JkpeXlw4dOqRWrVrVbGgAAFCnufWylLe3t7p06aL09HTnmMPhUHp6uuLi4irMb9u2rfbu3ausrCzncv/996tXr17KysrifhoAAOD+y1JJSUkaOnSoYmJi1LVrV82ZM0fFxcUaNmyYJCkxMVFhYWFKSUmRj4+POnToUG77gIAASaowDgAArk9uLzcDBw7UyZMnNXnyZOXn56tz585KS0tz3mSck5MjDw+3P7EOAADqCbeXG0kaO3asxo4dW+m6jIyM39w2NTXV9YEAAEC9xSkRAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKZQbAABgKXWi3MybN0+RkZHy8fFRbGysduzYcdW5CxcuVM+ePXXjjTfqxhtvVHx8/G/OBwAA1xe3l5uVK1cqKSlJU6ZM0bfffquoqCj16dNHJ06cqHR+RkaGBg0apC1btigzM1Ph4eH605/+pOPHj9dycgAAUBe5vdzMnj1bI0eO1LBhw9S+fXvNnz9ffn5+Wrx4caXzly1bptGjR6tz585q27at3nnnHTkcDqWnp9dycgAAUBe5tdyUlpZq165dio+Pd455eHgoPj5emZmZVXqPCxcu6NKlS2rcuHGl60tKSlRUVFRuAQAA1uXWcnPq1CmVlZUpODi43HhwcLDy8/Or9B7PPfecQkNDyxWkf5aSkiJ/f3/nEh4efs25AQBA3eX2y1LXYsaMGVqxYoVWr14tHx+fSuckJyfr7NmzziU3N7eWUwIAgNrk5c6dBwYGytPTUwUFBeXGCwoKFBIS8pvbvvbaa5oxY4Y+//xzderU6arz7Ha77Ha7S/ICAIC6z61nbry9vdWlS5dyNwNfuTk4Li7uqtvNnDlTL7/8stLS0hQTE1MbUQEAQD3h1jM3kpSUlKShQ4cqJiZGXbt21Zw5c1RcXKxhw4ZJkhITExUWFqaUlBRJ0t/+9jdNnjxZy5cvV2RkpPPenIYNG6phw4Zu+xwAAKBucHu5GThwoE6ePKnJkycrPz9fnTt3VlpamvMm45ycHHl4/N8JprffflulpaX693//93LvM2XKFE2dOrU2owMAgDrI7eVGksaOHauxY8dWui4jI6Pc6x9//LHmAwEAgHqrXj8tBQAA8K8oNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFIoNwAAwFLqRLmZN2+eIiMj5ePjo9jYWO3YseM3569atUpt27aVj4+POnbsqPXr19dSUgAAUNe5vdysXLlSSUlJmjJlir799ltFRUWpT58+OnHiRKXzv/rqKw0aNEgjRozQ7t271b9/f/Xv31/79u2r5eQAAKAucnu5mT17tkaOHKlhw4apffv2mj9/vvz8/LR48eJK58+dO1f33HOPnnnmGbVr104vv/yybrvtNr355pu1nBwAANRFXu7ceWlpqXbt2qXk5GTnmIeHh+Lj45WZmVnpNpmZmUpKSio31qdPH61Zs6bS+SUlJSopKXG+Pnv2rCSpqKjoGtPDShwlFyqM8TeCuu5f/27r+9+s1T4PXOvK34NhGL87163l5tSpUyorK1NwcHC58eDgYB08eLDSbfLz8yudn5+fX+n8lJQUTZs2rcJ4eHh4NVPjeuE/x90JAHOs9jdrtc8D1zh37pz8/f1/c45by01tSE5OLnemx+Fw6MyZM2rSpIlsNts1v39RUZHCw8OVm5urRo0aXfP7wfU4RnUfx6ju4xjVfVY/RoZh6Ny5cwoNDf3duW4tN4GBgfL09FRBQUG58YKCAoWEhFS6TUhIiKn5drtddru93FhAQED1Q19Fo0aNLPnHZCUco7qPY1T3cYzqPisfo987Y3OFW28o9vb2VpcuXZSenu4cczgcSk9PV1xcXKXbxMXFlZsvSZs2bbrqfAAAcH1x+2WppKQkDR06VDExMeratavmzJmj4uJiDRs2TJKUmJiosLAwpaSkSJLGjx+vO+64Q7NmzVK/fv20YsUK7dy5UwsWLHDnxwAAAHWE28vNwIEDdfLkSU2ePFn5+fnq3Lmz0tLSnDcN5+TkyMPj/04wdevWTcuXL9ekSZP0/PPPq3Xr1lqzZo06dOjglvx2u11TpkypcOkLdQfHqO7jGNV9HKO6j2P0f2xGVZ6pAgAAqCfc/iV+AAAArkS5AQAAlkK5AQAAlkK5AQAAlkK5uQbz5s1TZGSkfHx8FBsbqx07drg70nUrJSVF//Zv/6YbbrhBQUFB6t+/vw4dOlRuzi+//KIxY8aoSZMmatiwof785z9X+EJI1J4ZM2bIZrPpySefdI5xjNzv+PHj+o//+A81adJEvr6+6tixo3bu3OlcbxiGJk+erGbNmsnX11fx8fH64Ycf3Jj4+lJWVqYXX3xRLVq0kK+vr1q1aqWXX3653O8tcYwkGaiWFStWGN7e3sbixYuN/fv3GyNHjjQCAgKMgoICd0e7LvXp08dYsmSJsW/fPiMrK8u49957jYiICOP8+fPOOaNGjTLCw8ON9PR0Y+fOncbtt99udOvWzY2pr187duwwIiMjjU6dOhnjx493jnOM3OvMmTNG8+bNjb/85S/G9u3bjWPHjhkbNmwwjhw54pwzY8YMw9/f31izZo2xZ88e4/777zdatGhhXLx40Y3Jrx+vvPKK0aRJE+Ozzz4zsrOzjVWrVhkNGzY05s6d65zDMTIMyk01de3a1RgzZozzdVlZmREaGmqkpKS4MRWuOHHihCHJ2Lp1q2EYhlFYWGg0aNDAWLVqlXPO999/b0gyMjMz3RXzunTu3DmjdevWxqZNm4w77rjDWW44Ru733HPPGT169LjqeofDYYSEhBivvvqqc6ywsNCw2+3G+++/XxsRr3v9+vUzhg8fXm5swIABxuDBgw3D4BhdwWWpaigtLdWuXbsUHx/vHPPw8FB8fLwyMzPdmAxXnD17VpLUuHFjSdKuXbt06dKlcsesbdu2ioiI4JjVsjFjxqhfv37ljoXEMaoL1q5dq5iYGD300EMKCgpSdHS0Fi5c6FyfnZ2t/Pz8csfI399fsbGxHKNa0q1bN6Wnp+vw4cOSpD179uiLL75Q3759JXGMrnD7NxTXR6dOnVJZWZnzW5SvCA4O1sGDB92UClc4HA49+eST6t69u/Obq/Pz8+Xt7V3hR1ODg4OVn5/vhpTXpxUrVujbb7/VN998U2Edx8j9jh07prfffltJSUl6/vnn9c0332jcuHHy9vbW0KFDncehsv/2cYxqx8SJE1VUVKS2bdvK09NTZWVleuWVVzR48GBJ4hj9f5QbWM6YMWO0b98+ffHFF+6Ogn+Sm5ur8ePHa9OmTfLx8XF3HFTC4XAoJiZG06dPlyRFR0dr3759mj9/voYOHermdJCkDz74QMuWLdPy5ct16623KisrS08++aRCQ0M5Rv+Ey1LVEBgYKE9PzwpPcRQUFCgkJMRNqSBJY8eO1WeffaYtW7bopptuco6HhISotLRUhYWF5eZzzGrPrl27dOLECd12223y8vKSl5eXtm7dqjfeeENeXl4KDg7mGLlZs2bN1L59+3Jj7dq1U05OjiQ5jwP/7XOfZ555RhMnTtQjjzyijh07asiQIZowYYLzx6U5Rr+i3FSDt7e3unTpovT0dOeYw+FQenq64uLi3Jjs+mUYhsaOHavVq1dr8+bNatGiRbn1Xbp0UYMGDcods0OHDiknJ4djVkt69+6tvXv3Kisry7nExMRo8ODBzn9zjNyre/fuFb5C4fDhw2revLkkqUWLFgoJCSl3jIqKirR9+3aOUS25cOFCuR+TliRPT085HA5JHCMnd9/RXF+tWLHCsNvtRmpqqnHgwAHjP//zP42AgAAjPz/f3dGuS48//rjh7+9vZGRkGHl5ec7lwoULzjmjRo0yIiIijM2bNxs7d+404uLijLi4ODemxj8/LWUYHCN327Fjh+Hl5WW88sorxg8//GAsW7bM8PPzM9577z3nnBkzZhgBAQHGJ598Ynz33XfGAw88cN09ZuxOQ4cONcLCwpyPgn/88cdGYGCg8eyzzzrncIx4FPya/P3vfzciIiIMb29vo2vXrsbXX3/t7kjXLUmVLkuWLHHOuXjxojF69GjjxhtvNPz8/IwHH3zQyMvLc19oVCg3HCP3+/TTT40OHToYdrvdaNu2rbFgwYJy6x0Oh/Hiiy8awcHBht1uN3r37m0cOnTITWmvP0VFRcb48eONiIgIw8fHx2jZsqXxwgsvGCUlJc45HCPDsBnGP32tIQAAQD3HPTcAAMBSKDcAAMBSKDcAAMBSKDcAAMBSKDcAAMBSKDcAAMBSKDcAAMBSKDcAAMBSKDcArmsZGRmy2WwVfrDzn6WmpiogIKDWMgG4NpQbANe1bt26KS8vT/7+/u6OAsBFKDcArgtlZWXOX07+Z97e3goJCZHNZnNDKgA1gXIDwC0iIyM1Z86ccmOdO3fW1KlTJUmGYWjq1KmKiIiQ3W5XaGioxo0b55xbUlKip59+WmFhYfrDH/6g2NhYZWRkONdfuZS0du1atW/fXna7XTk5ORVyVHZZKjU1VREREfLz89ODDz6o06dPu/KjA6hhXu4OAACV+eijj/T6669rxYoVuvXWW5Wfn689e/Y4148dO1YHDhzQihUrFBoaqtWrV+uee+7R3r171bp1a0nShQsX9Le//U3vvPOOmjRpoqCgoN/d7/bt2zVixAilpKSof//+SktL05QpU2rscwJwPcoNgDopJydHISEhio+PV4MGDRQREaGuXbs61y1ZskQ5OTkKDQ2VJD399NNKS0vTkiVLNH36dEnSpUuX9NZbbykqKqrK+507d67uuecePfvss5KkNm3a6KuvvlJaWpqLPyGAmsJlKQB10kMPPaSLFy+qZcuWGjlypFavXq3Lly9Lkvbu3auysjK1adNGDRs2dC5bt27V0aNHne/h7e2tTp06mdrv999/r9jY2HJjcXFx1/6BANQaztwAcAsPDw8ZhlFu7NKlS85/h4eH69ChQ/r888+1adMmjR49Wq+++qq2bt2q8+fPy9PTU7t27ZKnp2e592jYsKHz376+vtwoDFyHKDcA3KJp06bKy8tzvi4qKlJ2dna5Ob6+vkpISFBCQoLGjBmjtm3bau/evYqOjlZZWZlOnDihnj17ujRXu3bttH379nJjX3/9tUv3AaBmUW4AuMVdd92l1NRUJSQkKCAgQJMnTy53FiY1NVVlZWWKjY2Vn5+f3nvvPfn6+qp58+Zq0qSJBg8erMTERM2aNUvR0dE6efKk0tPT1alTJ/Xr16/aucaNG6fu3bvrtdde0wMPPKANGzZwvw1Qz3DPDQC3SE5O1h133KH77rtP/fr1U//+/dWqVSvn+oCAAC1cuFDdu3dXp06d9Pnnn+vTTz9VkyZNJElLlixRYmKinnrqKd1yyy3q37+/vvnmG0VERFxTrttvv10LFy7U3LlzFRUVpY0bN2rSpEnX9J4AapfN+NeL3gAAAPUYZ24AAIClUG4AAIClUG4AAIClUG4AAIClUG4AAIClUG4AAIClUG4AAIClUG4AAIClUG4AAIClUG4AAIClUG4AAICl/D/VcvsuBf1uRwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data=np.sum(allPvalue, axis=1)*100/65\n",
    "index=[i for i in range (1,len(data)+1)]\n",
    "plt.bar(index, data)\n",
    "plt.xlabel('user id')\n",
    "plt.ylabel('percent of features')\n",
    "#plt.title('Total features in a profile (out of 65 features) that passed the similarity test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97999, 66)\n",
      "(97999, 57)\n"
     ]
    }
   ],
   "source": [
    "#Random project the recover data to impersonate the user. Used different seed\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "#traningdataReg = pd.concat([tDataReg, trainingDataRP['ID']], axis=1)\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','ID']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "traningdataReg.columns=dataset.columns\n",
    "trainingDataRPReg = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,96):\n",
    "    rng = np.random.RandomState(seed+10)\n",
    "    X = traningdataReg[traningdataReg['ID']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['ID'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['ID']=seed\n",
    "    trainingDataRPReg = pd.concat([trainingDataRPReg, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(traningdataReg.shape)\n",
    "print(trainingDataRPReg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in test dataset: 96\n"
     ]
    }
   ],
   "source": [
    "print(\"Total user in test dataset:\", len(pd.unique(trainingDataRPReg['ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3063/3063 [==============================] - 4s 1ms/step - loss: 19.9066 - accuracy: 0.0000e+00\n",
      "Loss: 19.906648635864258\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Performance of the attacker by using the random projected recover data\n",
    "#UserModel.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "Xtest=trainingDataRPReg.drop(columns=['ID'])\n",
    "ytest=trainingDataRPReg['ID']\n",
    "ytest=to_categorical(ytest)\n",
    "loss, accuracy = TrainedClassifier.evaluate(Xtest,ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97999, 66)\n",
      "(97999, 57)\n"
     ]
    }
   ],
   "source": [
    "#Random project the recover data to impersonate the user. If the attacker know the key\n",
    "import numpy as np\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "#traningdataReg = pd.concat([tDataReg, trainingDataRP['ID']], axis=1)\n",
    "column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56','ID']\n",
    "column2=column1=['RPF1','RPF2','RPF3','RPF4','RPF5','RPF6','RPF7','RPF8','RPF9','RPF10','RPF11','RPF12','RPF13','RPF14','RPF15',\n",
    "         'RPF16','RPF17','RPF18','RPF19','RPF20','RPF21','RPF22','RPF23','RPF24','RPF25','RPF26','RPF27','RPF28','RPF29','RPF30',\n",
    "         'RPF31','RPF32','RPF33','RPF34','RPF35','RPF36','RPF37','RPF38','RPF39','RPF40','RPF41','RPF42','RPF43','RPF44','RPF45',\n",
    "         'RPF46','RPF47','RPF48','RPF49','RPF50','RPF51','RPF52','RPF53','RPF54','RPF55','RPF56']\n",
    "traningdataReg.columns=dataset.columns\n",
    "trainingDataRPReg = pd.DataFrame(columns=column1)\n",
    "for seed in range(0,96):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = traningdataReg[traningdataReg['ID']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=56, random_state=rng)\n",
    "    Xdata=X.drop(columns=['ID'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['ID']=seed\n",
    "    trainingDataRPReg = pd.concat([trainingDataRPReg, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(traningdataReg.shape)\n",
    "print(trainingDataRPReg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3063/3063 [==============================] - 4s 1ms/step - loss: 0.1201 - accuracy: 0.9698\n",
      "Loss: 0.12010253220796585\n",
      "Accuracy: 0.969836413860321\n"
     ]
    }
   ],
   "source": [
    "#Performance of the attacker by using the random projected recover data when key is known\n",
    "#UserModel.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "Xtest=trainingDataRPReg.drop(columns=['ID'])\n",
    "ytest=trainingDataRPReg['ID']\n",
    "ytest=to_categorical(ytest)\n",
    "loss, accuracy = TrainedClassifier.evaluate(Xtest,ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
