{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of this program\n",
    "## Read the oversampled data and then project the data in a new dimension. Used the projected data to train a ML model\n",
    "## Verify correctness of the trained model by test data (project the test data by using same random matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052478</td>\n",
       "      <td>0.277631</td>\n",
       "      <td>0.451259</td>\n",
       "      <td>0.718039</td>\n",
       "      <td>0.462785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>0.167556</td>\n",
       "      <td>-0.021220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.175416</td>\n",
       "      <td>0.183196</td>\n",
       "      <td>0.083857</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>0.183644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052112</td>\n",
       "      <td>0.329417</td>\n",
       "      <td>0.456423</td>\n",
       "      <td>0.707689</td>\n",
       "      <td>0.431129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.188321</td>\n",
       "      <td>-0.046427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001681</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.161923</td>\n",
       "      <td>0.174437</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.172166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044798</td>\n",
       "      <td>0.246703</td>\n",
       "      <td>0.482247</td>\n",
       "      <td>0.682013</td>\n",
       "      <td>0.413386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.219466</td>\n",
       "      <td>-0.084152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.165296</td>\n",
       "      <td>0.176905</td>\n",
       "      <td>0.015824</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.179818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.292016</td>\n",
       "      <td>0.470626</td>\n",
       "      <td>0.711022</td>\n",
       "      <td>0.418269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019350</td>\n",
       "      <td>0.182533</td>\n",
       "      <td>-0.089321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.009006</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.165296</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.183644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048638</td>\n",
       "      <td>0.282665</td>\n",
       "      <td>0.438347</td>\n",
       "      <td>0.712347</td>\n",
       "      <td>0.447676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023968</td>\n",
       "      <td>0.151995</td>\n",
       "      <td>-0.024688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001410</td>\n",
       "      <td>0.007316</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.175416</td>\n",
       "      <td>0.184353</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.183644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5    6    7         8  \\\n",
       "0  0.052478  0.277631  0.451259  0.718039  0.462785  0.0  0.0  0.018702   \n",
       "1  0.052112  0.329417  0.456423  0.707689  0.431129  0.0  0.0  0.018824   \n",
       "2  0.044798  0.246703  0.482247  0.682013  0.413386  0.0  0.0  0.023549   \n",
       "3  0.050101  0.292016  0.470626  0.711022  0.418269  0.0  0.0  0.019350   \n",
       "4  0.048638  0.282665  0.438347  0.712347  0.447676  0.0  0.0  0.023968   \n",
       "\n",
       "          9        10  ...        25        26        27        28        29  \\\n",
       "0  0.167556 -0.021220  ... -0.000286  0.006156  0.000038  0.098039  0.175416   \n",
       "1  0.188321 -0.046427  ... -0.001681  0.006563  0.000043  0.172549  0.161923   \n",
       "2  0.219466 -0.084152  ... -0.003980  0.007612  0.000058  0.172549  0.165296   \n",
       "3  0.182533 -0.089321  ...  0.000438  0.009006  0.000081  0.149020  0.165296   \n",
       "4  0.151995 -0.024688  ... -0.001410  0.007316  0.000054  0.125490  0.175416   \n",
       "\n",
       "         30        31        32        33  Label  \n",
       "0  0.183196  0.083857  0.007032  0.183644      0  \n",
       "1  0.174437  0.012390  0.000154  0.172166      0  \n",
       "2  0.176905  0.015824  0.000250  0.179818      0  \n",
       "3  0.178174  0.036672  0.001343  0.183644      0  \n",
       "4  0.184353  0.061493  0.003786  0.183644      0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read all oversample data\n",
    "import csv\n",
    "import pandas as pd\n",
    "dataset=pd.read_csv('Dataset/OversampledSwipeData.csv',index_col=0)\n",
    "#testdataset=pd.read_csv('Dataset/SwipeDatatest.csv',index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccqmRdmvHjnS",
    "outputId": "02eefd01-10ea-451e-880c-507eb1f8dd34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0     300\n",
       "1     300\n",
       "2     300\n",
       "3     300\n",
       "4     300\n",
       "     ... \n",
       "81    300\n",
       "82    300\n",
       "83    300\n",
       "84    300\n",
       "85    300\n",
       "Name: Label, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace the user ID by class name and count the number of sample in each class\n",
    "#dataset['Label'] = pd.factorize(dataset['Label'])[0]\n",
    "dataset.groupby(['Label'])['Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in training dataset: 68\n",
      "Total user in auxiliary dataset: 18\n"
     ]
    }
   ],
   "source": [
    "#seperate the profile in two groups (80.0%, 20.0%): (i) Training profile (0-155), and (ii) auxiliary profile (156-192)\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData = dataset[dataset['Label'] <68]\n",
    "auxilaryData = dataset[dataset['Label'] >= 68]\n",
    "print(\"Total user in training dataset:\", len(pd.unique(trainingData['Label'])))\n",
    "print(\"Total user in auxiliary dataset:\", len(pd.unique(auxilaryData['Label'])))\n",
    "#assigned 0-154 users' data to dataset\n",
    "dataset=trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in the training dataset: 68\n"
     ]
    }
   ],
   "source": [
    "#total use in the system\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData=dataset\n",
    "print(\"Total user in the training dataset:\", len(pd.unique(trainingData['Label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cJtsn1DHjnT",
    "outputId": "080738d6-eabd-40e1-8436-c6cb14e1a567"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_24672\\2213213074.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  datasetRP = pd.concat([datasetRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20400, 34)\n",
      "(20400, 31)\n"
     ]
    }
   ],
   "source": [
    "column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30','Label']\n",
    "column2=column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30']\n",
    "datasetRP = pd.DataFrame(columns=column1)\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "import numpy as np\n",
    "for seed in range(0,68):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = dataset[dataset['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=30, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    datasetRP = pd.concat([datasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(dataset.shape)\n",
    "print(datasetRP.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in the training dataset: 68\n"
     ]
    }
   ],
   "source": [
    "#total use in the system\n",
    "totalUser= len(pd.unique(datasetRP['Label']))\n",
    "trainingData=datasetRP\n",
    "print(\"Total user in the training dataset:\", len(pd.unique(trainingData['Label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1J_SeYxDHjnW"
   },
   "outputs": [],
   "source": [
    "#Prepare the traning data for training and testing the model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X=trainingData.drop(columns=['Label'])\n",
    "y=trainingData['Label']\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "#Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2, random_state=22)\n",
    "\n",
    "ytrain = to_categorical(ytrain)\n",
    "yval = to_categorical(yval)\n",
    "#ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgWD7LFwHjnY",
    "outputId": "ec217a08-50ac-40ee-d14e-74cdb1e9a9d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16320, 30)\n",
      "(16320, 68)\n",
      "(4080, 30)\n",
      "(4080, 68)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xval.shape)\n",
    "print(yval.shape)\n",
    "#print(Xtest.shape)\n",
    "#print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mLyu5dz1Hjne"
   },
   "outputs": [],
   "source": [
    "# import all necessary package for a neural network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inlineimport keras\n",
    "from keras.layers import Dense, Dropout, Input,Activation,Dropout, Flatten\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "#from tqdm import tqdm\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "#import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bCpCz9-FHjnk"
   },
   "outputs": [],
   "source": [
    "#define optimizers for neural network\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "def adam_optimizer():\n",
    "    return Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "def RMSprop_optimizer():\n",
    "    return RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6S6V0q0gHjnm",
    "outputId": "7f585abc-dcb2-4c0c-eb85-28a1fafcf26d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,420</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)             │         \u001b[38;5;34m4,420\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,004</span> (93.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,004\u001b[0m (93.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,492</span> (91.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,492\u001b[0m (91.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#neural network architecture for model training\n",
    "\n",
    "def create_classifierRP(release=False,totalClass=68):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(64, input_dim=30))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.5))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(128))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.2))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "  #classifier.add(Dropout(0.2))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(64))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.2))\n",
    "\n",
    "  #if release:\n",
    "  classifier.add(Dense(totalClass, activation='softmax'))\n",
    "  #else:\n",
    "  #   classifier.add(Dense(Tuser))\n",
    "  #np.log_softmax_v2(a, axis=axis)\n",
    "  #classifier.add(F.softmax(a, dim=1))\n",
    "\n",
    "  classifier.compile(loss='categorical_crossentropy', optimizer=RMSprop_optimizer(),metrics=['accuracy'])\n",
    "  return classifier\n",
    "\n",
    "Clasf=create_classifierRP()\n",
    "Clasf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3j2Iq78BHjnn",
    "outputId": "3581446a-5285-4467-f9d8-7734bc897345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2696 - loss: 3.3339 - val_accuracy: 0.9968 - val_loss: 1.3918\n",
      "Epoch 2/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 1.0523 - val_accuracy: 0.9993 - val_loss: 0.0586\n",
      "Epoch 3/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.4702 - val_accuracy: 0.9993 - val_loss: 0.0097\n",
      "Epoch 4/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.3202 - val_accuracy: 0.9993 - val_loss: 0.0046\n",
      "Epoch 5/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.2646 - val_accuracy: 0.9995 - val_loss: 0.0033\n",
      "Epoch 6/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.2153 - val_accuracy: 0.9995 - val_loss: 0.0028\n",
      "Epoch 7/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.1904 - val_accuracy: 0.9995 - val_loss: 0.0026\n",
      "Epoch 8/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1870 - val_accuracy: 0.9995 - val_loss: 0.0029\n",
      "Epoch 9/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1761 - val_accuracy: 0.9995 - val_loss: 0.0028\n",
      "Epoch 10/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1563 - val_accuracy: 0.9995 - val_loss: 0.0026\n",
      "Epoch 11/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1538 - val_accuracy: 0.9995 - val_loss: 0.0024\n",
      "Epoch 12/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1567 - val_accuracy: 0.9995 - val_loss: 0.0023\n",
      "Epoch 13/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1381 - val_accuracy: 0.9995 - val_loss: 0.0019\n",
      "Epoch 14/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1446 - val_accuracy: 0.9995 - val_loss: 0.0020\n",
      "Epoch 15/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1348 - val_accuracy: 0.9995 - val_loss: 0.0020\n",
      "Epoch 16/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1315 - val_accuracy: 0.9995 - val_loss: 0.0018\n",
      "Epoch 17/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1282 - val_accuracy: 0.9995 - val_loss: 0.0021\n",
      "Epoch 18/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9618 - loss: 0.1232 - val_accuracy: 0.9995 - val_loss: 0.0017\n",
      "Epoch 19/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1239 - val_accuracy: 0.9995 - val_loss: 0.0015\n",
      "Epoch 20/20\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1217 - val_accuracy: 0.9995 - val_loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "#Train the classifier seperately for black-box attack\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5,min_lr=0.0001)\n",
    "callbacks_list = [learning_rate_reduction]\n",
    "\n",
    "Classfier2= create_classifierRP(True,68)\n",
    "\n",
    "#------Comment will start from here\n",
    "lossc='categorical_crossentropy'\n",
    "optimizerc=RMSprop(learning_rate=0.001, rho=0.9)\n",
    "Classfier2.compile(loss=lossc, optimizer=optimizerc,metrics=['accuracy'])\n",
    "#------Comments will end from here\n",
    "historyc2 =  Classfier2.fit(Xtrain, ytrain, batch_size=64, epochs=20, validation_data=(Xval, yval),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "Qep4iQmGHjno",
    "outputId": "3037a17f-7fe4-4c6d-f3df-0c1472eafa67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the classifier loss and accuracy curves for training and validation data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(historyc2.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(historyc2.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the test data and seperate test data\n",
    "import csv\n",
    "import pandas as pd\n",
    "testdataset=pd.read_csv('Dataset/SwipeDatatest.csv',index_col=0)\n",
    "testdataset = testdataset[testdataset['Label'] < 68]\n",
    "#testdataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Temp\\ipykernel_24672\\652946025.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  testdatasetRP = pd.concat([testdatasetRP, XRP], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1639, 34)\n",
      "(1639, 31)\n"
     ]
    }
   ],
   "source": [
    "#random project the test data by using same random matrix\n",
    "column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30','Label']\n",
    "column2=column1=['RPF1', 'RPF2', 'RPF3', 'RPF4', 'RPF5', 'RPF6', 'RPF7', 'RPF8', 'RPF9', 'RPF10', 'RPF11', 'RPF12', 'RPF13', 'RPF14', 'RPF15', 'RPF16', 'RPF17', 'RPF18',\n",
    "         'RPF19', 'RPF20', 'RPF21', 'RPF22', 'RPF23', 'RPF24', 'RPF25', 'RPF26', 'RPF27', 'RPF28', 'RPF29', 'RPF30']\n",
    "testdatasetRP = pd.DataFrame(columns=column1)\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "import numpy as np\n",
    "for seed in range(0,68):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    X = testdataset[testdataset['Label']==seed]\n",
    "    transformer = SparseRandomProjection(n_components=30, random_state=rng)\n",
    "    Xdata=X.drop(columns=['Label'])\n",
    "    XRP = pd.DataFrame(transformer.fit_transform(Xdata),columns=column2)\n",
    "    XRP['Label']=seed\n",
    "    testdatasetRP = pd.concat([testdatasetRP, XRP], ignore_index=True)\n",
    "    #print(\"Shape of Actual data:\",Xdata.shape)\n",
    "    #print(\"Shape of Randome Matrix:\", transformer.components_.shape[1],transformer.components_.shape[0])\n",
    "    #print(\"Shape of Projected data:\", X_new.shape)\n",
    "print(testdataset.shape)\n",
    "print(testdatasetRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=testdatasetRP.drop(columns=['Label'])\n",
    "ytest=testdatasetRP['Label']\n",
    "ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUEGiCjYHjnp",
    "outputId": "18962c16-758c-4d47-b850-234d7575e623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0034     \n",
      "Loss: 0.0015382273122668266\n",
      "Accuracy: 0.9993898868560791\n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier\n",
    "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
