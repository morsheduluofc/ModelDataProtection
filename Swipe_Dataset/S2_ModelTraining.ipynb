{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDdeQb0Q7K7_"
   },
   "source": [
    "# Description of this program:\n",
    "## Read the oversampled data and seperate all profile in two groups: Traning profile and Auxiliary profiles\n",
    "## Prepare the training data to train an ML model\n",
    "## Validate the correctness and security of the trained model\n",
    "- Virtual environment and keras: https://www.tutorialspoint.com/keras/keras_installation.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "tFCVTFWV7K8U",
    "outputId": "12663405-f250-488c-a58e-bf0ce11c714c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052478</td>\n",
       "      <td>0.277631</td>\n",
       "      <td>0.451259</td>\n",
       "      <td>0.718039</td>\n",
       "      <td>0.462785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>0.167556</td>\n",
       "      <td>-0.021220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.175416</td>\n",
       "      <td>0.183196</td>\n",
       "      <td>0.083857</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>0.183644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052112</td>\n",
       "      <td>0.329417</td>\n",
       "      <td>0.456423</td>\n",
       "      <td>0.707689</td>\n",
       "      <td>0.431129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.188321</td>\n",
       "      <td>-0.046427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001681</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.161923</td>\n",
       "      <td>0.174437</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.172166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044798</td>\n",
       "      <td>0.246703</td>\n",
       "      <td>0.482247</td>\n",
       "      <td>0.682013</td>\n",
       "      <td>0.413386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.219466</td>\n",
       "      <td>-0.084152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.165296</td>\n",
       "      <td>0.176905</td>\n",
       "      <td>0.015824</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.179818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.292016</td>\n",
       "      <td>0.470626</td>\n",
       "      <td>0.711022</td>\n",
       "      <td>0.418269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019350</td>\n",
       "      <td>0.182533</td>\n",
       "      <td>-0.089321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.009006</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.165296</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.183644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048638</td>\n",
       "      <td>0.282665</td>\n",
       "      <td>0.438347</td>\n",
       "      <td>0.712347</td>\n",
       "      <td>0.447676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023968</td>\n",
       "      <td>0.151995</td>\n",
       "      <td>-0.024688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001410</td>\n",
       "      <td>0.007316</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.175416</td>\n",
       "      <td>0.184353</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.183644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5    6    7         8  \\\n",
       "0  0.052478  0.277631  0.451259  0.718039  0.462785  0.0  0.0  0.018702   \n",
       "1  0.052112  0.329417  0.456423  0.707689  0.431129  0.0  0.0  0.018824   \n",
       "2  0.044798  0.246703  0.482247  0.682013  0.413386  0.0  0.0  0.023549   \n",
       "3  0.050101  0.292016  0.470626  0.711022  0.418269  0.0  0.0  0.019350   \n",
       "4  0.048638  0.282665  0.438347  0.712347  0.447676  0.0  0.0  0.023968   \n",
       "\n",
       "          9        10  ...        25        26        27        28        29  \\\n",
       "0  0.167556 -0.021220  ... -0.000286  0.006156  0.000038  0.098039  0.175416   \n",
       "1  0.188321 -0.046427  ... -0.001681  0.006563  0.000043  0.172549  0.161923   \n",
       "2  0.219466 -0.084152  ... -0.003980  0.007612  0.000058  0.172549  0.165296   \n",
       "3  0.182533 -0.089321  ...  0.000438  0.009006  0.000081  0.149020  0.165296   \n",
       "4  0.151995 -0.024688  ... -0.001410  0.007316  0.000054  0.125490  0.175416   \n",
       "\n",
       "         30        31        32        33  Label  \n",
       "0  0.183196  0.083857  0.007032  0.183644      0  \n",
       "1  0.174437  0.012390  0.000154  0.172166      0  \n",
       "2  0.176905  0.015824  0.000250  0.179818      0  \n",
       "3  0.178174  0.036672  0.001343  0.183644      0  \n",
       "4  0.184353  0.061493  0.003786  0.183644      0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read all data\n",
    "import csv\n",
    "import pandas as pd\n",
    "dataset=pd.read_csv('Dataset/OversampledSwipeData.csv',index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJ6zCcRoJBSj",
    "outputId": "3b5c9651-2166-4ad0-de1d-82bf7d1e0877"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25800, 34)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtcvPN1l7K8h",
    "outputId": "c5e94289-305a-42be-8833-cea464d447ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0     300\n",
       "1     300\n",
       "2     300\n",
       "3     300\n",
       "4     300\n",
       "     ... \n",
       "81    300\n",
       "82    300\n",
       "83    300\n",
       "84    300\n",
       "85    300\n",
       "Name: Label, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace the user ID by class name and count the number of sample in each class\n",
    "#dataset['Label'] = pd.factorize(dataset['Label'])[0]\n",
    "dataset.groupby(['Label'])['Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffvTQtrH7K8o",
    "outputId": "a2428e7b-1030-4d06-c93d-469d78d3b4c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user in training dataset: 68\n",
      "Total user in auxiliary dataset: 18\n"
     ]
    }
   ],
   "source": [
    "#seperate the profile in two groups: (i) Training profile (0-67) 80.0\\%, and (ii) auxiliary profile (68-85) 20.0%\n",
    "totalUser= len(pd.unique(dataset['Label']))\n",
    "trainingData = dataset[dataset['Label'] < 68]\n",
    "auxilaryData = dataset[dataset['Label'] >= 68]\n",
    "print(\"Total user in training dataset:\", len(pd.unique(trainingData['Label'])))\n",
    "print(\"Total user in auxiliary dataset:\", len(pd.unique(auxilaryData['Label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z1iZ-P0c7K8s"
   },
   "outputs": [],
   "source": [
    "#Prepare the traning data for training and testing the model\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X=trainingData.drop(columns=['Label'])\n",
    "y=trainingData['Label']\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "#Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2, random_state=22)\n",
    "\n",
    "ytrain = to_categorical(ytrain)\n",
    "yval = to_categorical(yval)\n",
    "#ytest = to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RR_H8-nz7K8v",
    "outputId": "1a368f4d-76be-4b8a-8451-618f9b37ea46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16320, 33)\n",
      "(16320, 68)\n",
      "(4080, 33)\n",
      "(4080, 68)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xval.shape)\n",
    "print(yval.shape)\n",
    "#print(Xtest.shape)\n",
    "#print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mFKXheCd7K9r"
   },
   "outputs": [],
   "source": [
    "# import all necessary package for a neural network\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inlineimport keras\n",
    "from keras.layers import Dense, Dropout, Input,Activation,Dropout, Flatten\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "#from tqdm import tqdm\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "#import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vQeWRxpf7K93"
   },
   "outputs": [],
   "source": [
    "#define optimizers for neural network\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "def adam_optimizer():\n",
    "    return Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "def RMSprop_optimizer():\n",
    "    return RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpyiok1O7K96",
    "outputId": "df7f7cc0-ce69-48ec-de0e-b7dbb6d7d438"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,772</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)             │         \u001b[38;5;34m8,772\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">347,076</span> (1.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m347,076\u001b[0m (1.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">344,516</span> (1.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m344,516\u001b[0m (1.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> (10.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,560\u001b[0m (10.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#neural network architecture for model training\n",
    "\n",
    "def create_classifier(release=False,totalClass=68):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(128, input_dim=33))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.1))\n",
    "\n",
    "  #classifier.add(Dense(256))\n",
    "  #classifier.add(BatchNormalization())\n",
    "  #classifier.add(Activation('relu'))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.1))\n",
    "\n",
    "  classifier.add(Dense(512))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.1))\n",
    "\n",
    "  classifier.add(Dense(256))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.1))\n",
    "\n",
    "  classifier.add(Dense(128))\n",
    "  classifier.add(BatchNormalization())\n",
    "  classifier.add(Activation('relu'))\n",
    "  classifier.add(Dropout(0.1))\n",
    "\n",
    "  #if release:\n",
    "  classifier.add(Dense(totalClass, activation='softmax'))\n",
    "  #else:\n",
    "  #   classifier.add(Dense(Tuser))\n",
    "  #np.log_softmax_v2(a, axis=axis)\n",
    "  #classifier.add(F.softmax(a, dim=1))\n",
    "\n",
    "  classifier.compile(loss='categorical_crossentropy', optimizer=RMSprop_optimizer(),metrics=['accuracy'])\n",
    "  return classifier\n",
    "\n",
    "Clasf=create_classifier()\n",
    "Clasf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eg9_dAIv7K-D",
    "outputId": "06df0b30-c9f8-4156-bbbe-32603a5cbaae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.3947 - loss: 2.4709 - val_accuracy: 0.1507 - val_loss: 3.3433 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6937 - loss: 0.9609 - val_accuracy: 0.6924 - val_loss: 0.9430 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7423 - loss: 0.7734 - val_accuracy: 0.8284 - val_loss: 0.5270 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7720 - loss: 0.6828 - val_accuracy: 0.8338 - val_loss: 0.4745 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7914 - loss: 0.6099 - val_accuracy: 0.8255 - val_loss: 0.4950 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8052 - loss: 0.5738 - val_accuracy: 0.8564 - val_loss: 0.4206 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8212 - loss: 0.5290 - val_accuracy: 0.8429 - val_loss: 0.4620 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8216 - loss: 0.5184 - val_accuracy: 0.8669 - val_loss: 0.3889 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8235 - loss: 0.5095 - val_accuracy: 0.8809 - val_loss: 0.3358 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8374 - loss: 0.4850 - val_accuracy: 0.8841 - val_loss: 0.3397 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8486 - loss: 0.4470 - val_accuracy: 0.8887 - val_loss: 0.3200 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8456 - loss: 0.4410 - val_accuracy: 0.8637 - val_loss: 0.3849 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8519 - loss: 0.4199 - val_accuracy: 0.8988 - val_loss: 0.3019 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8533 - loss: 0.4197 - val_accuracy: 0.8669 - val_loss: 0.3756 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.3826 - val_accuracy: 0.9017 - val_loss: 0.2954 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8680 - loss: 0.3850 - val_accuracy: 0.8941 - val_loss: 0.2918 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8688 - loss: 0.3878 - val_accuracy: 0.9039 - val_loss: 0.2758 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8753 - loss: 0.3568 - val_accuracy: 0.9152 - val_loss: 0.2531 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8804 - loss: 0.3411 - val_accuracy: 0.9069 - val_loss: 0.2732 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8705 - loss: 0.3725 - val_accuracy: 0.9137 - val_loss: 0.2555 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8782 - loss: 0.3537 - val_accuracy: 0.8975 - val_loss: 0.3108 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8820 - loss: 0.3381 - val_accuracy: 0.9051 - val_loss: 0.2772 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m253/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8847 - loss: 0.3300\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8847 - loss: 0.3300 - val_accuracy: 0.8436 - val_loss: 0.4758 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9007 - loss: 0.2813 - val_accuracy: 0.9355 - val_loss: 0.1788 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9142 - loss: 0.2449 - val_accuracy: 0.9363 - val_loss: 0.1897 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9081 - loss: 0.2571 - val_accuracy: 0.9390 - val_loss: 0.1821 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9055 - loss: 0.2624 - val_accuracy: 0.9402 - val_loss: 0.1771 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9109 - loss: 0.2546 - val_accuracy: 0.9488 - val_loss: 0.1556 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9108 - loss: 0.2402 - val_accuracy: 0.9451 - val_loss: 0.1649 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2454 - val_accuracy: 0.9463 - val_loss: 0.1607 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9175 - loss: 0.2365 - val_accuracy: 0.9493 - val_loss: 0.1525 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9116 - loss: 0.2432 - val_accuracy: 0.9409 - val_loss: 0.1658 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9182 - loss: 0.2339 - val_accuracy: 0.9451 - val_loss: 0.1627 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9163 - loss: 0.2323 - val_accuracy: 0.9382 - val_loss: 0.1861 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9184 - loss: 0.2253 - val_accuracy: 0.9431 - val_loss: 0.1695 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9188 - loss: 0.2160 - val_accuracy: 0.9502 - val_loss: 0.1461 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9260 - loss: 0.2134 - val_accuracy: 0.9426 - val_loss: 0.1656 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9234 - loss: 0.2130 - val_accuracy: 0.9444 - val_loss: 0.1572 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9205 - loss: 0.2141 - val_accuracy: 0.9490 - val_loss: 0.1511 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9276 - loss: 0.2090 - val_accuracy: 0.9471 - val_loss: 0.1537 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m250/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.2140\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.2142 - val_accuracy: 0.9453 - val_loss: 0.1596 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9269 - loss: 0.1995 - val_accuracy: 0.9581 - val_loss: 0.1277 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9368 - loss: 0.1794 - val_accuracy: 0.9593 - val_loss: 0.1273 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9288 - loss: 0.1875 - val_accuracy: 0.9581 - val_loss: 0.1192 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9409 - loss: 0.1718 - val_accuracy: 0.9591 - val_loss: 0.1240 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9365 - loss: 0.1774 - val_accuracy: 0.9591 - val_loss: 0.1285 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9409 - loss: 0.1699 - val_accuracy: 0.9600 - val_loss: 0.1184 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9391 - loss: 0.1695 - val_accuracy: 0.9635 - val_loss: 0.1101 - learning_rate: 2.5000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9377 - loss: 0.1671 - val_accuracy: 0.9615 - val_loss: 0.1194 - learning_rate: 2.5000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9409 - loss: 0.1594 - val_accuracy: 0.9596 - val_loss: 0.1209 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "#Train the classifier seperately for black-box attack\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=5, verbose=1, factor=0.5,min_lr=0.0001)\n",
    "callbacks_list = [learning_rate_reduction]\n",
    "\n",
    "Classfier2= create_classifier(True,68)\n",
    "\n",
    "#------Comment will start from here\n",
    "lossc='categorical_crossentropy'\n",
    "#optimizerc=RMSprop(learning_rate=0.0001, rho=0.9)\n",
    "optimizerc=Adam(learning_rate=0.001)\n",
    "Classfier2.compile(loss=lossc, optimizer=optimizerc,metrics=['accuracy'])\n",
    "#------Comments will end from here\n",
    "historyc2 =  Classfier2.fit(Xtrain, ytrain, batch_size=64, epochs=50, validation_data=(Xval, yval),verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "oLCDk2Rl7K-Z",
    "outputId": "86033674-222d-48e5-d1de-ca52f16fe374"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG0CAYAAADO5AZFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlNklEQVR4nO3dd1xV9f8H8NcF5AIyHCAgIjhw4ABFMTRzUZRmakvNnGlDLZNK8+tK+yWaaWZZljmyoaalDcsRjhIxFcWJuFAcDHGAIDLu/fz++HQvXNlw7z2M1/PxOA/uPffccz+czPvyfT5DJYQQICIiIqomLJRuABEREZExMdwQERFRtcJwQ0RERNUKww0RERFVKww3REREVK0w3BAREVG1wnBDRERE1QrDDREREVUrDDdERERUrTDcEBERUbWiaLj5+++/0b9/fzRs2BAqlQpbtmwp8T179uxBx44doVar0bx5c6xZs8bk7SQiIqKqw0rJD8/IyICfnx/GjBmDp59+usTj4+Li0K9fP7z66qv4/vvvER4ejrFjx8Ld3R0hISGl+kytVovr16/DwcEBKpWqor8CERERmYEQAnfv3kXDhg1hYVF8bUZVWRbOVKlU2Lx5MwYOHFjkMVOnTsXWrVtx8uRJ/b4hQ4bgzp072LZtW6k+5+rVq/D09Kxoc4mIiEgBV65cQaNGjYo9RtHKTVlFRkYiODjYYF9ISAjefPPNIt+TlZWFrKws/XNdlrty5QocHR1N0k4iIiIyrrS0NHh6esLBwaHEY6tUuElMTISrq6vBPldXV6SlpSEzMxO2trYF3hMWFoY5c+YU2O/o6MhwQ0REVMWUpktJtR8tNW3aNKSmpuq3K1euKN0kIiIiMqEqVblxc3NDUlKSwb6kpCQ4OjoWWrUBALVaDbVabY7mERERUSVQpSo3QUFBCA8PN9i3c+dOBAUFKdQiIiIiqmwUDTfp6emIjo5GdHQ0ADnUOzo6GvHx8QDkLaURI0boj3/11Vdx8eJFTJkyBWfOnMHnn3+OH3/8EZMnT1ai+URERFQJKRpuDh8+jA4dOqBDhw4AgNDQUHTo0AGzZs0CACQkJOiDDgA0adIEW7duxc6dO+Hn54dFixbh66+/LvUcN0RERFT9VZp5bswlLS0NTk5OSE1N5WgpIiKiKqIs399Vqs8NERERUUkYboiIiKhaYbghIiKiaoXhhoiIiKoVhhsiIiKqVhhuiIiIqFphuCEiIqrpsrOBhAQgK0vplhhFlVpbioiIiMpJCCAlBThzBoiNzfsZGwtcvAhoNPI4JyfA1VVuDRoU/lP32MEBKMUq3ebGcENERFRW2dlAWlrelpqa9/j+ffml7+gog4KjY95mbw9YWuadRwh5rowMuaWn5z3OyAC02uLbIYSstuR/T/5z6B4nJMgQc/t2yb9baqrczp4t+Vgbm8IDUMuWwKhRJb/fRBhuiIiIShIbC0ybBuzbJwNMRW7f2NsDtWvLEJSRAeTmGq+dJVGpgMaNgVatZABp2TLvsbs7cOcOkJQEJCcX/lP3ODlZBqf794H4eLnl16ULww0REVGldPs2MHcu8NlnhYeQ2rULVmjUavnFn7+qk5oK5OTI96Sny+1B1tbyfPm3/FWeolhb5wUm3Zb/ub09UL++DDA+PoCdXdHnqldPbq1bl/y59+4VDD26n40alfx+E2K4ISIielBuLvDVV8CsWcDNm3Jfv37A9OmAh4cMMQ4OpQsfOllZeYEnPR2wtTUMJLVqmeZ3MRU7O8DbW26VDMMNEVFpabWAhYkHmQohqwWXLskvUVdX036eseTmAv/8A2zdKr/0n3sO8PU17WdqNMD163kVE2N1bP3rL2DyZODkSfm8dWvg44+BkJCKnVetBlxc5EYmxXBDRFScmzeB778HVq0CTpwAmjaVX9q+vkCbNvJnq1bFl/oflJUl+yhcvFhwi4uTtzAAGaRCQmTfhaeekp03K5P792UQ+Pln4Ndf8yocAPDee0DbtsCQIcDgwUDz5hX7LCGAK1eAgweBQ4fkz6go4O5d+bpaLTuyFjW6x9k5b6tfX1ZKHgxD584Bb70F/PabfF6vnrwl9corgBW/LqsSlRBCKN0IcyrLkulEVENpNEB4OLByJbBlixzNUhyVCmjSRAYdHx/DkTT5R9HkH01TEmdnOWxXp04dGRRGjQICA0uuUmRmyspDdLSsBPXpA3TsWPHqxt27wB9/yEDzxx+GfUfq1wf695ft3r49r48JAAQEyJDz/POAl1fR59dogFu35DkuX84LMgcPyr4cD7K0zBvCXBZqdcGws22bbLOlJTBhAjB7tgw4VCmU5fub4YaISCcuDlizBli9WlYJdDp0AF56CXj8cfmFe/q03E6dklv+ikVp2dnJKlCTJvJn/s3bW75+7hzwzTfA2rWG7WnVSoacF1+Ut65u3JAhJv925kzBYcSNGskK0IABQM+esiNqSdLTZcA4cEDedtq1y3CkkIcH8PTTwKBBQPfueRWO27eBzZuBDRtkUMwfQIKCgIceksfcvCmDTEqKfHz7tqzSFMbKCmjfHujcWQa8zp3lLaOcnKJH9+h+6j4jJaX4sPrEE8CiRaXrUEtmxXBTDIYbohoof0fOwrbUVHl7JTw87z116wLDhgFjxshwU5wbN2TIOX1aBiRbW8O5TQrb6tYtfRVFqwV275bB66efZFUGkLetGjQAEhMLf5+zM+DvL4NSeLgcdqzj4CC/yAcMAPr2lZUhrVYGqshIGWYOHJC34h4MST4+MtA8/TTQqVPJ/ZBu3JDt3rAB2Lu36PCSX926gJubrPjowoyfn7y2FSGEvA75w44uYLVvD/TqVbHzG0lmpsyRDg6yWXXqlO39QshuWwcOAP/+K/+Y+/rKO4Vt2sica+y593RT9ty/L//I1K1r3PMz3BSD4YaomtFq5QRlly8XvsXHFz7stijBwTLQDBpU+fq4APJbatMmGXT++Sdvv4+PDDL5N3f3vG+w+/dlwPnlF9k/Jikp771WVjLAnT9f+CRvnp6y0vLQQ8Bjj8lvx/J+M16/LoPO5cvydlD+vjC6W0T16tXYPi6nTgErVshiXf7/FF5eMtv5+8uffn6y6KfLlXfv5hXYdIGmsLt4Oo6OMujowk7btrJgmJYms96tW3J78PHt2zJ4ZWbKP1IP/tQliu7dgb//Nu61YbgpBsMNURVw7RrwySfyb9LC/gbV/dTNvJq/b0dxdHOSPLg5OQHNmsnbPJVwWGuR4uJkSGnTRv4Tv7S0WtmH5Zdf5BYTk/eajY2sxujCzEMPyVtPVCytVoaLn36S8/35+eXdfSupgpGZCWzcKEeeR0Tk7W/USIaXB+fH07G3l1WdtDQZih78Ntdl1i5dZGbU3UmNjS1fN6Wy6NxZ/hEzJoabYjDcEFUBr7wi/6YvLUtL+QXs5VX45uoqvwlqaDWgROfOyW/mFi3kt2Vp+uIQcnPlhMU//SS7F127VvhxrVrJoKPbfH1laDl5Mq9Kc+eOPNbSUvbJfuUV4NFH5fPbt4Hjx4Fjx2R3qmPHZEh5cJLkxo3z8miXLjLYFHYXLytLrqxw6pRsw8mT8vHVq/L2l654Vq+e4eN69WRQq11bntfGpuif1tbGv+3FcFMMhhuiKqBlS/m379ix8pvhwb858z92d5fBhsGFzCA7W97d+/lnOZAu/4A2e3vgySdl96DoaNl16dy5gudwdJR3+k6dytvn5QWMGweMHg00bFhyO3JyZAXmxAn5v0KXLvJ/heqM4aYYDDdElVxiYl5fkZs3jd8rkaiM0tLkKPFffgF+/10+16lXT/bJfvpp2V3rwW5aKSmyD0xkpNwOHszr121pKd/78suySmPq+SGrurJ8f/OfOkRUueg6ybZvz2BDFSaEzMuOjvJ2SmldvSr7Xf/6qxy1lL9bl7u77G/+9NPAI48Uv2qCs7Os5jz5pHyemytvA509KzvdVvdqi1IYboioctENsXjkEWXbQVWKELJvdf5+JLq+JLpJjF1c5AijwrbGjeXUQLo+1lFRhudv0UJWWQYMkP1myltlsbLKG8xGpsNwQ0SVC8NNtSKE7Gh75owclHXmjNwyM2U/kyZN8tZe1IUMtbrw89y8KQfHJSTIEeUJCXJuw9OnZZApai5FlUq+/8YNuZVmFI9KJTvm6gJNq1YVuQpkbgw3RFR53Lole0gCsmZPlZoQsipy86bhFheXF2RiY4ueZigysuA+lUreqmnSRI7USUqSISYxsXSrYDRvnjdvi27z8QHu3ZPtKmy7dEmGLRsb2W9mwAA5YqmqrFlKBTHcEFVVubnyW6OsU5dWZhER8huzZcsa/82Sni43a2tZybC2lrc0ihpem5UlhxOnphb8qVve6u7dvJ/5H6elyS9/Kyv5Ofk/M//jWrXyJnnTTe5WmimGLC1l6GjVSq5q0KqV7P9y+XJeuLh0ST6+d09WZa5fL/xc9evL8NOwYd7P1q1loClu/VJrazk0urDJpoWQE945OJRt/VOqvBhuiKqa7Gw5O+0HH8jZvbp2lesMPf+8nIyuLHJzgf37ZZ2+T5+SlxkwtRp8S0oI2T/kjz/kFhEh//Pkp1LlBQ5d6NBoZIh5cM4Tc7KxkaFDt3l65oWYVq3kclmlmTpHCDm6SBd0bt2SGdfdXW5uboXfsqoolarGZ+lqh+GGqKrIyQG+/RZ4/335t7/O/v1ye+MNOXxj1Cigd2/5z+XCZGQAO3bkjWvVdVSwsgL+7/+Ad95RbkxqGcNNWlrehGHlpdXKPiHXr8sv09u386ab1z3W/bx/X3ZKbdBAfhkW9tPFpfjRM/mlp8uROLpAk39tTCCvr4iOEDLEFBVkVCo5KqhOHZlzdT+dnOR+Bwe56R7n/2lnJ4NSVpbMz9nZeY/z73NwMAwy9esbr9qhUsnr5+IiZ7glKi/Oc0NU2eXmAt9/D8ydC1y8KPe5ugLvvitXeP7pJ7mKdf4p9Bs1AkaMAEaOlMM8kpKA336Tgeavv+S3tE69evKYAwfk8+BgOWWquceo6m6xaTTyfkXjxoUelpMjM9mXX8qMBsg5/B7smKr72aiR/FK+eFFuFy4Y/oyLK7kvR1nZ2xuGizp1DB+r1bIys3ev4Wfb2Mhc2revXNOySRN5OR4MG/kfW1jkndvBgXOlUPVVpSbxW7ZsGRYuXIjExET4+fnh008/RWBgYKHH5uTkICwsDN988w2uXbuGli1bYsGCBXj88cdL/XkMN1RlaDTAunUy1OimOXVxAaZOBV57zfCfy0IAhw/L21Xr1hmuuNe8ufwmz/+/etOmstfkU08BDz8sqzyrVgGvvy57Vjo7A998I79lzWXnTrkoo5eXYWXqP5cvA19/DaxcKTuYlpaFRcFFrR9Uq5bsu/HgNPP5f9arJytEKSkyKyYlyX4a+X/euFHyZz2oSROgXz95qXv2rPii10TVVZWZxG/Dhg0IDQ3F8uXL0aVLFyxZsgQhISGIjY1FgwYNChw/Y8YMfPfdd1ixYgVatWqF7du3Y9CgQdi/fz86KN1XgMhYcnKAH3+Ut4jOnJH76tcHpkwBJkwofCYylUrW8Tt3BhYtklWaNWvktKrnz8tjOnfOG9da2KrOL70k++8MGSIXsunXD5g8GQgLK76jgxByrvkNG2QVqV49YPfust+rKOSWVG4usHWrXGbqzz/z8lmDBnKa+rFjZbVC10cjf8dU3WNdZaROHbk2ZrNmMtvl/9moUdF38cpCq5W3r4rq2Kv7efeuHMXTt68smhl7DR6iGk8oKDAwUEyYMEH/XKPRiIYNG4qwsLBCj3d3dxefffaZwb6nn35aDBs2rNSfmZqaKgCI1NTU8jWaqChpaULMmSPEd9/Jx2V186YQ8+YJ0bChEPJ7XIi6dYX44IPynU8IIa5fF2LLFiGuXi39ezIzhXjjjbw2dOggRGxsweNOnRJi5kwhWrTIO1a3rVtX9rY+8oh874oV4tYtIWbPFsLDw/C0vXsLsWGDEFlZpTulRiMvwc2bZW8OEVUuZfn+Vqxyk52djaioKEybNk2/z8LCAsHBwYgsbPIDAFlZWbB5YOEOW1tb7Nu3r8jPycrKQla+3ndp+RcFIQLkBBpnzsh7AhXx5pvy1g4gO0/07SurIP36FV/FOHMG+OQTeRsoM1Puc3WVt4hef1329iwvd3dZqSkLGxvZnuBgWR45ehTo2BH47DN5C2vDBmD9ejlrWv739O0rM8jmzbLj85Ahpf/M+/eBf/8FAByv8wie6iBvQwHyDtmoUXL9HR+fsv0qFhac3p6oRjJD2CrUtWvXBACxf/9+g/3vvPOOCAwMLPQ9Q4cOFb6+vuLs2bNCo9GIHTt2CFtbW2FtbV3k58yePVsAKLCxckNCCFmlaNlSlgWWLy//ecLD88oLzZsblhtq1xZiyBBZQbl/Xx6v1QqxY4cQTzxheKyfnxBr1uQdp7SrV4Xo1atgZQYQolYtIfr3N6xUnTkjX7O0FCIxsfSf8/ffQgAi3cFV1LLSCkCIpk2F+OGHynMpiEhZZancVKl+9Z988gl8fHzQqlUrWFtbY+LEiRg9ejQsihkeMG3aNKSmpuq3Kw+OtaSa7YMP5BSqABAaKlezK6vMTFlWAIDx4+U5jh6VHX+9veXQ6/XrgYEDZWeRF1+Ui0I+9pjsSKJSyY69u3fL940caZrJPMrDw0N29P3gA9kpxdISCAmRFaqkJLmq4LBhsuMLICff69xZdobesKHUH5O5Xfa32Xr3EeTkqvDMM8CRI8DQoZXnUhBR1aFYuHF2doalpSWSkpIM9iclJcHNza3Q97i4uGDLli3IyMjA5cuXcebMGdjb26Np06ZFfo5arYajo6PBRgRA3laZP18+btJETo06fHjpplzNb84cORrJw0N2vlWp5Kp48+fLscb//iuDk4eHnJjl++/lZ9euLW87nT0rh2j37Fk5e5ZaWgL/+5/spZuYKDspjx5d9Irdw4fLn99+W6rTR0UBhxbLcBNh8QiWLgU2biz7fIRERDqKhRtra2sEBAQgPDxcv0+r1SI8PBxBQUHFvtfGxgYeHh7Izc3FTz/9hAFl7VNAVZ9GI0OBbrnf8rx/3Dg5HGfAADnhSJ06cqbeefNKf56jR4GPPpKPP/+8YP8YlQoIDJQjmOLjgX/+kRWdjz8Grl4Fli6VQ7WrAk9P2QGmJIMHy0B0+HDeaK9CCAEsWwZ0D8pFx8wIAMDYtY/g9dcrZ8YjoirEDLfJirR+/XqhVqvFmjVrxOnTp8XLL78s6tSpIxL/u1c/fPhw8e677+qPP3DggPjpp5/EhQsXxN9//y169+4tmjRpIm7fvl3qz+RoqSpIqxXi0iUhfvxRiHfeEaJHDyHs7WXfjmbNyta3Q+ezz+T7HRyEuHJF7vvhh7z+IgcOlHyOnBwhAgLke557ruxtqM769ZPXZfr0Ql9OTRXi+eflIZ1wUAhAaJzqyOFNRESFqBKjpQBg8ODBuHHjBmbNmoXExET4+/tj27ZtcP1vkY/4+HiD/jT379/HjBkzcPHiRdjb26Nv37749ttvUac6LRxY0+XmyslJYmPl/YqDB4FDh+QsaYW5cEGORtqzR04LWxpXrwK6UXphYXKSE0B28Pj1V9k/ZvhwWZUpbE4ZnU8+kW2sU0dWYCjPiy/KCWq++w6YOxdZORaIj5cjoC5dAhYskNPvWFkBHz3xN/AbYPFId06vS0RGofgMxebGGYorgdxc+S137pz8hjt3Lu9xXFzB1QIB+S3o5yc7qwYGys3KSg5NTkkBHn9cBpOSFvURQnbs/fVX4KGHgH37DGdvu31bdva9ehV45RVg+fLCz3PxopyFLTNTTpk7Zky5L0d1kZws5/47exa4dj4T0z91hV3uXQys/zd+udm9wPGNG8s+xw+FDZD/PRYuBN5+W4GWE1FVUGVmKKYaJi0NmDFDTjdb3BLGNjayH4q/f16Q8fOT+x/0++9Ar16yk+vLL8tRPMV12Pj557wQtGJFwWlp69aVM/sGB8vFi/r3l5Wh/IQAXn1VBpvevWXn2hokO1t2pTl+HDh2LO+n4dgAWzTDsxiD1eh781v8gu6wtZUrK3h5yVw4bRpQv65W9kMCauRK4ERkGqzckOnpJnZ7/XW59DIgg0qzZnJWNh8fGWZ0jxs2LNvtid9/l52CtVoZnt5/v/Dj7twBWreWI36KOw6Qo5s+/lhOpnfihFzTSWftWjlc28ZGvlZVOgSX09WrcuXqPXvkXbiYmMIHlKlU8j9f69YywDycvQvPLe+DXHsn3D6dCOdGNgVz54kTslJWu7asmpV2OW0iqnFYuaHK48oVYOJEWS0BZKD5/HNZGTFW/4onn5S3j15+Wa7H1KiRvKX0oHfflcGmRQtg+vTizzlvnlxy+tQpOapq82b57Z2cLNdbAoD33qt0wSY1VXZXOntW/oyNlXnSy0uGDt3WvLlcBLIwSUlyyp3du2Wo0S1NlZ+Tk8wkfn55P9u0eaCLkrYn8HsjWF29CpeDWwHPZwqeSLeeVNeuDDZEZDQMN2QaGg3w6aeyQpKRIfvHTJ0qQ4Uplj0eNw64dk3OOTN+vJxz/6mn8l7/5x95mwmQt8UKu8WVn42NnI+mc2c5B82qVXJhyTfflCsj+vvL6o5Cbt6UVZTjxw3DzAPTRulFRBg+t7SUOVMXdpo2lefavVvmufwsLIBOneQduKAgGWQaNy7FcG0LCznB34IFcs6bZ4oJN7wlRURGxNtSZHxHjsgqSlSUfN61qwwUbdqY9nOFkCFn5UoZoMLD5bdxVpYMI2fOyGWkV6wo/Tk//FCGstq15aR8r78uv7QPHgQCAgwO1Whk/2QrK1kZadDAOPO13LolL2VUlJw6JipKjjgqipubnChYt3l4yH7aZ87IW0oxMSVPD+TvL7sy9e4NdO9egQn1Tp4E2rWTVZmEBLm6uY4Q8hZkYqKcZ4gBh4iKUZbvb4YbMp70dGDWLDlEWquV34gffigDhbmG+Oom5fvjD/lFGhEBrFsnKzqurvKbvaiZdQuj0chveF2FAQDeeitv4r7/XL8uR4/v2pW3z95ehpzCNmtr2b86LU3eStI9zr/vwgUZZuLiCm9a8+ZAhw5Aq1Z5QaZFi5LX2RRCtlcXdGJi5Gf5+MhftUcPwwxSYR06ANHR8nbka6/l7T93TjbY2lr+wiVV04ioRmO4KQbDjYmkpsp/6h89Kp8PGSI75BaxlIZJZWTIthw6JGfVTUyUPWA3bACef77s57t8WXYsSUuTyzScOGHQueT33+Wq1TdvysW/XVzkZMTG/D+rWTNZKOrUSf7s2FFOr1MlLF4sA2FQELB/f97+lStl8O3e3TA8EhEVgh2KybwyM+WQ6aNH5b2YNWuAJ55Qrj21a8vE0a1bXm/Yfv2A554r3/m8vOQIqdmz5XoB/wWb+/flHSvd/H3+/nL+v5Yt5Z2wuDj58efPy8qI7nFcnCwIOTjIKktRm7u7DDMdO5at2FTpDB0KvPMOEBkpL0SzZnI/+9sQkYmwckMVk5MDPP20DBOOjrLvhL+/0q2SLlyQX5w5OfL+TuPGRjv1mTOyOHXsmHz+5puyS05pVrDWaGRfnBo1GW9IiBx99t57MiQCsgp26RKwfbtcIZ2IqBhl+f6uSX+9krFptXICu99/l/0lfv+98gQbQFYILl6UfTuMFGyEkHdTAgJksHFxkasMfPxx6YINIEcq1ahgA+StFP7dd/IixsfLYGNpKW9XEREZUU37K5YedPs2MGgQMGECcONG6d8nhCxXfP+9HB60aZPsO1HZqNUVGOpj6M4dWa0ZOxa4dw/o00cGnL59jXL66m3gQNkh6fx54N9/82Yl7thR3p8jIjIi9rmpyYSQQ7a3bJHP162TC0mOHVtwWYIHzZ0r57FRqYBvvim4REEVlZ4u5+lLSir487ffZN9iKys5V+A779TACkx52dvL25fffSfnvNGtH8b+NkRkAgw3NdmqVbLiYmUlxxOfPCnXTFq5Ug7b7dSp8Pd9+qnsO6F7/MILZmtyRQkhB0/lHwYdEyM7+SYlyYpMcZo2lRkwMNA87a1Whg+X4WbDhrwe0gw3RGQC7FBcU505IzuO3LsnZ5ANDZWBZuZMOeRZpZJB54MPDIfqfP898OKL8vGcOXJeG4XcuSPnhcvOlqOTsrMLf5yQYBhkUlOLP6+NjZwSx9VVDv7SPfb0lDmuJv+xqZDc3Lyh+To3bwL16inXJiKqMjjPTTEYbiC/8YOC5NDtPn3kKBbd/ZWEBHm/5fvv5XMXFzkR34gRcmK8gQPlcJ833gCWLDHOFLxldOeOzFxLl8oAU1YWFrIC07q1LFi1bi0nsHN3l2HG3l6RX6tmeOstOe8NIGcuPn5c2fYQUZXBcFMMhhvkfcHUry+/XBo2LHjMnj2yk/Hp0/J5YKA89v59Wbn55huzdzjJzZWrOMyeDaSkyH1168pKi7W13NTqgo/r189bQ6lVKxlkOBmuQo4elZ2IAfnn67PPlG0PEVUZnMSPirZ9e96/nFevLjzYAEDPnvKLaMkSefvp4EG5v39/2VfHzMHmzz9lJouJkc9btQIWLZJzBbLKUoX4+8vZno8fl1VDIiITYOWmJklOll8sSUll+1fzlSuyb41KJWfoNcWq3kU4eRJ4+22ZyQBZhZkzRw7yqlXLbM0gYzp3Ti7DMGIEkykRlRpvSxWjxoYbIeRw7T//BNq2lZUYM4aUskpOlrefvvpKzhVYq5bs5jNjRhVaU4mIiIyGt6Wqu+RkOQnahQvAo4/KUn9J/wJeulQGGxsbOZa5kgabU6eAL7+Uy1PdvSv3Pf207NOsW5KIiIioOAw3VcGVK3KRQd125kzea1OnyltNo0YBw4bJ4T4POnYMmDJFPl60SFZuKpH79+V0O19+Cezbl7e/Y0e5rAGnQiEiorLgbanK6M4d4Kef8sLMpUsFj2nXTs4Z8tdfeeOhrazkWgCjRslbUNbWch6bgAAZiJ56Ss5GXEn6OZw9K287rV4N3Lol91layma++ioQHMwZgImISOJtqaruuedkaNGxtJRljEcekdvDD+dNfHbrFrB+vRyaffAg8OuvcqtfX844l5Iig427u5x5WOFgc/s2sHOnrNLs2pW339MTGDcOeOmlogdwERERlQYrN5WNEHIhwYwMuTBl375ywj17+5Lfe/q0DDnffisn49NRqWSiMPPQ2+Rk4MgRwy0uzrBZ/foBr7wih3SXtJwVERHVXBwtVYxKH27i4wEvL3mL6d698o13zs2VYeabb2Qn4qlTgf/9z/htzefOHSAyUhaPoqJkkLl2rfBjmzWTRaWxY4HGjU3aLCIiqiZ4W6oq080I3KJF+SdysbKSpZAnnjBeu/IRQnYDioiQ2759cpTTgzFZpQJatpR31HSbv7/hUlVERETGxnBT2ejCja+vsu14wNmzsgi0b58MNPnveuk0bw507SoXE+/YEfDzK93dNCIiImNiuKlsdOsLVJJwExcnJ9P77jvDykytWnIQVrducuvaVa6cTUREpDSGm8qmklRuEhLkyttffQXk5Mh9jz4K9Oolw0znzpV2HkAiIqrhGG4qEyEUDze3b8vZgD/5BMjMlPsefRSYN0/ebiIiIqrsGG4qk8REOezIwkJ2KDajjAwZaD78EEhNlfseekiGml69zNoUIiKiClF8/tdly5bB29sbNjY26NKlCw4ePFjs8UuWLEHLli1ha2sLT09PTJ48Gffv3zdTa01MV7Vp1gxQq83ykbm5cqHvZs2A6dNlsGnbFvjlF7lwM4MNERFVNYpWbjZs2IDQ0FAsX74cXbp0wZIlSxASEoLY2Fg0KGSNpB9++AHvvvsuVq1aha5du+Ls2bMYNWoUVCoVFi9erMBvYGRmviUVEQGMHw8cPy6fN20KzJ0LDBnCCfWIiKjqUrRys3jxYowbNw6jR4+Gr68vli9fDjs7O6xatarQ4/fv349u3brhhRdegLe3Nx577DEMHTq0xGpPlWGmcJOcDIweLVdxOH5cruSwbJlcpWHYMAYbIiKq2hQLN9nZ2YiKikJwcHBeYywsEBwcjMjIyELf07VrV0RFRenDzMWLF/HHH3+gb9++RX5OVlYW0tLSDLZKy8ThRqMBvvhCTqy3Zo3cN3YsEBsrKzjlnTOQiIioMlHstlRKSgo0Gg1cH5gcxdXVFWfOnCn0PS+88AJSUlLw8MMPQwiB3NxcvPrqq/hfMUsLhIWFYc6cOUZtu8mYMNwcOiQDzOHD8nmHDsDnn8tOw0RERNWJ4h2Ky2LPnj2YN28ePv/8cxw5cgQ///wztm7divfff7/I90ybNg2pqan67cqVK2ZscRncuCFX8FapgFatjHbaW7eAV18FunSRwcbREfj0Uxl2GGyIiKg6Uqxy4+zsDEtLSyQlJRnsT0pKgpubW6HvmTlzJoYPH46xY8cCANq1a4eMjAy8/PLLmD59OiwsCmY1tVoNtZlGHlWIbmZib2/Azq7Cp8vKkhPwzZ0rMxMAvPgisHAhUMTlJSIiqhYUq9xYW1sjICAA4eHh+n1arRbh4eEICgoq9D337t0rEGAs/+v9WuUXNzfSLSmNBvj2W1n8eeMNGWx8fYE9e+R+BhsiIqruFB0KHhoaipEjR6JTp04IDAzEkiVLkJGRgdGjRwMARowYAQ8PD4SFhQEA+vfvj8WLF6NDhw7o0qULzp8/j5kzZ6J///76kFNlVTDcCAH8/jvwv/8BJ0/KfW5ucl2ol15iZ2EiIqo5FA03gwcPxo0bNzBr1iwkJibC398f27Zt03cyjo+PN6jUzJgxAyqVCjNmzMC1a9fg4uKC/v3744MPPlDqVzAeXbhp3brMb/3nH+Ddd+WkewBQpw4wdaqs3BjhDhcREVGVohJV/n5O2aSlpcHJyQmpqalwdHRUujl5GjaUq1UeOCB7/5bCsWOyUvPHH/K5rS0waRIwZQpQt64J20pERGRmZfn+5tpSlcHt2zLYAKWu3HzyCTB5srwdZWkJjBsHzJwpMxIREVFNxnBTGehGSjVqJMdql2DfPuCtt2Swee454IMPAB8fE7eRiIioimC4qQzK0Jk4JUWu/aTRyKUSvv1WTo1DREREUpWaxK/aKmW40WqBESOAa9fkEgrLlzPYEBERPYjhpjLQ3ZYqIdx89BHw55+AjQ3w44+Avb0Z2kZERFTFMNxUBqWo3EREyJFRALB0KdC+vRnaRUREVAUx3Cjt7l0gPl4+LmKk1M2bef1sXnhBruRNREREhWO4UZpuBXQ3N6BevQIva7XAyJHA1atAixbsZ0NERFQShhullTAz8aJFwNatgFot+9k4OJixbURERFUQw43Siulvs38/MG2afLx0KeDnZ8Z2ERERVVEMN0orItzcvAkMHiz72QwdKmcgJiIiopIx3CitkHCTv5+Njw/w5ZfsZ0NERFRaDDdKuncPiIuTj/OFm48/zutns3Ej+9kQERGVBcONkmJj5QJR9esDLi4AZLVm5kz58pIl7GdDRERUVgw3Sso/M/F/952mTQMyM4Hu3YFXXlGwbURERFUUw42SHuhvc/Ag8N13ctfixexnQ0REVB4MN0rKF26EAEJD5dMRI4BOnZRrFhERUVXGcKOkfOFm40a5fpSdHTBvnrLNIiIiqsqslG5AjZWVBZw/DwC436Q1pv43j82UKYCHh4LtIiIiquJYuVHKuXNyhj5HRyz5sSEuXZKh5u23lW4YERFR1cZwo5T/bkll+/hiXpjsOTx/PlC7tpKNIiIiqvoYbpTyX7g5eNcXd+8CnTsDL7ygcJuIiIiqAYYbpfwXbrack8PAP/4YsOB/DSIiogrj16lCxH8T+J0Svnj+eaBbN4UbREREVE1wtJQScnMhzsRCBeCCtS92LFC6QURERNUHKzcKyI65AIvcHKSjNp6d7Alvb6VbREREVH0w3ChgxxLZ3+acVWu8+z/+JyAiIjImfrOa2c2bQPQPMtzYd2oNR0eFG0RERFTNMNyY2Zw5QJP7Mtw06++rcGuIiIiqH4YbM8rKAr78EvCFDDcWbRluiIiIjK1ShJtly5bB29sbNjY26NKlCw4ePFjksT179oRKpSqw9evXz4wtLp/Ll4HcbA1a4Yzc4ctwQ0REZGyKh5sNGzYgNDQUs2fPxpEjR+Dn54eQkBAkJycXevzPP/+MhIQE/Xby5ElYWlriueeeM3PLyy4uDvDGJdjiPqBWA02aKN0kIiKiakfxcLN48WKMGzcOo0ePhq+vL5YvXw47OzusWrWq0OPr1asHNzc3/bZz507Y2dlVmXCjuyWFVq0AS0tlG0RERFQNKRpusrOzERUVheDgYP0+CwsLBAcHIzIyslTnWLlyJYYMGYLaRaw4mZWVhbS0NINNKXFxQGvImYl5S4qIiMg0FA03KSkp0Gg0cHV1Ndjv6uqKxMTEEt9/8OBBnDx5EmPHji3ymLCwMDg5Oek3T0/PCre7vAwqNww3REREJqH4bamKWLlyJdq1a4fAwMAij5k2bRpSU1P125UrV8zYQkMMN0RERKan6NpSzs7OsLS0RFJSksH+pKQkuLm5FfvejIwMrF+/HnPnzi32OLVaDbVaXeG2GkPcRcHbUkRERCamaOXG2toaAQEBCA8P1+/TarUIDw9HUFBQse/duHEjsrKy8OKLL5q6mUZx9y6QeeseHJAudzRqpGyDiIiIqinFVwUPDQ3FyJEj0alTJwQGBmLJkiXIyMjA6NGjAQAjRoyAh4cHwsLCDN63cuVKDBw4EPXr11ei2WUWFwfY4V7eDjs75RpDRERUjSkebgYPHowbN25g1qxZSExMhL+/P7Zt26bvZBwfHw8LC8MCU2xsLPbt24cdO3Yo0eRyiYsDaiNDPrG1BSyqdHcnIiKiSkslhBBKN8Kc0tLS4OTkhNTUVDiacdXKJUuAryafxmm0AerXB1JSzPbZREREVV1Zvr9ZPjATg8pNEXPyEBERUcUx3JiJQZ8b9rchIiIyGYYbM2HlhoiIyDwYbsxACFZuiIiIzIXhxgxSUoCMDMCelRsiIiKTY7gxg7g4+dPdiZUbIiIiU2O4MQNduGlUl5UbIiIiU2O4MQNduHFzZOWGiIjI1BhuzEAXbhrUZuWGiIjI1BhuzEAXburbsXJDRERkagw3ZqALN3VrsXJDRERkagw3JqbRAJcvy8eOVqzcEBERmRrDjYldvw7k5ABWVoCdYOWGiIjI1BhuTEx3S6pxY0CVycoNERGRqTHcmJgu3DRpAjlNMcDKDRERkQkx3JiYQbi5x8oNERGRqTHcmBgrN0RERObFcGNihYYbVm6IiIhMhuHGxAq9LcXKDRERkckw3JhQVhZw7Zp83MRbsHJDRERkBgw3JhQfDwghs0yDOtmAVitfYOWGiIjIZBhuTEh3S8rbG1Ddy8h7gZUbIiIik2G4MaFC+9vUqiU3IiIiMolyhZvdu3cbux3VEoeBExERmV+5ws3jjz+OZs2a4f/+7/9w5coVY7ep2uAEfkREROZXrnBz7do1TJw4EZs2bULTpk0REhKCH3/8EdnZ2cZuX5XGyg0REZH5lSvcODs7Y/LkyYiOjsa///6LFi1aYPz48WjYsCHeeOMNHDt2zNjtrJJYuSEiIjK/Cnco7tixI6ZNm4aJEyciPT0dq1atQkBAALp3745Tp04Zo41VUno6kJIiH7NyQ0REZD7lDjc5OTnYtGkT+vbtCy8vL2zfvh2fffYZkpKScP78eXh5eeG5554zZlurFF3Vpm5dwMkJrNwQERGZiVV53vT6669j3bp1EEJg+PDh+PDDD9G2bVv967Vr18ZHH32Ehg0bGq2hVY3BLSmAlRsiIiIzKVfl5vTp0/j0009x/fp1LFmyxCDY6Dg7O5dqyPiyZcvg7e0NGxsbdOnSBQcPHiz2+Dt37mDChAlwd3eHWq1GixYt8Mcff5Tn1zCpAuGGlRsiIiKzKFflJjw8vOQTW1mhR48exR6zYcMGhIaGYvny5ejSpQuWLFmCkJAQxMbGokGDBgWOz87OxqOPPooGDRpg06ZN8PDwwOXLl1GnTp3y/BomxcoNERGRMspVuQkLC8OqVasK7F+1ahUWLFhQ6vMsXrwY48aNw+jRo+Hr64vly5fDzs6u0HPrzn/r1i1s2bIF3bp1g7e3N3r06AE/P7/y/BomxcoNERGRMsoVbr788ku0atWqwP42bdpg+fLlpTpHdnY2oqKiEBwcnNcYCwsEBwcjMjKy0Pf8+uuvCAoKwoQJE+Dq6oq2bdti3rx50Gg0RX5OVlYW0tLSDDZzYOWGiIhIGeUKN4mJiXB3dy+w38XFBQkJCaU6R0pKCjQaDVxdXQ32u7q6IjExsdD3XLx4EZs2bYJGo8Eff/yBmTNnYtGiRfi///u/Ij8nLCwMTk5O+s3T07NU7asIIVi5ISIiUkq5wo2npyciIiIK7I+IiDDpCCmtVosGDRrgq6++QkBAAAYPHozp06cXWy2aNm0aUlNT9Zs5lou4eVPOcwPIFcEBsHJDRERkJuXqUDxu3Di8+eabyMnJQe/evQHITsZTpkzBW2+9VapzODs7w9LSEklJSQb7k5KS4ObmVuh73N3dUatWLVhaWur3tW7dGomJicjOzoa1tXWB96jVaqjV6tL+akahq9q4uwM2Nv/tZOWGiIjILMoVbt555x3cvHkT48eP168nZWNjg6lTp2LatGmlOoe1tTUCAgIQHh6OgQMHApCVmfDwcEycOLHQ93Tr1g0//PADtFotLCxk0ens2bNwd3cvNNgopcAtKYCVGyIiIjMp120plUqFBQsW4MaNGzhw4ACOHTuGW7duYdasWWU6T2hoKFasWIFvvvkGMTExeO2115CRkYHRo0cDAEaMGGEQll577TXcunULkyZNwtmzZ7F161bMmzcPEyZMKM+vYTKFhhtWboiIiMyiXJUbHXt7e3Tu3Lnc7x88eDBu3LiBWbNmITExEf7+/ti2bZu+k3F8fLy+QgPIvj7bt2/H5MmT0b59e3h4eGDSpEmYOnVqRX4No2PlhoiISDnlDjeHDx/Gjz/+iPj4eP2tKZ2ff/651OeZOHFikbeh9uzZU2BfUFAQDhw4UKa2mlux4YaVGyIiIpMq122p9evXo2vXroiJicHmzZuRk5ODU6dOYdeuXXBycjJ2G6ucYm9LsXJDRERkUuUKN/PmzcPHH3+M3377DdbW1vjkk09w5swZPP/882jcuLGx21ilaLXA5cvyMSs3RERE5leucHPhwgX069cPgBz1lJGRAZVKhcmTJ+Orr74yagOrmuvXgexswNISaNQo3wus3BAREZlFucJN3bp1cffuXQCAh4cHTp48CUCu2H1P9yVeQ+luSTVuDFjpejTl5srEA7ByQ0REZGLl6lD8yCOPYOfOnWjXrh2ee+45TJo0Cbt27cLOnTvRp08fY7exSim2vw3Ayg0REZGJlSvcfPbZZ7h//z4AYPr06ahVqxb279+PZ555BjNmzDBqA6uaYkdKWVgAZp4tmYiIqKYpc7jJzc3F77//jpCQEAByJe93333X6A2rqkqcwE+lMnubiIiIapIy97mxsrLCq6++qq/ckCFO4EdERKSscnUoDgwMRHR0tJGbUj1w6QUiIiJllavPzfjx4xEaGoorV64gICAAtR+oSLRv394ojatqsrOBq1flY1ZuiIiIlFGucDNkyBAAwBtvvKHfp1KpIISASqWCRqMxTuuqmPh4QAjA1hb4b3ksiZUbIiIisylXuInT3XshA7rL4u39QL9hVm6IiIjMplzhxsvLy9jtqBYK7W8DsHJDRERkRuUKN2vXri329REjRpSrMVVdkeGGlRsiIiKzKVe4mTRpksHznJwc3Lt3D9bW1rCzs2O4YeWGiIhIMeUaCn779m2DLT09HbGxsXj44Yexbt06Y7exymDlhoiISHnlCjeF8fHxwfz58wtUdWoSVm6IiIiUZ7RwA8jZi69fv27MU1YZ6enAjRvyMSs3REREyilXn5tff/3V4LkQAgkJCfjss8/QrVs3ozSsqrl0Sf6sU0duBli5ISIiMptyhZuBAwcaPFepVHBxcUHv3r2xaNEiY7SryklKAqysCqnaAKzcEBERmVG5wo1WqzV2O6q8Pn2A+/eBO3cKeZGVGyIiIrMxap+bms7SEqhfv5AXWLkhIiIym3KFm2eeeQYLFiwosP/DDz/Ec889V+FGVTu6cMPKDRERkcmVK9z8/fff6Nu3b4H9TzzxBP7+++8KN6ra0d2WYuWGiIjI5MoVbtLT02FtbV1gf61atZCWllbhRlU7rNwQERGZTbnCTbt27bBhw4YC+9evXw9fX98KN6raYeWGiIjIbMo1WmrmzJl4+umnceHCBfTu3RsAEB4ejnXr1mHjxo1GbWC1wMoNERGR2ZQr3PTv3x9btmzBvHnzsGnTJtja2qJ9+/b466+/0KNHD2O3sWrTaoHMTPmYlRsiIiKTUwkhhNKNMKe0tDQ4OTkhNTUVjo6Opv/AjAzA3l4+vns37zERERGVWlm+v8vV5+bQoUP4999/C+z/999/cfjw4fKcsvrS9bcBeFuKiIjIDMoVbiZMmIArV64U2H/t2jVMmDChwo2qVnT9bWxsAAvOmUhERGRq5fq2PX36NDp27Fhgf4cOHXD69Okyn2/ZsmXw9vaGjY0NunTpgoMHDxZ57Jo1a6BSqQw2GxubMn+m2XCkFBERkVmVK9yo1WokJSUV2J+QkAArq7L1Ud6wYQNCQ0Mxe/ZsHDlyBH5+fggJCUFycnKR73F0dERCQoJ+u3z5cpl/B7Ph0gtERERmVa5w89hjj2HatGlITU3V77tz5w7+97//4dFHHy3TuRYvXoxx48Zh9OjR8PX1xfLly2FnZ4dVq1YV+R6VSgU3Nzf95urqWp5fwzy4aCYREZFZlSvcfPTRR7hy5Qq8vLzQq1cv9OrVC02aNEFiYiIWLVpU6vNkZ2cjKioKwcHBeQ2ysEBwcDAiIyOLfF96ejq8vLzg6emJAQMG4NSpU0Uem5WVhbS0NIPNrFi5ISIiMqtyhRsPDw8cP34cH374IXx9fREQEIBPPvkEJ06cgKenZ6nPk5KSAo1GU6Dy4urqisTExELf07JlS6xatQq//PILvvvuO2i1WnTt2hVXr14t9PiwsDA4OTnpt7K0zyhYuSEiIjKrck3iBwC1a9fGww8/jMaNGyM7OxsA8OeffwIAnnrqKeO0rhBBQUEICgrSP+/atStat26NL7/8Eu+//36B46dNm4bQ0FD987S0NPMGHFZuiIiIzKpc4ebixYsYNGgQTpw4AZVKBSEEVCqV/nWNRlOq8zg7O8PS0rJA5+SkpCS4ubmV6hy1atVChw4dcP78+UJfV6vVUKvVpTqXSbByQ0REZFblui01adIkNGnSBMnJybCzs8PJkyexd+9edOrUCXv27Cn1eaytrREQEIDw8HD9Pq1Wi/DwcIPqTHE0Gg1OnDgBd3f3sv4a5sHKDRERkVmVq3ITGRmJXbt2wdnZGRYWFrC0tMTDDz+MsLAwvPHGGzh69GipzxUaGoqRI0eiU6dOCAwMxJIlS5CRkYHRo0cDAEaMGAEPDw+EhYUBAObOnYuHHnoIzZs3x507d7Bw4UJcvnwZY8eOLc+vYnqs3BAREZlVucKNRqOBg4MDAHlr6fr162jZsiW8vLwQGxtbpnMNHjwYN27cwKxZs5CYmAh/f39s27ZN38k4Pj4eFvlm9r19+zbGjRuHxMRE1K1bFwEBAdi/fz98fX3L86uYHis3REREZlWucNO2bVscO3YMTZo0QZcuXfDhhx/C2toaX331FZo2bVrm802cOBETJ04s9LUHb3N9/PHH+Pjjj8vTbGWwckNERGRW5Qo3M2bMQMZ/FYm5c+fiySefRPfu3VG/fn1s2LDBqA2s8li5ISIiMqtyhZuQkBD94+bNm+PMmTO4desW6tatazBqisDKDRERkZmVe56bB9WrV89Yp6peWLkhIiIyq3INBacyYOWGiIjIrBhuTI2VGyIiIrNiuDE1Xbhh5YaIiMgsGG5MTXdbipUbIiIis2C4MTVWboiIiMyK4cbUWLkhIiIyK4YbUxKClRsiIiIzY7gxpexsQKuVj1m5ISIiMguGG1PSVW0AVm6IiIjMhOHGlHT9bWrVkhsRERGZHMONKbG/DRERkdkx3JgSR0oRERGZHcONKXHpBSIiIrNjuDElLppJRERkdgw3psTKDRERkdkx3JgSKzdERERmx3BjSqzcEBERmR3DjSmxckNERGR2DDemxMoNERGR2THcmBIrN0RERGbHcGNKrNwQERGZHcONKbFyQ0REZHYMN6bEyg0REZHZMdyYEis3REREZsdwY0qs3BAREZkdw40p6cINKzdERERmw3BjSrrbUqzcEBERmU2lCDfLli2Dt7c3bGxs0KVLFxw8eLBU71u/fj1UKhUGDhxo2gaWFys3REREZqd4uNmwYQNCQ0Mxe/ZsHDlyBH5+fggJCUFycnKx77t06RLefvttdO/e3UwtLQdWboiIiMxO8XCzePFijBs3DqNHj4avry+WL18OOzs7rFq1qsj3aDQaDBs2DHPmzEHTpk3N2NoyYuWGiIjI7BQNN9nZ2YiKikJwcLB+n4WFBYKDgxEZGVnk++bOnYsGDRrgpZdeKvEzsrKykJaWZrCZDSs3REREZqdouElJSYFGo4Grq6vBfldXVyQmJhb6nn379mHlypVYsWJFqT4jLCwMTk5O+s3T07PC7S6V3FwgO1s+ZuWGiIjIbBS/LVUWd+/exfDhw7FixQo4OzuX6j3Tpk1Damqqfrty5YqJW/kfXdUGYOWGiIjIjKyU/HBnZ2dYWloiKSnJYH9SUhLc3NwKHH/hwgVcunQJ/fv31+/TarUAACsrK8TGxqJZs2YG71Gr1VCr1SZofQl0/W1UKkCJzyciIqqhFK3cWFtbIyAgAOHh4fp9Wq0W4eHhCAoKKnB8q1atcOLECURHR+u3p556Cr169UJ0dLT5bjmVRv7+NiqVsm0hIiKqQRSt3ABAaGgoRo4ciU6dOiEwMBBLlixBRkYGRo8eDQAYMWIEPDw8EBYWBhsbG7Rt29bg/XXq1AGAAvsVx5FSREREilA83AwePBg3btzArFmzkJiYCH9/f2zbtk3fyTg+Ph4WFlWqa5DEkVJERESKUAkhhNKNMKe0tDQ4OTkhNTUVjo6Opvug8HAgOBho2xY4ccJ0n0NERFQDlOX7uwqWRKoIXeWGt6WIiIjMiuHGVHR9bnhbioiIyKwYbkyFlRsiIiJFMNyYCis3REREimC4MRVWboiIiBTBcGMqrNwQEREpguHGVFi5ISIiUgTDjamwckNERKQIhhtTYeWGiIhIEQw3psLKDRERkSIYbkyFC2cSEREpguHGVLhwJhERkSIYbkyFlRsiIiJFMNyYCis3REREimC4MRVWboiIiBTBcGMqrNwQEREpguHGVFi5ISIiUgTDjSlotUBmpnzMyg0REZFZMdyYgi7YAKzcEBERmRnDjSno+tsADDdERERmxnBjCrr+NjY2gAUvMRERkTnxm9cUOFKKiIhIMQw3psCRUkRERIphuDEFVm6IiIgUw3BjCrrKDcMNERGR2THcmIKucsPbUkRERGbHcGMKrNwQEREphuHGFFi5ISIiUgzDjSmwckNERKQYhhtTYOWGiIhIMZUi3Cxbtgze3t6wsbFBly5dcPDgwSKP/fnnn9GpUyfUqVMHtWvXhr+/P7799lsztrYUWLkhIiJSjOLhZsOGDQgNDcXs2bNx5MgR+Pn5ISQkBMnJyYUeX69ePUyfPh2RkZE4fvw4Ro8ejdGjR2P79u1mbnkxWLkhIiJSjOLhZvHixRg3bhxGjx4NX19fLF++HHZ2dli1alWhx/fs2RODBg1C69at0axZM0yaNAnt27fHvn37zNzyYrByQ0REpBhFw012djaioqIQHBys32dhYYHg4GBERkaW+H4hBMLDwxEbG4tHHnmk0GOysrKQlpZmsJkcKzdERESKUTTcpKSkQKPRwNXV1WC/q6srEhMTi3xfamoq7O3tYW1tjX79+uHTTz/Fo48+WuixYWFhcHJy0m+enp5G/R0KxcoNERGRYhS/LVUeDg4OiI6OxqFDh/DBBx8gNDQUe/bsKfTYadOmITU1Vb9duXLF9A3kwplERESKsVLyw52dnWFpaYmkpCSD/UlJSXBzcyvyfRYWFmjevDkAwN/fHzExMQgLC0PPnj0LHKtWq6FWq43a7hJx4UwiIiLFKFq5sba2RkBAAMLDw/X7tFotwsPDERQUVOrzaLVaZGVlmaKJ5cPKDRERkWIUrdwAQGhoKEaOHIlOnTohMDAQS5YsQUZGBkaPHg0AGDFiBDw8PBAWFgZA9qHp1KkTmjVrhqysLPzxxx/49ttv8cUXXyj5axhi5YaIiEgxioebwYMH48aNG5g1axYSExPh7++Pbdu26TsZx8fHw8Iir8CUkZGB8ePH4+rVq7C1tUWrVq3w3XffYfDgwUr9CgWxckNERKQYlRBCKN0Ic0pLS4OTkxNSU1Ph6Ohomg9xdATu3gXOnQP+6xtERERE5VeW7+8qOVqqUhOClRsiIiIFMdwYW3Y2oNXKx+xzQ0REZHYMN8amq9oArNwQEREpgOHG2HQjpWrVkhsRERGZFcONsbG/DRERkaIYboyNc9wQEREpiuHG2Fi5ISIiUhTDjbGxckNERKQohhtj01VuGG6IiIgUwXBjbLrKDW9LERERKYLhxthYuSEiIlIUw42xsXJDRESkKIYbY2PlhoiISFEMN8bGyg0REZGiGG6MjZUbIiIiRTHcGBsrN0RERIpiuDE2Vm6IiIgUxXBjbFx+gYiISFFWSjeg2uHyC0RkYrm5ucjOzla6GURGZ2NjAwuLitddGG6MjZUbIjIRIQTi4+ORkpKidFOITMLCwgK+vr5Qq9UVOg/DjbGxckNEJqILNh4eHrC3tzfKv3CJKgutVouLFy/i/Pnz8PHxgbW1dbnPxXBjbKzcEJEJ5Obm6oONm5ub0s0hMolGjRohLi4OP/zwA3r06IEmTZqU6zyM/cbGyg0RmYCuj429vb3CLSEyHd3tqMzMTPzxxx+4fPlyuc7DcGNsrNwQkQnxVhRVZyqVCgDg4uKCO3fu4OLFi+U6D/8vMTZWboiIiCpEpVLB2toad+/eLdf7GW6MKTcX0A3PZOWGiMhkvL29sWTJklIfv2fPHqhUKty5c8dkbSLj0lVxyoPhxph0VRuAlRsiIsgvqOK29957r1znPXToEF5++eVSH9+1a1ckJCTAycmpXJ9HVQtHSxmTrr+NSgVUcIw+EVF1kJCQoH+8YcMGzJo1C7Gxsfp9+TtICyGg0WhgZVXyV5OLi0uZ2mFtbV1jR5llZ2dXaFh1VcTKjTHl729TgXIaEVFpCCH/TaXEJkTp2ujm5qbfnJycoFKp9M/PnDkDBwcH/PnnnwgICIBarca+fftw4cIFDBgwAK6urrC3t0fnzp3x119/GZz3wdtSKpUKX3/9NQYNGgQ7Ozv4+Pjg119/1b/+4G2pNWvWoE6dOti+fTtat24Ne3t7PP744wZhLDc3F2+88Qbq1KmD+vXrY+rUqRg5ciQGDhxY5O978+ZNDB06FB4eHrCzs0O7du2wbt06g2O0Wi0+/PBDNG/eHGq1Go0bN8YHH3ygf/3q1asYOnQo6tWrh9q1a6NTp074999/AQCjRo0q8PlvvvkmevbsqX/es2dPTJw4EW+++SacnZ0REhICAFi8eDHatWuH2rVrw9PTE+PHj0d6errBuSIiItCzZ0/Y2dmhbt26CAkJwe3bt7F27VrUr18fWVlZBscPHDgQw4cPL/J6KIXhxpg4UoqIzOjePcDeXpkt/134inr33Xcxf/58xMTEoH379khPT0ffvn0RHh6Oo0eP4vHHH0f//v0RHx9f7HnmzJmD559/HsePH0ffvn0xbNgw3Lp1q5jrdw8fffQRvv32W/z999+Ij4/H22+/rX99wYIF+P7777F69WpEREQgLS0NW7ZsKbYN9+/fR0BAALZu3YqTJ0/i5ZdfxvDhw3Hw4EH9MdOmTcP8+fMxc+ZMnD59Gj/88ANcXV0BAOnp6ejRoweuXbuGX3/9FceOHcOUKVOg1WpLcSXzfPPNN7C2tkZERASWL18OQI60W7p0KU6dOoVvvvkGu3btwpQpU/TviY6ORp8+feDr64vIyEjs27cP/fv3h0ajwXPPPQeNRmMQGJOTk7F161aMGTOmTG0zC1HDpKamCgAiNTXV+CePjBQCEKJJE+Ofm4hqtIyMDHH48GGRkZGh35eeLv/KUWJLTy/777B69Wrh5OSkf757924BQGzZsqXE97Zp00Z8+umn+udeXl7i448/1j8HIGbMmJHv2qQLAOLPP/80+Kzbt2/r2wJAnD9/Xv+eZcuWCVdXV/1zV1dXsXDhQv3z3Nxc0bhxYzFgwIDS/spCCCH69esn3nrrLSGEEGlpaUKtVosVK1YUeuyXX34pHBwcxM2bNwt9feTIkQU+f9KkSaJHjx765z169BAdOnQosV0bN24U9evX1z8fOnSo6NatW5HHv/baa+KJJ57QP1+0aJFo2rSp0Gq1JX5Waen+nG/atEksXLhQ/PLLL/rXyvL9XSkqN8uWLYO3tzdsbGzQpUsXg4T7oBUrVqB79+6oW7cu6tati+Dg4GKPNytWbojIjOzsgPR0ZTZj/jXXqVMng+fp6el4++230bp1a9SpUwf29vaIiYkpsXLTvn17/ePatWvD0dERycnJRR5vZ2eHZs2a6Z+7u7vrj09NTUVSUhICAwP1r1taWiIgIKDYNmg0Grz//vto164d6tWrB3t7e2zfvl3f9piYGGRlZaFPnz6Fvj86OhodOnRAvXr1iv2ckhTWzr/++gt9+vSBh4cHHBwcMHz4cNy8eRP3/ivD6So3RRk3bhx27NiBa9euAZC39kaNGlWhUU2moni42bBhA0JDQzF79mwcOXIEfn5+CAkJKfIP5J49ezB06FDs3r0bkZGR8PT0xGOPPaa/2IriHDdEZEYqlfzrRonNmN9ntR/4O/Ptt9/G5s2bMW/ePPzzzz+Ijo5Gu3btSlwJvVatWg9cH1Wxt3MKO16UtjNRERYuXIhPPvkEU6dOxe7duxEdHY2QkBB9221tbYt9f0mvW1hYFGhjTk5OgeMevKaXLl3Ck08+ifbt2+Onn35CVFQUli1bBgClbluHDh3g5+eHtWvXIioqCqdOncKoUaOKfY9SFA83ixcvxrhx4zB69Gj4+vpi+fLlsLOzw6pVqwo9/vvvv8f48ePh7++PVq1a4euvv4ZWq0V4eLiZW14IXeWG4YaIqNwiIiIwatQoDBo0CO3atYObmxsuXbpk1jY4OTnB1dUVhw4d0u/TaDQ4cuRIse+LiIjAgAED8OKLL8LPzw9NmzbF2bNn9a/7+PjA1ta2yO+s9u3bIzo6usi+Qi4uLgadngFZcSlJVFQUtFotFi1ahIceeggtWrTA9evXC3x2Sd+lY8eOxZo1a7B69WoEBwfD09OzxM9WgqLhJjs7G1FRUQgODtbvs7CwQHBwMCIjI0t1jnv37iEnJ6fIEl5WVhbS0tIMNpPRVW54W4qIqNx8fHzw888/Izo6GseOHcMLL7xQ5g61xvD6668jLCwMv/zyC2JjYzFp0iTcvn272NswPj4+2LlzJ/bv34+YmBi88sorSEpK0r9uY2ODqVOnYsqUKVi7di0uXLiAAwcOYOXKlQCAoUOHws3NDQMHDkRERAQuXryIn376Sf+d2Lt3bxw+fBhr167FuXPnMHv2bJw8ebLE36V58+bIycnBp59+iosXL+Lbb7/VdzTWmTZtGg4dOoTx48fj+PHjOHPmDL744gukpKToj3nhhRdw9epVrFixonJ2JP6PouEmJSUFGo1G30tcx9XVFYmJiaU6x9SpU9GwYUODgJRfWFgYnJyc9JtJUyYrN0REFbZ48WLUrVsXXbt2Rf/+/RESEoKOHTuavR1Tp07F0KFDMWLECAQFBcHe3h4hISGwsbEp8j0zZsxAx44dERISgp49e+qDSn4zZ87EW2+9hVmzZqF169YYPHiwviuGtbU1duzYgQYNGqBv375o164d5s+fD0tLSwBASEgIZs6ciSlTpqBz5864e/cuRowYUeLv4ufnh8WLF2PBggVo27Ytvv/+e4SFhRkc06JFC+zYsQPHjh1DYGAggoKC8MsvvxjMO+Tk5IRnnnkG9vb2xQ6JV5pKVPQGYwVcv34dHh4e2L9/P4KCgvT7p0yZgr179+rH9Rdl/vz5+PDDD7Fnzx6DjmT5ZWVlGYzLT0tLg6enJ1JTU+Ho6GicX0RnwQLg3XeBUaOA1auNe24iqtHu3buHmJgYtG7dGnasDitCq9WidevWeP755/H+++8r3RzF9OnTB23atMHSpUuNfm7dn/NLly4hLi4OLVq0wFNPPQVAfn87OTmV6vtb0RmKnZ2dYWlpaVCyA4CkpKQSZ5L86KOPMH/+fPz1119FBhtALp+uNtdswazcEBFVG5cvX8aOHTvQo0cPZGVl4bPPPkNcXBxeeOEFpZumiNu3b2PPnj3Ys2cPPv/8c6WbUyxFb0tZW1sjICDAoAOTrnNw/krOgz788EO8//772LZtW4EhhIpinxsiomrDwsICa9asQefOndGtWzecOHECf/31F1q3bq100xTRoUMHjBo1CgsWLEDLli2Vbk6xFF9bKjQ0FCNHjkSnTp0QGBiIJUuWICMjA6NHjwYAjBgxAh4eHvp7gwsWLMCsWbPwww8/wNvbW983x97e3mCNEkWwckNEVG14enoiIiJC6WZUGuYesVYRioebwYMH48aNG5g1axYSExPh7++Pbdu26TsZx8fHw8Iir8D0xRdfIDs7G88++6zBeWbPnl3u1WWNhpP4ERERKU7xcAMAEydOxMSJEwt9bc+ePQbPK3Vy5CR+REREilN8Er9qhZUbIiIixTHcGBMrN0RERIpjuDEmVm6IiIgUx3BjTKzcEBERKY7hxphYuSEiMomePXvizTff1D/39vbGkiVLin2PSqXCli1bKvzZxjoPmQ/DjTGxckNEZKB///54/PHHC33tn3/+gUqlwvHjx8t83kOHDuHll1+uaPMMvPfee/D39y+wPyEhAU888YRRP4tMi+HGmFi5ISIy8NJLL2Hnzp24evVqgddWr16NTp06FbuETlFcXFzMtsaWm5ub+ZbxqUSys7OVbkK5MdwYi1YLZGbKx6zcEJE5CCH/UaXEVso1l5988km4uLhgzZo1BvvT09OxceNGvPTSS7h58yaGDh0KDw8P2NnZoV27dli3bl2x533wttS5c+fwyCOPwMbGBr6+vti5c2eB90ydOhUtWrSAnZ0dmjZtipkzZyInJwcAsGbNGsyZMwfHjh2DSqWCSqXSt/nB21InTpxA7969YWtri/r16+Pll19Genq6/vVRo0Zh4MCB+Oijj+Du7o769etjwoQJ+s8qzIULFzBgwAC4urrC3t4enTt3xl9//WVwTFZWFqZOnQpPT0+o1Wo0b94cK1eu1L9+6tQpPPnkk3B0dISDgwO6d++OCxcuACh4Ww8ABg4ciFGjRhlc0/fffx8jRoyAo6OjvjJW3HXT+e2339C5c2fY2NjA2dkZgwYNAgDMnTsXbdu2LfD7+vv7Y+bMmUVej4qqFJP4VQu6YAOwckNE5nHvHqDUsjPp6aX6h5yVlRVGjBiBNWvWYPr06VCpVACAjRs3QqPRYOjQoUhPT0dAQACmTp0KR0dHbN26FcOHD0ezZs0QGBhY4mdotVo8/fTTcHV1xb///ovU1NQCX+QA4ODggDVr1qBhw4Y4ceIExo0bBwcHB0yZMgWDBw/GyZMnsW3bNn2ocHJyKnCOjIwMhISEICgoCIcOHUJycjLGjh2LiRMnGgS43bt3w93dHbt378b58+cxePBg+Pv7Y9y4cUVcznT07dsXH3zwAdRqNdauXYv+/fsjNjYWjRs3BiCXI4qMjMTSpUvh5+eHuLg4pKSkAACuXbuGRx55BD179sSuXbvg6OiIiIgI5Obmlnj98vvoo48wa9YszJ49u1TXDQC2bt2KQYMGYfr06Vi7di2ys7Pxxx9/AADGjBmDOXPm4NChQ+jcuTMA4OjRozh+/Dh+/vnnMrWtTEQNk5qaKgCI1NRU4544OVkI+W8ZITQa456biGq8jIwMcfjwYZGRkZG3Mz097+8dc2/p6aVue0xMjAAgdu/erd/XvXt38eKLLxb5nn79+om33npL/7xHjx5i0qRJ+udeXl7i448/FkIIsX37dmFlZSWuXbumf/3PP/8UAMTmzZuL/IyFCxeKgIAA/fPZs2cLPz+/AsflP89XX30l6tatK9Lz/f5bt24VFhYWIjExUQghxMiRI4WXl5fIzc3VH/Pcc8+JwYMHF9mWwrRp00Z8+umnQgghYmNjBQCxc+fOQo+dNm2aaNKkicjOzi709QevnxBCDBgwQIwcOVL/3MvLSwwcOLDEdj143YKCgsSwYcOKPP6JJ54Qr732mv7566+/Lnr27Fnosbo/55s2bRILFy4Uv/zyi/61snx/s3JjLLr+NjY2gAXv9hGRGdjZyQqKUp9dSq1atULXrl2xatUq9OzZE+fPn8c///yDuXPnAgA0Gg3mzZuHH3/8EdeuXUN2djaysrJK3acmJiYGnp6eaNiwoX5fUFBQgeM2bNiApUuX4sKFC0hPT0dubi4cHR1L/XvoPsvPzw+181WtunXrBq1Wi9jYWP26iG3atIGlpaX+GHd3d5w4caLI86anp+O9997D1q1bkZCQgNzcXGRmZiI+Ph4AEB0dDUtLS/To0aPQ90dHR6N79+6oVatWmX6fB3Xq1KnAvpKuW3R0dJEVKQAYN24cxowZg8WLF8PCwgI//PADPv744wq1syQMN8bCkVJEZG4qVZX5O+ell17C66+/jmXLlmH16tVo1qyZ/ot64cKF+OSTT7BkyRK0a9cOtWvXxptvvmnUDq2RkZEYNmwY5syZg5CQEDg5OWH9+vVYtGiR0T4jvwdDhkqlglarLfL4t99+Gzt37sRHH32E5s2bw9bWFs8++6z+Gtja2hb7eSW9bmFhAfFAP6nC+gDVfuDPU2muW0mf3b9/f6jVamzevBnW1tbIyckpsPi1sbHEYCwcKUVEVKTnn39e/6/2tWvXYsyYMfr+NxERERgwYABefPFF+Pn5oWnTpjh79mypz926dWtcuXIFCQkJ+n0HDhwwOGb//v3w8vLC9OnT0alTJ/j4+ODy5csGx1hbW0Oj0ZT4WceOHUOG7u/8/9pvYWGBli1blrrND4qIiMCoUaMwaNAgtGvXDm5ubgYLRbdr1w5arRZ79+4t9P3t27fHP//8U2SnZRcXF4Pro9FocPLkyRLbVZrr1r59e4SHhxd5DisrK4wcORKrV6/G6tWrMWTIkBIDUUUx3BhLTo7s2OfgoHRLiIgqHXt7ewwePBjTpk1DQkKCwSgdHx8f7Ny5E/v370dMTAxeeeUVJCUllfrcwcHBaNGiBUaOHIljx47hn3/+wfTp0w2O8fHxQXx8PNavX48LFy5g6dKl2Lx5s8Ex3t7eiIuLQ3R0NFJSUpCVlVXgs4YNGwYbGxuMHDkSJ0+exO7du/H6669j+PDh+ltS5eHj44Off/4Z0dHROHbsGF544QWDSo+3tzdGjhyJMWPGYMuWLYiLi8OePXvw448/AgAmTpyItLQ0DBkyBIcPH8a5c+fw7bffIjY2FgDQu3dvbN26FVu3bsWZM2fw2muv4c6dO6VqV0nXbfbs2Vi3bh1mz56NmJgYnDhxAgsWLDA4ZuzYsdi1axe2bduGMWPGlPs6lRbDjbF07QrcvQuUIgkTEdVEL730Em7fvo2QkBCD/jEzZsxAx44dERISgp49e8LNzQ0DBw4s9XktLCywefNmZGZmIjAwEGPHjsUHH3xgcMxTTz2FyZMnY+LEifD398f+/fsLDEV+5pln8Pjjj6NXr15wcXEpdDi6nZ0dtm/fjlu3bqFz58549tln0adPH3z22WdluxgPWLx4MerWrYuuXbuif//+CAkJQceOHQ2O+eKLL/Dss89i/PjxaNWqFcaNG6evINWvXx+7du1Ceno6evTogYCAAKxYsUJ/e2zMmDEYOXIkRowYgR49eqBp06bo1atXie0qzXXr2bMnNm7ciF9//RX+/v7o3bs3Dh48aHCMj48PunbtilatWqFLly4VuVSlohIP3oSr5tLS0uDk5ITU1NQydyQjIlLKvXv3EBMTg9atW5tt8joiYxFCwMfHB+PHj0doaGiRx+n+nF+6dAlxcXFo0aIFnnrqKQBl+/5mh2IiIiIymRs3bmD9+vVITEzE6NGjzfKZDDdERERkMg0aNICzszO++uor1K1b1yyfyXBDREREJqNE7xd2KCYiIqJqheGGiKgKKW4iOKKqzlhVHoYbIqIqwNraGgAMVp8mqm50cwuVdcHPB7HPDRFRFWBlZQVnZ2dcu3YNgJwUz4Lr2FE1otVqceXKFdy7dw8ajaZCVRyGGyKiKqJx48YAoA84RNWNVqtFYmIihBDIycmBvb19uc7DcENEVEWoVCp4eXnBwsIC4eHhyMzMhJOTEys4VC0IIZCVlQWtVotbt27BwcEB3t7e5ToXww0RURXj6emJ3r17Y8eOHUhKSmInY6pWLCwsYG9vj969e6Np06blOgfDDRFRFdS4cWMMHz4cd+/eLXEla6KqRBduKrJyOMMNEVEVpVaroVarlW4GUaXDG7VERERUrdS4yo1uaFlaWprCLSEiIqLS0n1vl2aIeI0LN3fv3gUgO+QRERFR1XL37l04OTkVe4xKKLGilYK0Wi2uX78OBwcHqFQqo547LS0Nnp6euHLlChwdHY16biqI19u8eL3Ni9fbvHi9zas811sIgbt376Jhw4YlTn9Q4yo3FhYWaNSokUk/w9HRkf9zmBGvt3nxepsXr7d58XqbV1mvd0kVGx12KCYiIqJqheGGiIiIqhWGGyNSq9WYPXs2550wE15v8+L1Ni9eb/Pi9TYvU1/vGtehmIiIiKo3Vm6IiIioWmG4ISIiomqF4YaIiIiqFYYbIiIiqlYYboxk2bJl8Pb2ho2NDbp06YKDBw8q3aRq4++//0b//v3RsGFDqFQqbNmyxeB1IQRmzZoFd3d32NraIjg4GOfOnVOmsVVcWFgYOnfuDAcHBzRo0AADBw5EbGyswTH379/HhAkTUL9+fdjb2+OZZ55BUlKSQi2u2r744gu0b99eP5FZUFAQ/vzzT/3rvNamNX/+fKhUKrz55pv6fbzmxvPee+9BpVIZbK1atdK/bsprzXBjBBs2bEBoaChmz56NI0eOwM/PDyEhIUhOTla6adVCRkYG/Pz8sGzZskJf//DDD7F06VIsX74c//77L2rXro2QkBDcv3/fzC2t+vbu3YsJEybgwIED2LlzJ3JycvDYY48hIyNDf8zkyZPx22+/YePGjdi7dy+uX7+Op59+WsFWV12NGjXC/PnzERUVhcOHD6N3794YMGAATp06BYDX2pQOHTqEL7/8Eu3btzfYz2tuXG3atEFCQoJ+27dvn/41k15rQRUWGBgoJkyYoH+u0WhEw4YNRVhYmIKtqp4AiM2bN+ufa7Va4ebmJhYuXKjfd+fOHaFWq8W6desUaGH1kpycLACIvXv3CiHkta1Vq5bYuHGj/piYmBgBQERGRirVzGqlbt264uuvv+a1NqG7d+8KHx8fsXPnTtGjRw8xadIkIQT/fBvb7NmzhZ+fX6Gvmfpas3JTQdnZ2YiKikJwcLB+n4WFBYKDgxEZGalgy2qGuLg4JCYmGlx/JycndOnShdffCFJTUwEA9erVAwBERUUhJyfH4Hq3atUKjRs35vWuII1Gg/Xr1yMjIwNBQUG81iY0YcIE9OvXz+DaAvzzbQrnzp1Dw4YN0bRpUwwbNgzx8fEATH+ta9zCmcaWkpICjUYDV1dXg/2urq44c+aMQq2qORITEwGg0Ouve43KR6vV4s0330S3bt3Qtm1bAPJ6W1tbo06dOgbH8nqX34kTJxAUFIT79+/D3t4emzdvhq+vL6Kjo3mtTWD9+vU4cuQIDh06VOA1/vk2ri5dumDNmjVo2bIlEhISMGfOHHTv3h0nT540+bVmuCGiQk2YMAEnT540uEdOxteyZUtER0cjNTUVmzZtwsiRI7F3716lm1UtXblyBZMmTcLOnTthY2OjdHOqvSeeeEL/uH379ujSpQu8vLzw448/wtbW1qSfzdtSFeTs7AxLS8sCPbyTkpLg5uamUKtqDt015vU3rokTJ+L333/H7t270ahRI/1+Nzc3ZGdn486dOwbH83qXn7W1NZo3b46AgACEhYXBz88Pn3zyCa+1CURFRSE5ORkdO3aElZUVrKyssHfvXixduhRWVlZwdXXlNTehOnXqoEWLFjh//rzJ/3wz3FSQtbU1AgICEB4ert+n1WoRHh6OoKAgBVtWMzRp0gRubm4G1z8tLQ3//vsvr385CCEwceJEbN68Gbt27UKTJk0MXg8ICECtWrUMrndsbCzi4+N5vY1Eq9UiKyuL19oE+vTpgxMnTiA6Olq/derUCcOGDdM/5jU3nfT0dFy4cAHu7u6m//Nd4S7JJNavXy/UarVYs2aNOH36tHj55ZdFnTp1RGJiotJNqxbu3r0rjh49Ko4ePSoAiMWLF4ujR4+Ky5cvCyGEmD9/vqhTp4745ZdfxPHjx8WAAQNEkyZNRGZmpsItr3pee+014eTkJPbs2SMSEhL027179/THvPrqq6Jx48Zi165d4vDhwyIoKEgEBQUp2Oqq69133xV79+4VcXFx4vjx4+Ldd98VKpVK7NixQwjBa20O+UdLCcFrbkxvvfWW2LNnj4iLixMREREiODhYODs7i+TkZCGEaa81w42RfPrpp6Jx48bC2tpaBAYGigMHDijdpGpj9+7dAkCBbeTIkUIIORx85syZwtXVVajVatGnTx8RGxurbKOrqMKuMwCxevVq/TGZmZli/Pjxom7dusLOzk4MGjRIJCQkKNfoKmzMmDHCy8tLWFtbCxcXF9GnTx99sBGC19ocHgw3vObGM3jwYOHu7i6sra2Fh4eHGDx4sDh//rz+dVNea5UQQlS8/kNERERUObDPDREREVUrDDdERERUrTDcEBERUbXCcENERETVCsMNERERVSsMN0RERFStMNwQERFRtcJwQ0RERNUKww0R1Th79uyBSqUqsGgfEVUPDDdERERUrTDcEBERUbXCcENEZqfVahEWFoYmTZrA1tYWfn5+2LRpE4C8W0Zbt25F+/btYWNjg4ceeggnT540OMdPP/2ENm3aQK1Ww9vbG4sWLTJ4PSsrC1OnToWnpyfUajWaN2+OlStXGhwTFRWFTp06wc7ODl27dkVsbKz+tWPHjqFXr15wcHCAo6MjAgICcPjwYRNdESIyJoYbIjK7sLAwrF27FsuXL8epU6cwefJkvPjii9i7d6/+mHfeeQeLFi3CoUOH4OLigv79+yMnJweADCXPP/88hgwZghMnTuC9997DzJkzsWbNGv37R4wYgXXr1mHp0qWIiYnBl19+CXt7e4N2TJ8+HYsWLcLhw4dhZWWFMWPG6F8bNmwYGjVqhEOHDiEqKgrvvvsuatWqZdoLQ0TGYZS1xYmISun+/fvCzs5O7N+/32D/Sy+9JIYOHSp2794tAIj169frX7t586awtbUVGzZsEEII8cILL4hHH33U4P3vvPOO8PX1FUIIERsbKwCInTt3FtoG3Wf89ddf+n1bt24VAERmZqYQQggHBwexZs2aiv/CRGR2rNwQkVmdP38e9+7dw6OPPgp7e3v9tnbtWly4cEF/XFBQkP5xvXr10LJlS8TExAAAYmJi0K1bN4PzduvWDefOnYNGo0F0dDQsLS3Ro0ePYtvSvn17/WN3d3cAQHJyMgAgNDQUY8eORXBwMObPn2/QNiKq3BhuiMis0tPTAQBbt25FdHS0fjt9+rS+301F2draluq4/LeZVCoVANkfCADee+89nDp1Cv369cOuXbvg6+uLzZs3G6V9RGRaDDdEZFa+vr5Qq9WIj49H8+bNDTZPT0/9cQcOHNA/vn37Ns6ePYvWrVsDAFq3bo2IiAiD80ZERKBFixawtLREu3btoNVqDfrwlEeLFi0wefJk7NixA08//TRWr15dofMRkXlYKd0AIqpZHBwc8Pbbb2Py5MnQarV4+OGHkZqaioiICDg6OsLLywsAMHfuXNSvXx+urq6YPn06nJ2dMXDgQADAW2+9hc6dO+P999/H4MGDERkZic8++wyff/45AMDb2xsjR47EmDFjsHTpUvj5+eHy5ctITk7G888/X2IbMzMz8c477+DZZ59FkyZNcPXqVRw6dAjPPPOMya4LERmR0p1+iKjm0Wq1YsmSJaJly5aiVq1awsXFRYSEhIi9e/fqO/v+9ttvok2bNsLa2loEBgaKY8eOGZxj06ZNwtfXV9SqVUs0btxYLFy40OD1zMxMMXnyZOHu7i6sra1F8+bNxapVq4QQeR2Kb9++rT/+6NGjAoCIi4sTWVlZYsiQIcLT01NYW1uLhg0biokTJ+o7GxNR5aYSQgiF8xURkd6ePXvQq1cv3L59G3Xq1FG6OURUBbHPDREREVUrDDdERERUrfC2FBEREVUrrNwQERFRtcJwQ0RERNUKww0RERFVKww3REREVK0w3BAREVG1wnBDRERE1QrDDREREVUrDDdERERUrfw/qmJ+3KkvGmUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the classifier loss and accuracy curves for training and validation data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(historyc2.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(historyc2.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>0.042055</td>\n",
       "      <td>0.373291</td>\n",
       "      <td>0.462234</td>\n",
       "      <td>0.672240</td>\n",
       "      <td>0.460185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.181142</td>\n",
       "      <td>-0.057993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.017546</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.182163</td>\n",
       "      <td>0.180288</td>\n",
       "      <td>0.031583</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.187470</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>0.038581</td>\n",
       "      <td>0.480622</td>\n",
       "      <td>0.728615</td>\n",
       "      <td>0.953126</td>\n",
       "      <td>0.664928</td>\n",
       "      <td>0.034667</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.307242</td>\n",
       "      <td>-0.252209</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022077</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.943739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6137</th>\n",
       "      <td>0.068385</td>\n",
       "      <td>0.357468</td>\n",
       "      <td>0.628147</td>\n",
       "      <td>0.658977</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.045326</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.133935</td>\n",
       "      <td>-0.006750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.943739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>0.034741</td>\n",
       "      <td>0.249940</td>\n",
       "      <td>0.421155</td>\n",
       "      <td>0.462863</td>\n",
       "      <td>0.392526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030944</td>\n",
       "      <td>0.161029</td>\n",
       "      <td>-0.068421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.018482</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.943739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.080271</td>\n",
       "      <td>0.253895</td>\n",
       "      <td>0.510652</td>\n",
       "      <td>0.724922</td>\n",
       "      <td>0.429636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.122974</td>\n",
       "      <td>-0.096867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.168670</td>\n",
       "      <td>0.172760</td>\n",
       "      <td>0.097554</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.175992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4         5         6         7  \\\n",
       "2595  0.042055  0.373291  0.462234  0.672240  0.460185  0.000000  0.000000   \n",
       "3984  0.038581  0.480622  0.728615  0.953126  0.664928  0.034667  0.024510   \n",
       "6137  0.068385  0.357468  0.628147  0.658977  0.675978  0.045326  0.029412   \n",
       "6479  0.034741  0.249940  0.421155  0.462863  0.392526  0.000000  0.000000   \n",
       "39    0.080271  0.253895  0.510652  0.724922  0.429636  0.000000  0.000000   \n",
       "\n",
       "             8         9        10  ...        25        26        27  \\\n",
       "2595  0.007363  0.181142 -0.057993  ...  0.000146  0.017546  0.000308   \n",
       "3984  0.003954  0.307242 -0.252209  ... -0.022077  0.034743  0.001207   \n",
       "6137  0.004798  0.133935 -0.006750  ... -0.000243  0.009306  0.000087   \n",
       "6479  0.030944  0.161029 -0.068421  ...  0.002685  0.018482  0.000342   \n",
       "39    0.009380  0.122974 -0.096867  ...  0.000560  0.007207  0.000052   \n",
       "\n",
       "            28        29        30        31        32        33  Label  \n",
       "2595  0.176471  0.182163  0.180288  0.031583  0.000997  0.187470     21  \n",
       "3984  1.000000  0.860215  0.943739  0.000000  0.000000  0.975610     33  \n",
       "6137  1.000000  0.860215  0.943739  0.000000  0.000000  0.975610     51  \n",
       "6479  1.000000  0.860215  0.943739  0.000000  0.000000  0.975610     53  \n",
       "39    0.062745  0.168670  0.172760  0.097554  0.009515  0.175992      0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#valid test data\n",
    "import csv\n",
    "import pandas as pd\n",
    "testdataset=pd.read_csv('Dataset/SwipeDatatest.csv',index_col=0)\n",
    "testdataset = testdataset[testdataset['Label'] < 68]\n",
    "Xtest=testdataset.drop(columns=['Label'])\n",
    "ytest=testdataset['Label']\n",
    "ytest = to_categorical(ytest)\n",
    "\n",
    "testdataset.head()\n",
    "#Xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60OnWGGQ7K-b",
    "outputId": "6d91f20a-176b-410c-e2a5-ec3d3b15465f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8273 - loss: 0.6728\n",
      "Loss: 0.6854076981544495\n",
      "Accuracy: 0.8206223249435425\n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier for valid test data\n",
    "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#invalid test data\n",
    "import csv\n",
    "import pandas as pd\n",
    "testdataset=pd.read_csv('Dataset/SwipeDatatest.csv',index_col=0)\n",
    "testdataset = testdataset[testdataset['Label'] >= 68]\n",
    "Xtest=testdataset.drop(columns=['Label'])\n",
    "ytest = np.random.randint(0, 68, size=Xtest.shape[0])\n",
    "ytest = pd.DataFrame(ytest, columns=['random_numbers'])\n",
    "#ytest=testdataset['Label']\n",
    "print(type(ytest))\n",
    "ytest = to_categorical(ytest)\n",
    "\n",
    "#testdataset.head()\n",
    "#Xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0239 - loss: 14.7471  \n",
      "Loss: 14.961579322814941\n",
      "Accuracy: 0.021176470443606377\n"
     ]
    }
   ],
   "source": [
    "#Performance of the classifier for valid test data\n",
    "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
    "#print('Test score:', score)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
